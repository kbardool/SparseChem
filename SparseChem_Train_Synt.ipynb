{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d81e7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T18:50:52.221512Z",
     "start_time": "2022-03-04T18:50:52.203972Z"
    }
   },
   "source": [
    "### Output to `experiments/SparseChem`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f966d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:05.444859Z",
     "start_time": "2022-04-09T15:53:05.418073Z"
    }
   },
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "810bc0a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:17.541949Z",
     "start_time": "2022-04-09T15:53:17.362741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../experiments/synt-SparseChem/0409_1753\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2020 KU Leuven\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "import sparsechem as sc\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "import time\n",
    "import json\n",
    "import functools\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "import csv\n",
    "#from apex import amp\n",
    "from contextlib import redirect_stdout\n",
    "from sparsechem import Nothing\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_memlab import MemReporter\n",
    "import multiprocessing\n",
    "from pynvml import *\n",
    " \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions( linewidth=132)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    nvmlInit()\n",
    "\n",
    "multiprocessing.set_start_method('fork', force=True)\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Training a multi-task model.\")\n",
    "parser.add_argument(\"--x\", help=\"Descriptor file (matrix market, .npy or .npz)\", type=str, default=None)\n",
    "parser.add_argument(\"--y_class\", \"--y\", \"--y_classification\", help=\"Activity file (matrix market, .npy or .npz)\", type=str, default=None)\n",
    "parser.add_argument(\"--y_regr\", \"--y_regression\", help=\"Activity file (matrix market, .npy or .npz)\", type=str, default=None)\n",
    "parser.add_argument(\"--y_censor\", help=\"Censor mask for regression (matrix market, .npy or .npz)\", type=str, default=None)\n",
    "parser.add_argument(\"--weights_class\", \"--task_weights\", \"--weights_classification\", help=\"CSV file with columns task_id, training_weight, aggregation_weight, task_type (for classification tasks)\", type=str, default=None)\n",
    "parser.add_argument(\"--weights_regr\", \"--weights_regression\", help=\"CSV file with columns task_id, training_weight, censored_weight, aggregation_weight, aggregation_weight, task_type (for regression tasks)\", type=str, default=None)\n",
    "parser.add_argument(\"--censored_loss\", help=\"Whether censored loss is used for training (default 1)\", type=int, default=1)\n",
    "parser.add_argument(\"--folding\", help=\"Folding file (npy)\", type=str, required=True)\n",
    "parser.add_argument(\"--fold_va\", help=\"Validation fold number\", type=int, default=0)\n",
    "parser.add_argument(\"--fold_te\", help=\"Test fold number (removed from dataset)\", type=int, default=None)\n",
    "parser.add_argument(\"--batch_ratio\", help=\"Batch ratio\", type=float, default=0.02)\n",
    "parser.add_argument(\"--internal_batch_max\", help=\"Maximum size of the internal batch\", type=int, default=None)\n",
    "parser.add_argument(\"--normalize_loss\", help=\"Normalization constant to divide the loss (default uses batch size)\", type=float, default=None)\n",
    "parser.add_argument(\"--normalize_regression\", help=\"Set this to 1 if the regression tasks should be normalized\", type=int, default=0)\n",
    "parser.add_argument(\"--normalize_regr_va\", help=\"Set this to 1 if the regression tasks in validation fold should be normalized together with training folds\", type=int, default=0)\n",
    "parser.add_argument(\"--inverse_normalization\", help=\"Set this to 1 if the regression tasks in validation fold should be inverse normalized at validation time\", type=int, default=0)\n",
    "parser.add_argument(\"--hidden_sizes\", nargs=\"+\", help=\"Hidden sizes of trunk\", default=[], type=int, required=True)\n",
    "parser.add_argument(\"--last_hidden_sizes\", nargs=\"+\", help=\"Hidden sizes in the head (if specified , class and reg heads have this dimension)\", default=None, type=int)\n",
    "#parser.add_argument(\"--middle_dropout\", help=\"Dropout for layers before the last\", type=float, default=0.0)\n",
    "#parser.add_argument(\"--last_dropout\", help=\"Last dropout\", type=float, default=0.2)\n",
    "parser.add_argument(\"--weight_decay\", help=\"Weight decay\", type=float, default=0.0)\n",
    "parser.add_argument(\"--last_non_linearity\", help=\"Last layer non-linearity (depecrated)\", type=str, default=\"relu\", choices=[\"relu\", \"tanh\"])\n",
    "parser.add_argument(\"--middle_non_linearity\", \"--non_linearity\", help=\"Before last layer non-linearity\", type=str, default=\"relu\", choices=[\"relu\", \"tanh\"])\n",
    "parser.add_argument(\"--input_transform\", help=\"Transformation to apply to inputs\", type=str, default=\"none\", choices=[\"binarize\", \"none\", \"tanh\", \"log1p\"])\n",
    "parser.add_argument(\"--lr\", help=\"Learning rate\", type=float, default=1e-3)\n",
    "parser.add_argument(\"--lr_alpha\", help=\"Learning rate decay multiplier\", type=float, default=0.3)\n",
    "parser.add_argument(\"--lr_steps\", nargs=\"+\", help=\"Learning rate decay steps\", type=int, default=[10])\n",
    "parser.add_argument(\"--input_size_freq\", help=\"Number of high importance features\", type=int, default=None)\n",
    "parser.add_argument(\"--fold_inputs\", help=\"Fold input to a fixed set (default no folding)\", type=int, default=None)\n",
    "parser.add_argument(\"--epochs\", help=\"Number of epochs\", type=int, default=20)\n",
    "parser.add_argument(\"--pi_zero\", help=\"Reference class ratio to be used for calibrated aucpr\", type=float, default=0.1)\n",
    "parser.add_argument(\"--min_samples_class\", help=\"Minimum number samples in each class and in each fold for AUC calculation (only used if aggregation_weight is not provided in --weights_class)\", type=int, default=5)\n",
    "parser.add_argument(\"--min_samples_auc\", help=\"Obsolete: use 'min_samples_class'\", type=int, default=None)\n",
    "parser.add_argument(\"--min_samples_regr\", help=\"Minimum number of uncensored samples in each fold for regression metric calculation (only used if aggregation_weight is not provided in --weights_regr)\", type=int, default=10)\n",
    "parser.add_argument(\"--dev\", help=\"Device to use\", type=str, default=\"cuda:0\")\n",
    "parser.add_argument(\"--run_name\", help=\"Run name for results\", type=str, default=None)\n",
    "parser.add_argument(\"--output_dir\", help=\"Output directory, including boards (default 'models')\", type=str, default=\"models\")\n",
    "parser.add_argument(\"--prefix\", help=\"Prefix for run name (default 'run')\", type=str, default='sc')\n",
    "parser.add_argument(\"--verbose\", help=\"Verbosity level: 2 = full; 1 = no progress; 0 = no output\", type=int, default=2, choices=[0, 1, 2])\n",
    "parser.add_argument(\"--save_model\", help=\"Set this to 0 if the model should not be saved\", type=int, default=1)\n",
    "parser.add_argument(\"--save_board\", help=\"Set this to 0 if the TensorBoard should not be saved\", type=int, default=1)\n",
    "parser.add_argument(\"--profile\", help=\"Set this to 1 to output memory profile information\", type=int, default=0)\n",
    "parser.add_argument(\"--mixed_precision\", help=\"Set this to 1 to run in mixed precision mode (vs single precision)\", type=int, default=0)\n",
    "parser.add_argument(\"--eval_train\", help=\"Set this to 1 to calculate AUCs for train data\", type=int, default=0)\n",
    "parser.add_argument(\"--enable_cat_fusion\", help=\"Set this to 1 to enable catalogue fusion\", type=int, default=0)\n",
    "parser.add_argument(\"--eval_frequency\", help=\"The gap between AUC eval (in epochs), -1 means to do an eval at the end.\", type=int, default=1)\n",
    "#hybrid model features\n",
    "parser.add_argument(\"--regression_weight\", help=\"between 0 and 1 relative weight of regression loss vs classification loss\", type=float, default=0.5)\n",
    "parser.add_argument(\"--scaling_regularizer\", help=\"L2 regularizer of the scaling layer, if inf scaling layer is switched off\", type=float, default=np.inf)\n",
    "parser.add_argument(\"--class_feature_size\", help=\"Number of leftmost features used from the output of the trunk (default: use all)\", type=int, default=-1)\n",
    "parser.add_argument(\"--regression_feature_size\", help=\"Number of rightmost features used from the output of the trunk (default: use all)\", type=int, default=-1)\n",
    "parser.add_argument(\"--last_hidden_sizes_reg\", nargs=\"+\", help=\"Hidden sizes in the regression head (overwritten by last_hidden_sizes)\", default=None, type=int)\n",
    "parser.add_argument(\"--last_hidden_sizes_class\", nargs=\"+\", help=\"Hidden sizes in the classification head (overwritten by last_hidden_sizes)\", default=None, type=int)\n",
    "parser.add_argument(\"--dropouts_reg\"  , nargs=\"+\", help=\"List of dropout values used in the regression head (needs one per last hidden in reg head, ignored if last_hidden_sizes_reg not specified)\", default=[], type=float)\n",
    "parser.add_argument(\"--dropouts_class\", nargs=\"+\", help=\"List of dropout values used in the classification head (needs one per last hidden in class head, ignored if no last_hidden_sizes_class not specified)\", default=[], type=float)\n",
    "parser.add_argument(\"--dropouts_trunk\", nargs=\"+\", help=\"List of dropout values used in the trunk\", default=[], type=float)\n",
    "\n",
    "dev = \"gpu\" \n",
    "rstr = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "# data_dir=\"chembl23_data\"\n",
    "# data_dir=\"chembl23_run_01152022\"\n",
    "data_dir = \"../MLDatasets/chembl23_synthetic\"\n",
    "output_dir = f\"../experiments/synt-SparseChem/{rstr}\"\n",
    "print(output_dir)\n",
    "\n",
    "rm_output=False\n",
    "\n",
    "# rstr = \"synthetic_data_model\" ##random_str(12)\n",
    "# rstr = \"synthetic_data_model_03042022\" ##random_str(12)\n",
    "\n",
    "# output_dir = f\"./models-{rstr}/\"\n",
    "# output_dir = f\"./{data_dir}/models-{rstr}/\"\n",
    "\n",
    "# output dir kbardool/kusanagi/experiments/SparseChem/0116_0843\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6d5b25",
   "metadata": {},
   "source": [
    "### Two layer network as specified in `https://git.infra.melloddy.eu/wp2/sparsechem/-/blob/master/docs/main.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f34127f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:34.733257Z",
     "start_time": "2022-04-09T15:53:34.705946Z"
    }
   },
   "outputs": [],
   "source": [
    "cmd = (\n",
    "  f\" --x              {data_dir}/chembl_23mini_x.npy \" +\n",
    "  f\" --y_class        {data_dir}/chembl_23mini_adashare_y_all_bin_sparse.npy \" +\n",
    "  f\" --folding        {data_dir}/chembl_23mini_folds.npy \" +\n",
    "\n",
    "  f\" --output_dir     {output_dir}\" +\n",
    "  F\" --dev             cpu \"\n",
    "  f\" --fold_va           0 \" +\n",
    "  f\" --fold_inputs   32000\" +\n",
    "  f\" --batch_ratio    0.01 \" +\n",
    "  f\" --hidden_sizes     50 50\" +\n",
    "  f\" --dropouts_trunk    0 0 \" +\n",
    "  f\" --weight_decay   1e-4 \" \n",
    "  f\" --epochs          100 \" +\n",
    "  f\" --lr             1e-3 \" +\n",
    "  f\" --lr_steps         10 \" +\n",
    "  f\" --lr_alpha        0.3\"  + \n",
    "  f\" --prefix          sc \"  +\n",
    "  f\" --min_samples_class 1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2a96b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:38:55.671646Z",
     "start_time": "2022-04-09T15:38:55.648170Z"
    }
   },
   "outputs": [],
   "source": [
    "#   f\" --eval_train        0 \" +\n",
    "## f\" --last_hidden_sizes   ?? \"\"\n",
    "# cmd = (\n",
    "#   f\" --x       {data_dir}/chembl_23mini_x.npy \" +\n",
    "#   f\" --y_class {data_dir}/chembl_23mini_adashare_y_all_bin_sparse.npy \" +\n",
    "#   f\" --folding {data_dir}/chembl_23mini_folds.npy \" +\n",
    "#   f\" --output_dir {output_dir}\" +    \n",
    "#   f\" --fold_va            0 \" +\n",
    "#   f\" --batch_ratio     0.02 \" +\n",
    "#   f\" --hidden_sizes   40 40 \" +\n",
    "#   f\" --dropouts_trunk  0  0 \" +\n",
    "#   f\" --weight_decay   1e-4 \" +\n",
    "#   f\" --epochs           20 \" +\n",
    "#   f\" --lr             1e-3 \" +\n",
    "#   f\" --lr_steps         10 \" +\n",
    "#   f\" --lr_alpha        0.3 \" \n",
    "# )\n",
    "\n",
    "\n",
    "#   f\" --hidden_sizes   25 25 25 25 25 25 \" +\n",
    "#   f\" --dropouts_trunk  0  0  0  0  0  0 \" +\n",
    "#   f\" --hidden_sizes   400 400 \" +\n",
    "#   f\" --last_dropout   0.2 \" +\n",
    "#   f\" --middle_dropout 0.2 \" +\n",
    "#   f\" --x ./{data_dir}/chembl_23_x.mtx \" +\n",
    "#   f\" --y_class ./{data_dir}/chembl_23_y.mtx \" +\n",
    "#   f\" --folding ./{data_dir}/folding_hier_0.6.npy \" +\n",
    "\n",
    "#### copied from SparseChemDev \n",
    "\n",
    "# cmd = (\n",
    "#         f\" --x       ./{data_dir}/chembl_23mini_x.npy\" +\n",
    "#         f\" --y_class ./{data_dir}/chembl_23mini_y.npy\" +\n",
    "#         f\" --folding ./{data_dir}/chembl_23mini_folds.npy\" +\n",
    "#         f\" --hidden_sizes 20 30 40 \" +  \n",
    "#         f\" --output_dir {output_dir}\" +\n",
    "#         f\" --batch_ratio 0.1\" +\n",
    "#         f\" --epochs 2\" +\n",
    "#         f\" --lr 1e-3\" +\n",
    "#         f\" --lr_steps 1\" +\n",
    "#         f\" --dev {dev}\" +\n",
    "#         f\" --verbose 1\")\n",
    "#         f\" --input_size_freq  40\"\n",
    "#         f\" --tail_hidden_size  10\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d1085",
   "metadata": {},
   "source": [
    "### Initializations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31290fa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:36.513411Z",
     "start_time": "2022-04-09T15:53:36.484072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'batch_ratio': 0.01,\n",
      "    'censored_loss': 1,\n",
      "    'class_feature_size': -1,\n",
      "    'dev': 'cpu',\n",
      "    'dropouts_class': [],\n",
      "    'dropouts_reg': [],\n",
      "    'dropouts_trunk': [0.0, 0.0],\n",
      "    'enable_cat_fusion': 0,\n",
      "    'epochs': 100,\n",
      "    'eval_frequency': 1,\n",
      "    'eval_train': 0,\n",
      "    'fold_inputs': 32000,\n",
      "    'fold_te': None,\n",
      "    'fold_va': 0,\n",
      "    'folding': '../MLDatasets/chembl23_synthetic/chembl_23mini_folds.npy',\n",
      "    'hidden_sizes': [50, 50],\n",
      "    'input_size_freq': None,\n",
      "    'input_transform': 'none',\n",
      "    'internal_batch_max': None,\n",
      "    'inverse_normalization': 0,\n",
      "    'last_hidden_sizes': None,\n",
      "    'last_hidden_sizes_class': None,\n",
      "    'last_hidden_sizes_reg': None,\n",
      "    'last_non_linearity': 'relu',\n",
      "    'lr': 0.001,\n",
      "    'lr_alpha': 0.3,\n",
      "    'lr_steps': [10],\n",
      "    'middle_non_linearity': 'relu',\n",
      "    'min_samples_auc': None,\n",
      "    'min_samples_class': 1,\n",
      "    'min_samples_regr': 10,\n",
      "    'mixed_precision': 0,\n",
      "    'normalize_loss': None,\n",
      "    'normalize_regr_va': 0,\n",
      "    'normalize_regression': 0,\n",
      "    'output_dir': '../experiments/synt-SparseChem/0409_1753',\n",
      "    'pi_zero': 0.1,\n",
      "    'prefix': 'sc',\n",
      "    'profile': 0,\n",
      "    'regression_feature_size': -1,\n",
      "    'regression_weight': 0.5,\n",
      "    'run_name': None,\n",
      "    'save_board': 1,\n",
      "    'save_model': 1,\n",
      "    'scaling_regularizer': inf,\n",
      "    'verbose': 2,\n",
      "    'weight_decay': 0.0001,\n",
      "    'weights_class': None,\n",
      "    'weights_regr': None,\n",
      "    'x': '../MLDatasets/chembl23_synthetic/chembl_23mini_x.npy',\n",
      "    'y_censor': None,\n",
      "    'y_class': '../MLDatasets/chembl23_synthetic/chembl_23mini_adashare_y_all_bin_sparse.npy',\n",
      "    'y_regr': None}\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(cmd.split())\n",
    "\n",
    "\n",
    "# %tb\n",
    "# args = parser.parse_args()\n",
    "\n",
    "def vprint(s=\"\"):\n",
    "    if args.verbose:\n",
    "        print(s)\n",
    "\n",
    "pp.pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "200d78ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:37.063289Z",
     "start_time": "2022-04-09T15:53:37.039565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name is 'sc_50.50_lr0.001_do0.0'.\n"
     ]
    }
   ],
   "source": [
    "if args.run_name is not None:\n",
    "    name = args.run_name\n",
    "else:\n",
    "    name  = f\"{args.prefix}\"\n",
    "    name += f\"_{'.'.join([str(h) for h in args.hidden_sizes])}\"\n",
    "#     name += f\"_do{'.'.join([str(d) for d in args.dropouts_trunk])}\"\n",
    "    name += f\"_lr{args.lr}\"\n",
    "    name += f\"_do{args.dropouts_trunk[0]}\"\n",
    "#     name += f\"_wd{args.weight_decay}\"\n",
    "#     name += f\"_hs{'.'.join([str(h) for h in args.hidden_sizes])}\"\n",
    "    \n",
    "#     name += f\"_lrsteps{'.'.join([str(s) for s in args.lr_steps])}_ep{args.epochs}\"\n",
    "#     name += f\"_fva{args.fold_va}_fte{args.fold_te}\"\n",
    "    if args.mixed_precision == 1:\n",
    "        name += f\"_mixed_precision\"\n",
    "vprint(f\"Run name is '{name}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8540f870",
   "metadata": {},
   "source": [
    "### Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31a37333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:37.729818Z",
     "start_time": "2022-04-09T15:53:37.704191Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if (args.last_hidden_sizes is not None) and ((args.last_hidden_sizes_class is not None) or (args.last_hidden_sizes_reg is not None)):\n",
    "    raise ValueError(\"Head specific and general last_hidden_sizes argument were both specified!\")\n",
    "if (args.last_hidden_sizes is not None):\n",
    "    args.last_hidden_sizes_class = args.last_hidden_sizes\n",
    "    args.last_hidden_sizes_reg   = args.last_hidden_sizes\n",
    "\n",
    "if args.last_hidden_sizes_reg is not None:\n",
    "    assert len(args.last_hidden_sizes_reg) == len(args.dropouts_reg), \"Number of hiddens and number of dropout values specified must be equal in the regression head!\"\n",
    "if args.last_hidden_sizes_class is not None:\n",
    "    assert len(args.last_hidden_sizes_class) == len(args.dropouts_class), \"Number of hiddens and number of dropout values specified must be equal in the classification head!\"\n",
    "if args.hidden_sizes is not None:\n",
    "    assert len(args.hidden_sizes) == len(args.dropouts_trunk), \"Number of hiddens and number of dropout values specified must be equal in the trunk!\"\n",
    "\n",
    "if args.class_feature_size == -1:\n",
    "    args.class_feature_size = args.hidden_sizes[-1]\n",
    "if args.regression_feature_size == -1:\n",
    "    args.regression_feature_size = args.hidden_sizes[-1]\n",
    "\n",
    "assert args.regression_feature_size <= args.hidden_sizes[-1], \"Regression feature size cannot be larger than the trunk output\"\n",
    "assert args.class_feature_size <= args.hidden_sizes[-1], \"Classification feature size cannot be larger than the trunk output\"\n",
    "assert args.regression_feature_size + args.class_feature_size >= args.hidden_sizes[-1], \"Unused features in the trunk! Set regression_feature_size + class_feature_size >= trunk output!\"\n",
    "#if args.regression_feature_size != args.hidden_sizes[-1] or args.class_feature_size != args.hidden_sizes[-1]:\n",
    "#    raise ValueError(\"Hidden spliting not implemented yet!\")\n",
    "\n",
    "assert args.input_size_freq is None, \"Using tail compression not yet supported.\"\n",
    "\n",
    "if (args.y_class is None) and (args.y_regr is None):\n",
    "    raise ValueError(\"No label data specified, please add --y_class and/or --y_regr.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba30c7a",
   "metadata": {},
   "source": [
    "### Summary writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34215554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:38.317480Z",
     "start_time": "2022-04-09T15:53:38.288440Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.profile == 1:\n",
    "    assert (args.save_board==1), \"Tensorboard should be enabled to be able to profile memory usage.\"\n",
    "if args.save_board:\n",
    "    tb_name = os.path.join(args.output_dir, \"\", name)\n",
    "    writer  = SummaryWriter(tb_name)\n",
    "else:\n",
    "    writer = Nothing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e021b65",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6aea99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T18:45:40.685828Z",
     "start_time": "2022-03-04T18:45:40.657750Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eef41e32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:39.092354Z",
     "start_time": "2022-04-09T15:53:38.860759Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count non zero:80\n",
      "Input dimension: 32000\n",
      "#samples:        18388\n",
      "#classification tasks:  15\n",
      "#regression tasks:      0\n",
      "Using 15 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "Using 0 regression tasks for calculating metrics (RMSE, Rsquared, correlation).\n"
     ]
    }
   ],
   "source": [
    "ecfp     = sc.load_sparse(args.x)\n",
    "y_class  = sc.load_sparse(args.y_class)\n",
    "y_regr   = sc.load_sparse(args.y_regr)\n",
    "y_censor = sc.load_sparse(args.y_censor)\n",
    "\n",
    "if (y_regr is None) and (y_censor is not None):\n",
    "    raise ValueError(\"y_censor provided please also provide --y_regr.\")\n",
    "if y_class is None:\n",
    "    y_class = scipy.sparse.csr_matrix((ecfp.shape[0], 0))\n",
    "if y_regr is None:\n",
    "    y_regr  = scipy.sparse.csr_matrix((ecfp.shape[0], 0))\n",
    "if y_censor is None:\n",
    "    y_censor = scipy.sparse.csr_matrix(y_regr.shape)\n",
    "\n",
    "folding = np.load(args.folding)\n",
    "assert ecfp.shape[0] == folding.shape[0], \"x and folding must have same number of rows\"\n",
    "\n",
    "## Loading task weights\n",
    "tasks_class = sc.load_task_weights(args.weights_class, y=y_class, label=\"y_class\")\n",
    "tasks_regr  = sc.load_task_weights(args.weights_regr, y=y_regr, label=\"y_regr\")\n",
    "\n",
    "## Input transformation\n",
    "ecfp = sc.fold_transform_inputs(ecfp, folding_size=args.fold_inputs, transform=args.input_transform)\n",
    "print(f\"count non zero:{ecfp[0].count_nonzero()}\")\n",
    "num_pos    = np.array((y_class == +1).sum(0)).flatten()\n",
    "num_neg    = np.array((y_class == -1).sum(0)).flatten()\n",
    "num_class  = np.array((y_class != 0).sum(0)).flatten()\n",
    "if (num_class != num_pos + num_neg).any():\n",
    "    raise ValueError(\"For classification all y values (--y_class/--y) must be 1 or -1.\")\n",
    "\n",
    "num_regr   = np.bincount(y_regr.indices, minlength=y_regr.shape[1])\n",
    "\n",
    "assert args.min_samples_auc is None, \"Parameter 'min_samples_auc' is obsolete. Use '--min_samples_class' that specifies how many samples a task needs per FOLD and per CLASS to be aggregated.\"\n",
    "\n",
    "if tasks_class.aggregation_weight is None:\n",
    "    ## using min_samples rule\n",
    "    fold_pos, fold_neg = sc.class_fold_counts(y_class, folding)\n",
    "    n = args.min_samples_class\n",
    "    tasks_class.aggregation_weight = ((fold_pos >= n).all(0) & (fold_neg >= n)).all(0).astype(np.float64)\n",
    "\n",
    "if tasks_regr.aggregation_weight is None:\n",
    "    if y_censor.nnz == 0:\n",
    "        y_regr2 = y_regr.copy()\n",
    "        y_regr2.data[:] = 1\n",
    "    else:\n",
    "        ## only counting uncensored data\n",
    "        y_regr2      = y_censor.copy()\n",
    "        y_regr2.data = (y_regr2.data == 0).astype(np.int32)\n",
    "    fold_regr, _ = sc.class_fold_counts(y_regr2, folding)\n",
    "    del y_regr2\n",
    "    tasks_regr.aggregation_weight = (fold_regr >= args.min_samples_regr).all(0).astype(np.float64)\n",
    "\n",
    "vprint(f\"Input dimension: {ecfp.shape[1]}\")\n",
    "vprint(f\"#samples:        {ecfp.shape[0]}\")\n",
    "vprint(f\"#classification tasks:  {y_class.shape[1]}\")\n",
    "vprint(f\"#regression tasks:      {y_regr.shape[1]}\")\n",
    "vprint(f\"Using {(tasks_class.aggregation_weight > 0).sum()} classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\")\n",
    "vprint(f\"Using {(tasks_regr.aggregation_weight > 0).sum()} regression tasks for calculating metrics (RMSE, Rsquared, correlation).\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if args.fold_te is not None and args.fold_te >= 0:\n",
    "    ## removing test data\n",
    "    assert args.fold_te != args.fold_va, \"fold_va and fold_te must not be equal.\"\n",
    "    keep    = folding != args.fold_te\n",
    "    ecfp    = ecfp[keep]\n",
    "    y_class = y_class[keep]\n",
    "    y_regr  = y_regr[keep]\n",
    "    y_censor = y_censor[keep]\n",
    "    folding = folding[keep]\n",
    "\n",
    "normalize_inv = None\n",
    "if args.normalize_regression == 1 and args.normalize_regr_va == 1:\n",
    "   y_regr, mean_save, var_save = sc.normalize_regr(y_regr)\n",
    "fold_va = args.fold_va\n",
    "idx_tr  = np.where(folding != fold_va)[0]\n",
    "idx_va  = np.where(folding == fold_va)[0]\n",
    "\n",
    "y_class_tr = y_class[idx_tr]\n",
    "y_class_va = y_class[idx_va]\n",
    "y_regr_tr  = y_regr[idx_tr]\n",
    "y_regr_va  = y_regr[idx_va]\n",
    "y_censor_tr = y_censor[idx_tr]\n",
    "y_censor_va = y_censor[idx_va]\n",
    "\n",
    "if args.normalize_regression == 1 and args.normalize_regr_va == 0:\n",
    "   y_regr_tr, mean_save, var_save = sc.normalize_regr(y_regr_tr) \n",
    "   if args.inverse_normalization == 1:\n",
    "      normalize_inv = {}\n",
    "      normalize_inv[\"mean\"] = mean_save\n",
    "      normalize_inv[\"var\"]  = var_save\n",
    "num_pos_va  = np.array((y_class_va == +1).sum(0)).flatten()\n",
    "num_neg_va  = np.array((y_class_va == -1).sum(0)).flatten()\n",
    "num_regr_va = np.bincount(y_regr_va.indices, minlength=y_regr.shape[1])\n",
    "pos_rate = num_pos_va/(num_pos_va+num_neg_va)\n",
    "pos_rate_ref = args.pi_zero\n",
    "pos_rate = np.clip(pos_rate, 0, 0.99)\n",
    "cal_fact_aucpr = pos_rate*(1-pos_rate_ref)/(pos_rate_ref*(1-pos_rate))\n",
    "#import ipdb; ipdb.set_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e10ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:39.122643Z",
     "start_time": "2022-04-09T15:53:39.093871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension   : 32000\n",
      "Input dimension   : 32000\n",
      "Training dataset  : (14633, 32000)\n",
      "Validation dataset: (3755, 32000)\n",
      "\n",
      "#classification tasks:  15\n",
      "#regression tasks    :      0\n",
      "Using  15 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "Using   0 regression tasks for calculating metrics (RMSE, Rsquared, correlation).\n"
     ]
    }
   ],
   "source": [
    "vprint(f\"Input dimension   : {ecfp.shape[1]}\")\n",
    "vprint(f\"Input dimension   : {ecfp.shape[1]}\")\n",
    "vprint(f\"Training dataset  : {ecfp[idx_tr].shape}\")\n",
    "vprint(f\"Validation dataset: {ecfp[idx_va].shape}\")\n",
    "vprint()\n",
    "vprint(f\"#classification tasks:  {y_class.shape[1]}\")\n",
    "vprint(f\"#regression tasks    :      {y_regr.shape[1]}\")\n",
    "vprint(f\"Using {(tasks_class.aggregation_weight > 0).sum():3d} classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\")\n",
    "vprint(f\"Using {(tasks_regr.aggregation_weight > 0).sum():3d} regression tasks for calculating metrics (RMSE, Rsquared, correlation).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4a5dcd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:39.218524Z",
     "start_time": "2022-04-09T15:53:39.193804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig batch size:   128\n",
      "orig num int batches:   1\n",
      "batch size:   128\n",
      "num_int_batches:   1\n"
     ]
    }
   ],
   "source": [
    "num_int_batches = 1\n",
    "batch_size = 128\n",
    "# batch_size  = int(np.ceil(args.batch_ratio * idx_tr.shape[0]))\n",
    "\n",
    "print(f\"orig batch size:   {batch_size}\")\n",
    "print(f\"orig num int batches:   {num_int_batches}\")\n",
    "\n",
    "if args.internal_batch_max is not None:\n",
    "    if args.internal_batch_max < batch_size:\n",
    "        num_int_batches = int(np.ceil(batch_size / args.internal_batch_max))\n",
    "        batch_size      = int(np.ceil(batch_size / num_int_batches))\n",
    "print(f\"batch size:   {batch_size}\")\n",
    "print(f\"num_int_batches:   {num_int_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4b785ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:39.363403Z",
     "start_time": "2022-04-09T15:53:39.339297Z"
    }
   },
   "outputs": [],
   "source": [
    "tasks_cat_id_list = None\n",
    "select_cat_ids = None\n",
    "if tasks_class.cat_id is not None:\n",
    "    tasks_cat_id_list = [[x,i] for i,x in enumerate(tasks_class.cat_id) if str(x) != 'nan']\n",
    "    tasks_cat_ids = [i for i,x in enumerate(tasks_class.cat_id) if str(x) != 'nan']\n",
    "    select_cat_ids = np.array(tasks_cat_ids)\n",
    "    cat_id_size = len(tasks_cat_id_list)\n",
    "else:\n",
    "    cat_id_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7deb48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "532eab6d",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd9d061d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:40.331516Z",
     "start_time": "2022-04-09T15:53:40.263741Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/leuven/326/vsc32647/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/torch/nn/init.py:388: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "dataset_tr = sc.ClassRegrSparseDataset(x=ecfp[idx_tr], y_class=y_class_tr, y_regr=y_regr_tr, y_censor=y_censor_tr, y_cat_columns=select_cat_ids)\n",
    "dataset_va = sc.ClassRegrSparseDataset(x=ecfp[idx_va], y_class=y_class_va, y_regr=y_regr_va, y_censor=y_censor_va, y_cat_columns=select_cat_ids)\n",
    "\n",
    "loader_tr = DataLoader(dataset_tr, batch_size=batch_size, num_workers = 8, pin_memory=True, collate_fn=dataset_tr.collate, shuffle=True)\n",
    "loader_va = DataLoader(dataset_va, batch_size=batch_size, num_workers = 4, pin_memory=True, collate_fn=dataset_va.collate, shuffle=False)\n",
    "\n",
    "args.input_size  = dataset_tr.input_size\n",
    "args.output_size = dataset_tr.output_size\n",
    "\n",
    "args.class_output_size = dataset_tr.class_output_size\n",
    "args.regr_output_size  = dataset_tr.regr_output_size\n",
    "args.cat_id_size = cat_id_size\n",
    "\n",
    "dev  = torch.device(args.dev)\n",
    "net  = sc.SparseFFN(args).to(dev)\n",
    "loss_class = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "loss_regr  = sc.censored_mse_loss\n",
    "if not args.censored_loss:\n",
    "    loss_regr = functools.partial(loss_regr, censored_enabled=False)\n",
    "\n",
    "tasks_class.training_weight = tasks_class.training_weight.to(dev)\n",
    "tasks_regr.training_weight  = tasks_regr.training_weight.to(dev)\n",
    "tasks_regr.censored_weight  = tasks_regr.censored_weight.to(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e0e180",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29294e00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:41.013747Z",
     "start_time": "2022-04-09T15:53:40.990995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:\n",
      "SparseFFN(\n",
      "  (net): Sequential(\n",
      "    (0): SparseInputNet(\n",
      "      (net_freq): SparseLinear(in_features=32000, out_features=50, bias=True)\n",
      "    )\n",
      "    (1): MiddleNet(\n",
      "      (net): Sequential(\n",
      "        (layer_0): Sequential(\n",
      "          (0): ReLU()\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classLast): LastNet(\n",
      "    (net): Sequential(\n",
      "      (initial_layer): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=50, out_features=15, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (regrLast): Sequential(\n",
      "    (0): LastNet(\n",
      "      (net): Sequential(\n",
      "        (initial_layer): Sequential(\n",
      "          (0): Tanh()\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=50, out_features=0, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vprint(\"Network:\")\n",
    "vprint(net)\n",
    "reporter = None\n",
    "h = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cc2adb",
   "metadata": {},
   "source": [
    "### setup memory profiling reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b500e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:42.831868Z",
     "start_time": "2022-04-09T15:53:42.808045Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.profile == 1:\n",
    "   torch_gpu_id = torch.cuda.current_device()\n",
    "   if \"CUDA_VISIBLE_DEVICES\" in os.environ:\n",
    "      ids = list(map(int, os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"\").split(\",\")))\n",
    "      nvml_gpu_id = ids[torch_gpu_id] # remap\n",
    "   else:\n",
    "      nvml_gpu_id = torch_gpu_id\n",
    "   h = nvmlDeviceGetHandleByIndex(nvml_gpu_id)\n",
    "\n",
    "if args.profile == 1:\n",
    "   #####   output saving   #####\n",
    "   if not os.path.exists(args.output_dir):\n",
    "       os.makedirs(args.output_dir)\n",
    "\n",
    "   reporter = MemReporter(net)\n",
    "\n",
    "   with open(f\"{args.output_dir}/memprofile.txt\", \"w+\") as profile_file:\n",
    "        with redirect_stdout(profile_file):\n",
    "             profile_file.write(f\"\\nInitial model detailed report:\\n\\n\")\n",
    "             reporter.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75bd200",
   "metadata": {},
   "source": [
    "###  Optimizer, Scheduler, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce9acd52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:45.900115Z",
     "start_time": "2022-04-09T15:53:45.875622Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "scheduler = MultiStepLR(optimizer, milestones=args.lr_steps, gamma=args.lr_alpha, verbose = False)\n",
    "scaler    = torch.cuda.amp.GradScaler()\n",
    "num_prints = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e3e87b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:53:45.944481Z",
     "start_time": "2022-04-09T15:53:45.919794Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "dev              :    cpu\n",
      "args.lr          :    0.001\n",
      "args.weight_decay:    0.0001\n",
      "args.lr_steps    :    [10]\n",
      "args.lr_steps    :    [10]\n",
      "num_int_batches  :    1\n",
      "batch_size       :    128\n",
      "EPOCHS           :    100\n",
      "scaler           :    <torch.cuda.amp.grad_scaler.GradScaler object at 0x2b36906286a0>\n",
      "args.normalize_loss    :    None\n",
      "loss_class       :    BCEWithLogitsLoss()\n",
      "mixed precision  :    0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(optimizer)\n",
    "# args.eval_train = 0 \n",
    "# args.epochs     = 5\n",
    "print(f\"dev              :    {dev}\")\n",
    "print(f\"args.lr          :    {args.lr}\")\n",
    "print(f\"args.weight_decay:    {args.weight_decay}\")\n",
    "print(f\"args.lr_steps    :    {args.lr_steps}\")\n",
    "print(f\"args.lr_steps    :    {args.lr_steps}\")\n",
    "print(f\"num_int_batches  :    {num_int_batches}\")\n",
    "print(f\"batch_size       :    {batch_size}\")\n",
    "print(f\"EPOCHS           :    {args.epochs}\")\n",
    "print(f\"scaler           :    {scaler}\")\n",
    "print(f\"args.normalize_loss    :    {args.normalize_loss}\")\n",
    "print(f\"loss_class       :    {loss_class}\")\n",
    "print(f\"mixed precision  :    {args.mixed_precision}\")\n",
    "print(args.eval_train)\n",
    "current_epoch = 0\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682eef3d",
   "metadata": {},
   "source": [
    "###  Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6cc90f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T16:00:50.391210Z",
     "start_time": "2022-04-09T15:53:46.155974Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  |     logl  bceloss   aucroc    aucpr aucpr_cal   f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "0      |  0.51432  0.51432  0.82507  0.82519   0.42370  0.76441 |       nan       nan       nan |    5.3 \n",
      "1      |  0.47294  0.47294  0.85790  0.85838   0.49325  0.78895 |       nan       nan       nan |    1.2 \n",
      "2      |  0.47625  0.47625  0.86483  0.86514   0.50730  0.79516 |       nan       nan       nan |    5.1 \n",
      "3      |  0.49428  0.49428  0.86776  0.86821   0.51476  0.79702 |       nan       nan       nan |    1.4 \n",
      "4      |  0.52146  0.52146  0.86797  0.86829   0.51417  0.79817 |       nan       nan       nan |    1.4 \n",
      "5      |  0.55235  0.55235  0.86930  0.86943   0.51521  0.79893 |       nan       nan       nan |    1.5 \n",
      "6      |  0.58466  0.58466  0.86862  0.86813   0.51119  0.79919 |       nan       nan       nan |    1.2 \n",
      "7      |  0.62153  0.62153  0.86737  0.86742   0.51065  0.79677 |       nan       nan       nan |    1.2 \n",
      "8      |  0.65595  0.65595  0.86746  0.86686   0.50756  0.79706 |       nan       nan       nan |    1.2 \n",
      "9      |  0.68449  0.68449  0.86794  0.86768   0.51093  0.79700 |       nan       nan       nan |    2.7 \n",
      "10     |  0.68682  0.68682  0.86865  0.86816   0.51119  0.79802 |       nan       nan       nan |    1.2 \n",
      "11     |  0.69490  0.69490  0.86892  0.86851   0.51191  0.79821 |       nan       nan       nan |    3.6 \n",
      "12     |  0.70474  0.70474  0.86889  0.86847   0.51175  0.79819 |       nan       nan       nan |    4.4 \n",
      "13     |  0.71504  0.71504  0.86892  0.86846   0.51159  0.79854 |       nan       nan       nan |    3.5 \n",
      "14     |  0.72497  0.72497  0.86870  0.86837   0.51165  0.79820 |       nan       nan       nan |    2.2 \n",
      "15     |  0.73435  0.73435  0.86885  0.86835   0.51105  0.79869 |       nan       nan       nan |    1.8 \n",
      "16     |  0.74609  0.74609  0.86866  0.86824   0.51121  0.79810 |       nan       nan       nan |    2.6 \n",
      "17     |  0.75652  0.75652  0.86866  0.86822   0.51119  0.79834 |       nan       nan       nan |    1.4 \n",
      "18     |  0.76889  0.76889  0.86860  0.86821   0.51106  0.79834 |       nan       nan       nan |    5.1 \n",
      "19     |  0.77997  0.77997  0.86835  0.86807   0.51118  0.79776 |       nan       nan       nan |    1.2 \n",
      "Epoch  |     logl  bceloss   aucroc    aucpr aucpr_cal   f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "20     |  0.79046  0.79046  0.86809  0.86783   0.51020  0.79795 |       nan       nan       nan |    1.1 \n",
      "21     |  0.80026  0.80026  0.86843  0.86811   0.51076  0.79821 |       nan       nan       nan |    5.7 \n",
      "22     |  0.80921  0.80921  0.86832  0.86816   0.51135  0.79814 |       nan       nan       nan |    1.3 \n",
      "23     |  0.81987  0.81987  0.86828  0.86793   0.51015  0.79770 |       nan       nan       nan |    5.3 \n",
      "24     |  0.83112  0.83112  0.86831  0.86806   0.51086  0.79812 |       nan       nan       nan |    8.5 \n",
      "25     |  0.84161  0.84161  0.86822  0.86810   0.51127  0.79747 |       nan       nan       nan |    1.2 \n",
      "26     |  0.85043  0.85043  0.86822  0.86781   0.50994  0.79756 |       nan       nan       nan |    1.6 \n",
      "27     |  0.86134  0.86134  0.86786  0.86776   0.51046  0.79777 |       nan       nan       nan |    3.8 \n",
      "28     |  0.86925  0.86925  0.86803  0.86772   0.50935  0.79766 |       nan       nan       nan |    2.9 \n",
      "29     |  0.87910  0.87910  0.86797  0.86777   0.51033  0.79793 |       nan       nan       nan |    4.8 \n",
      "30     |  0.88757  0.88757  0.86804  0.86800   0.51119  0.79743 |       nan       nan       nan |    7.5 \n",
      "31     |  0.90089  0.90089  0.86766  0.86769   0.51070  0.79744 |       nan       nan       nan |    1.8 \n",
      "32     |  0.90600  0.90600  0.86786  0.86771   0.51007  0.79801 |       nan       nan       nan |    2.7 \n",
      "33     |  0.91551  0.91551  0.86794  0.86778   0.51015  0.79772 |       nan       nan       nan |    2.7 \n",
      "34     |  0.92446  0.92446  0.86777  0.86767   0.51018  0.79769 |       nan       nan       nan |    8.3 \n",
      "35     |  0.92905  0.92905  0.86795  0.86794   0.51090  0.79786 |       nan       nan       nan |    3.9 \n",
      "36     |  0.94338  0.94338  0.86754  0.86745   0.50985  0.79750 |       nan       nan       nan |    5.0 \n",
      "37     |  0.94784  0.94784  0.86768  0.86776   0.51113  0.79768 |       nan       nan       nan |    2.6 \n",
      "38     |  0.95866  0.95866  0.86744  0.86757   0.51065  0.79729 |       nan       nan       nan |    3.4 \n",
      "39     |  0.96464  0.96464  0.86742  0.86738   0.50934  0.79744 |       nan       nan       nan |    1.7 \n",
      "Epoch  |     logl  bceloss   aucroc    aucpr aucpr_cal   f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "40     |  0.97234  0.97234  0.86727  0.86737   0.51000  0.79751 |       nan       nan       nan |    3.5 \n",
      "41     |  0.97636  0.97636  0.86760  0.86779   0.51113  0.79786 |       nan       nan       nan |    6.2 \n",
      "42     |  0.98290  0.98290  0.86767  0.86772   0.51061  0.79752 |       nan       nan       nan |   10.0 \n",
      "43     |  0.98820  0.98820  0.86770  0.86783   0.51119  0.79735 |       nan       nan       nan |    1.4 \n",
      "44     |  0.99920  0.99920  0.86745  0.86757   0.51065  0.79740 |       nan       nan       nan |    1.2 \n",
      "45     |  1.00874  1.00874  0.86725  0.86745   0.51035  0.79747 |       nan       nan       nan |    9.9 \n",
      "46     |  1.02057  1.02057  0.86699  0.86734   0.51070  0.79702 |       nan       nan       nan |   11.1 \n",
      "47     |  1.02278  1.02278  0.86720  0.86735   0.51017  0.79743 |       nan       nan       nan |    1.2 \n",
      "48     |  1.02940  1.02940  0.86688  0.86704   0.50925  0.79686 |       nan       nan       nan |    3.9 \n",
      "49     |  1.03378  1.03378  0.86726  0.86751   0.51052  0.79737 |       nan       nan       nan |    1.1 \n",
      "50     |  1.04247  1.04247  0.86708  0.86714   0.50969  0.79688 |       nan       nan       nan |    1.3 \n",
      "51     |  1.04731  1.04731  0.86695  0.86727   0.51056  0.79686 |       nan       nan       nan |    4.6 \n",
      "52     |  1.04981  1.04981  0.86732  0.86776   0.51176  0.79719 |       nan       nan       nan |    2.2 \n",
      "53     |  1.05494  1.05494  0.86721  0.86750   0.51124  0.79734 |       nan       nan       nan |    2.0 \n",
      "54     |  1.06208  1.06208  0.86737  0.86790   0.51284  0.79717 |       nan       nan       nan |    1.2 \n",
      "55     |  1.07055  1.07055  0.86702  0.86747   0.51134  0.79696 |       nan       nan       nan |    9.3 \n",
      "56     |  1.07038  1.07038  0.86726  0.86760   0.51148  0.79715 |       nan       nan       nan |    6.3 \n",
      "57     |  1.07441  1.07441  0.86728  0.86772   0.51220  0.79738 |       nan       nan       nan |    1.4 \n",
      "58     |  1.08292  1.08292  0.86710  0.86750   0.51147  0.79741 |       nan       nan       nan |    7.5 \n",
      "59     |  1.09048  1.09048  0.86714  0.86751   0.51151  0.79726 |       nan       nan       nan |    8.1 \n",
      "Epoch  |     logl  bceloss   aucroc    aucpr aucpr_cal   f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "60     |  1.09158  1.09158  0.86732  0.86777   0.51203  0.79769 |       nan       nan       nan |    7.7 \n",
      "61     |  1.09563  1.09563  0.86739  0.86773   0.51150  0.79748 |       nan       nan       nan |    8.1 \n",
      "62     |  1.10740  1.10740  0.86664  0.86735   0.51183  0.79678 |       nan       nan       nan |    7.7 \n",
      "63     |  1.10683  1.10683  0.86716  0.86768   0.51210  0.79713 |       nan       nan       nan |    4.1 \n",
      "64     |  1.11531  1.11531  0.86709  0.86726   0.51012  0.79732 |       nan       nan       nan |    6.7 \n",
      "65     |  1.12182  1.12182  0.86660  0.86686   0.50878  0.79710 |       nan       nan       nan |    1.5 \n",
      "66     |  1.12320  1.12320  0.86699  0.86752   0.51170  0.79695 |       nan       nan       nan |    2.8 \n",
      "67     |  1.13206  1.13206  0.86644  0.86718   0.51140  0.79635 |       nan       nan       nan |    9.2 \n",
      "68     |  1.13873  1.13873  0.86653  0.86708   0.51085  0.79683 |       nan       nan       nan |    2.4 \n",
      "69     |  1.14214  1.14214  0.86653  0.86713   0.51085  0.79674 |       nan       nan       nan |    1.4 \n",
      "70     |  1.14592  1.14592  0.86633  0.86710   0.51146  0.79651 |       nan       nan       nan |    1.3 \n",
      "71     |  1.14655  1.14655  0.86659  0.86708   0.51033  0.79691 |       nan       nan       nan |    1.9 \n",
      "72     |  1.15746  1.15746  0.86635  0.86684   0.50980  0.79619 |       nan       nan       nan |    1.6 \n",
      "73     |  1.16184  1.16184  0.86612  0.86680   0.51034  0.79638 |       nan       nan       nan |    1.2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74     |  1.16436  1.16436  0.86659  0.86735   0.51189  0.79634 |       nan       nan       nan |    1.4 \n",
      "75     |  1.16691  1.16691  0.86618  0.86726   0.51265  0.79632 |       nan       nan       nan |    2.5 \n",
      "76     |  1.17256  1.17256  0.86640  0.86705   0.51132  0.79680 |       nan       nan       nan |    1.3 \n",
      "77     |  1.17364  1.17364  0.86643  0.86732   0.51234  0.79624 |       nan       nan       nan |    2.4 \n",
      "78     |  1.18231  1.18231  0.86650  0.86710   0.51106  0.79615 |       nan       nan       nan |    1.3 \n",
      "79     |  1.18620  1.18620  0.86615  0.86699   0.51178  0.79589 |       nan       nan       nan |    1.4 \n",
      "Epoch  |     logl  bceloss   aucroc    aucpr aucpr_cal   f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "80     |  1.18848  1.18848  0.86625  0.86698   0.51096  0.79674 |       nan       nan       nan |    1.3 \n",
      "81     |  1.18894  1.18894  0.86625  0.86686   0.51045  0.79641 |       nan       nan       nan |    2.7 \n",
      "82     |  1.19186  1.19186  0.86670  0.86730   0.51162  0.79670 |       nan       nan       nan |    1.2 \n",
      "83     |  1.20068  1.20068  0.86613  0.86680   0.51036  0.79622 |       nan       nan       nan |    4.0 \n",
      "84     |  1.20278  1.20278  0.86621  0.86701   0.51107  0.79600 |       nan       nan       nan |    1.3 \n",
      "85     |  1.20773  1.20773  0.86611  0.86660   0.50916  0.79627 |       nan       nan       nan |    1.8 \n",
      "86     |  1.21199  1.21199  0.86602  0.86658   0.50949  0.79617 |       nan       nan       nan |    1.3 \n",
      "87     |  1.21608  1.21608  0.86600  0.86654   0.50913  0.79650 |       nan       nan       nan |    1.6 \n",
      "88     |  1.22012  1.22012  0.86604  0.86661   0.50941  0.79643 |       nan       nan       nan |    4.2 \n",
      "89     |  1.22065  1.22065  0.86611  0.86673   0.50973  0.79623 |       nan       nan       nan |    1.3 \n",
      "90     |  1.22926  1.22926  0.86600  0.86676   0.51042  0.79631 |       nan       nan       nan |    1.9 \n",
      "91     |  1.23588  1.23588  0.86571  0.86627   0.50881  0.79604 |       nan       nan       nan |    2.4 \n",
      "92     |  1.23256  1.23256  0.86642  0.86720   0.51178  0.79639 |       nan       nan       nan |    2.4 \n",
      "93     |  1.23778  1.23778  0.86594  0.86679   0.51089  0.79641 |       nan       nan       nan |    2.8 \n",
      "94     |  1.23822  1.23822  0.86597  0.86675   0.51029  0.79627 |       nan       nan       nan |    1.8 \n",
      "95     |  1.24357  1.24357  0.86590  0.86673   0.51093  0.79601 |       nan       nan       nan |    4.6 \n",
      "96     |  1.24717  1.24717  0.86611  0.86696   0.51113  0.79622 |       nan       nan       nan |    2.1 \n",
      "97     |  1.25178  1.25178  0.86579  0.86662   0.51055  0.79609 |       nan       nan       nan |    3.6 \n",
      "98     |  1.25236  1.25236  0.86603  0.86714   0.51260  0.79640 |       nan       nan       nan |    5.6 \n",
      "99     |  1.25420  1.25420  0.86611  0.86709   0.51208  0.79678 |       nan       nan       nan |    3.8 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "end_epoch = current_epoch + args.epochs\n",
    "\n",
    "for epoch in range(current_epoch, end_epoch, 1):\n",
    "    t0 = time.time()\n",
    "    sc.train_class_regr(\n",
    "        net, optimizer,\n",
    "        loader          = loader_tr,\n",
    "        loss_class      = loss_class,\n",
    "        loss_regr       = loss_regr,\n",
    "        dev             = dev,\n",
    "        weights_class   = tasks_class.training_weight * (1-args.regression_weight) * 2,\n",
    "        weights_regr    = tasks_regr.training_weight * args.regression_weight * 2,\n",
    "        censored_weight = tasks_regr.censored_weight,\n",
    "        normalize_loss  = args.normalize_loss,\n",
    "        num_int_batches = num_int_batches,\n",
    "        progress        = False,\n",
    "        reporter        = reporter,\n",
    "        writer          = writer,\n",
    "        epoch           = epoch,\n",
    "        args            = args,\n",
    "        scaler          = scaler)\n",
    "#         nvml_handle     = h)\n",
    "\n",
    "    if args.profile == 1:\n",
    "       with open(f\"{args.output_dir}/memprofile.txt\", \"a+\") as profile_file:\n",
    "            profile_file.write(f\"\\nAfter epoch {epoch} model detailed report:\\n\\n\")\n",
    "            with redirect_stdout(profile_file):\n",
    "                 reporter.report()\n",
    "\n",
    "    t1 = time.time()\n",
    "    eval_round = (args.eval_frequency > 0) and ((epoch + 1) % args.eval_frequency == 0)\n",
    "    last_round = epoch == args.epochs - 1\n",
    "\n",
    "    if eval_round or last_round:\n",
    "\n",
    "        results_va = sc.evaluate_class_regr(net, loader_va, \n",
    "                                            loss_class, \n",
    "                                            loss_regr, \n",
    "                                            tasks_class=tasks_class, \n",
    "                                            tasks_regr=tasks_regr, \n",
    "                                            dev=dev, \n",
    "                                            progress = False, \n",
    "                                            normalize_inv=normalize_inv, \n",
    "                                            cal_fact_aucpr=cal_fact_aucpr)\n",
    "   #     import ipdb; ipdb.set_trace()\n",
    "        for key, val in results_va[\"classification_agg\"].items():\n",
    "            writer.add_scalar(\"val_metrics:aggregated/\"+key, val, epoch*batch_size)\n",
    "            \n",
    "#             writer.add_scalar(key+\"/va\", val, epoch)            \n",
    "#         for key, val in results_va[\"regression_agg\"].items():\n",
    "#             writer.add_scalar(key+\"/va\", val, epoch)\n",
    "\n",
    "            \n",
    "        if args.eval_train:\n",
    "            results_tr = sc.evaluate_class_regr(net, loader_tr, loss_class, loss_regr, tasks_class=tasks_class, tasks_regr=tasks_regr, dev=dev, progress = args.verbose >= 2)\n",
    "            for key, val in results_tr[\"classification_agg\"].items():\n",
    "                writer.add_scalar(\"trn_metrics:aggregated/\"+key, val, epoch *batch_size)                \n",
    "\n",
    "#                 writer.add_scalar(key+\"/tr\", val, epoch)\n",
    "#             for key, val in results_tr[\"regression_agg\"].items():\n",
    "#                 writer.add_scalar(key+\"/tr\", val, epoch)\n",
    "        else:\n",
    "            results_tr = None\n",
    "        if args.verbose:\n",
    "            ## printing a new header every 20 lines\n",
    "            header = num_prints % 20 == 0\n",
    "            num_prints += 1\n",
    "            sc.print_metrics_cr(epoch, t1 - t0, results_tr, results_va, header)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "#print(\"DEBUG data for hidden spliting\")\n",
    "#print (f\"Classification mask: Sum = {net.classmask.sum()}\\t Uniques: {np.unique(net.classmask)}\")\n",
    "#print (f\"Regression mask:     Sum = {net.regmask.sum()}\\t Uniques: {np.unique(net.regmask)}\")\n",
    "#print (f\"overlap: {(net.regmask * net.classmask).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3043743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T16:00:50.754632Z",
     "start_time": "2022-04-09T16:00:50.393113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da364148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T16:00:50.778537Z",
     "start_time": "2022-04-09T16:00:50.755746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf85dd52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93247874",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T16:00:50.800483Z",
     "start_time": "2022-04-09T16:00:50.779989Z"
    }
   },
   "outputs": [],
   "source": [
    "results_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6a5b742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T16:00:50.856154Z",
     "start_time": "2022-04-09T16:00:50.801672Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving performance metrics (AUCs) and model.\n",
      "Saved model weights into '../experiments/synt-SparseChem/0409_1753/sc_50.50_lr0.001_do0.0.pt'.\n",
      "Saved config and results into '../experiments/synt-SparseChem/0409_1753/sc_50.50_lr0.001_do0.0.json'.\n",
      "You can load the results by:\n",
      "  import sparsechem as sc\n",
      "  res = sc.load_results('../experiments/synt-SparseChem/0409_1753/sc_50.50_lr0.001_do0.0.json')\n"
     ]
    }
   ],
   "source": [
    "writer.close()\n",
    "vprint()\n",
    "if args.profile == 1:\n",
    "   multiplexer = sc.create_multiplexer(tb_name)\n",
    "#   sc.export_scalars(multiplexer, '.', \"GPUmem\", \"testcsv.csv\")\n",
    "   data = sc.extract_scalars(multiplexer, '.', \"GPUmem\")\n",
    "   vprint(f\"Peak GPU memory used: {sc.return_max_val(data)}MB\")\n",
    "\n",
    "\n",
    "vprint(\"Saving performance metrics (AUCs) and model.\")\n",
    "\n",
    "#####   model saving   #####\n",
    "if not os.path.exists(args.output_dir):\n",
    "   os.makedirs(args.output_dir)\n",
    "\n",
    "model_file = f\"{args.output_dir}/{name}.pt\"\n",
    "out_file   = f\"{args.output_dir}/{name}.json\"\n",
    "\n",
    "if args.save_model:\n",
    "   torch.save(net.state_dict(), model_file)\n",
    "   vprint(f\"Saved model weights into '{model_file}'.\")\n",
    "\n",
    "results_va[\"classification\"][\"num_pos\"] = num_pos_va\n",
    "results_va[\"classification\"][\"num_neg\"] = num_neg_va\n",
    "results_va[\"regression\"][\"num_samples\"] = num_regr_va\n",
    "\n",
    "if results_tr is not None:\n",
    "    results_tr[\"classification\"][\"num_pos\"] = num_pos - num_pos_va\n",
    "    results_tr[\"classification\"][\"num_neg\"] = num_neg - num_neg_va\n",
    "    results_tr[\"regression\"][\"num_samples\"] = num_regr - num_regr_va\n",
    "\n",
    "stats=None\n",
    "if args.normalize_regression == 1 :\n",
    "   stats={}\n",
    "   stats[\"mean\"] = mean_save\n",
    "   stats[\"var\"]  = np.array(var_save)[0]\n",
    "\n",
    "\n",
    "sc.save_results(out_file, args, validation=results_va, training=results_tr, stats=stats)\n",
    "\n",
    "vprint(f\"Saved config and results into '{out_file}'.\\nYou can load the results by:\\n  import sparsechem as sc\\n  res = sc.load_results('{out_file}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1468a4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b3bfa0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T16:00:50.890609Z",
     "start_time": "2022-04-09T16:00:50.857455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.885874  0.871041        0.871098  0.807054  0.168322  0.606809   \n",
      "1          0.888604  0.887446        0.887491  0.809677  0.062541  0.598409   \n",
      "2          0.854575  0.879469        0.879512  0.812050  0.033761  0.551145   \n",
      "3          0.862605  0.845979        0.846067  0.788917  0.152042  0.563402   \n",
      "4          0.878554  0.888349        0.888389  0.817576  0.214644  0.600783   \n",
      "5          0.881924  0.887073        0.887113  0.815473  0.066836  0.583941   \n",
      "6          0.834998  0.814079        0.814156  0.759245  0.046447  0.514217   \n",
      "7          0.855126  0.842711        0.842787  0.776418  0.037014  0.555036   \n",
      "8          0.848646  0.867646        0.867698  0.788732  0.027189  0.523724   \n",
      "9          0.865716  0.857817        0.857870  0.775096  0.290136  0.555437   \n",
      "10         0.869513  0.890414        0.890454  0.820114  0.074026  0.569095   \n",
      "11         0.872135  0.872236        0.872292  0.798886  0.312345  0.579529   \n",
      "12         0.869628  0.884085        0.884127  0.801551  0.058037  0.571864   \n",
      "13         0.857332  0.857497        0.857570  0.790885  0.018523  0.544231   \n",
      "14         0.866399  0.860555        0.860607  0.790075  0.040073  0.561734   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  auc_pr_cal  num_pos  num_neg  \n",
      "task                                                                  \n",
      "0      0.610906     0.168322  1.157830    0.532272     1788     1967  \n",
      "1      0.603688     0.410355  1.112738    0.560550     1888     1867  \n",
      "2      0.555409     0.323903  1.324167    0.506223     2075     1680  \n",
      "3      0.570734     0.822630  1.282155    0.442472     1852     1903  \n",
      "4      0.604704     0.228804  1.229244    0.559041     1947     1808  \n",
      "5      0.594826     0.741122  1.142968    0.550827     1942     1813  \n",
      "6      0.521653     0.330692  1.489743    0.453869     1725     2030  \n",
      "7      0.558803     0.615658  1.373351    0.470887     1795     1960  \n",
      "8      0.529765     0.776051  1.377021    0.490173     2004     1751  \n",
      "9      0.569176     0.921360  1.233573    0.539993     1762     1993  \n",
      "10     0.580322     0.322273  1.157847    0.514404     2098     1657  \n",
      "11     0.584428     0.592117  1.171810    0.516270     1901     1854  \n",
      "12     0.578773     0.620852  1.267797    0.554900     1958     1797  \n",
      "13     0.552983     0.334732  1.297207    0.468011     1909     1846  \n",
      "14     0.565494     0.670994  1.195607    0.521239     1828     1927  ,\n",
      "    'classification_agg': roc_auc_score       0.866109\n",
      "auc_pr              0.867093\n",
      "avg_prec_score      0.867149\n",
      "f1_max              0.796783\n",
      "p_f1_max            0.106796\n",
      "kappa               0.565290\n",
      "kappa_max           0.572111\n",
      "p_kappa_max         0.525324\n",
      "bceloss             1.254204\n",
      "auc_pr_cal          0.512075\n",
      "logloss             1.254204\n",
      "num_tasks_total    15.000000\n",
      "num_tasks_agg      15.000000\n",
      "dtype: float64,\n",
      "    'regression': Empty DataFrame\n",
      "Columns: [rmse, rmse_uncen, rsquared, corrcoef, num_samples]\n",
      "Index: [],\n",
      "    'regression_agg': rmse               NaN\n",
      "rmse_uncen         NaN\n",
      "rsquared           NaN\n",
      "corrcoef           NaN\n",
      "mseloss            NaN\n",
      "num_tasks_total    0.0\n",
      "num_tasks_agg      0.0\n",
      "dtype: float64}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(results_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0737937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T16:00:50.921328Z",
     "start_time": "2022-04-09T16:00:50.891617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>avg_prec_score</th>\n",
       "      <th>f1_max</th>\n",
       "      <th>p_f1_max</th>\n",
       "      <th>kappa</th>\n",
       "      <th>kappa_max</th>\n",
       "      <th>p_kappa_max</th>\n",
       "      <th>bceloss</th>\n",
       "      <th>auc_pr_cal</th>\n",
       "      <th>num_pos</th>\n",
       "      <th>num_neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.885874</td>\n",
       "      <td>0.871041</td>\n",
       "      <td>0.871098</td>\n",
       "      <td>0.807054</td>\n",
       "      <td>0.168322</td>\n",
       "      <td>0.606809</td>\n",
       "      <td>0.610906</td>\n",
       "      <td>0.168322</td>\n",
       "      <td>1.157830</td>\n",
       "      <td>0.532272</td>\n",
       "      <td>1788</td>\n",
       "      <td>1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888604</td>\n",
       "      <td>0.887446</td>\n",
       "      <td>0.887491</td>\n",
       "      <td>0.809677</td>\n",
       "      <td>0.062541</td>\n",
       "      <td>0.598409</td>\n",
       "      <td>0.603688</td>\n",
       "      <td>0.410355</td>\n",
       "      <td>1.112738</td>\n",
       "      <td>0.560550</td>\n",
       "      <td>1888</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.854575</td>\n",
       "      <td>0.879469</td>\n",
       "      <td>0.879512</td>\n",
       "      <td>0.812050</td>\n",
       "      <td>0.033761</td>\n",
       "      <td>0.551145</td>\n",
       "      <td>0.555409</td>\n",
       "      <td>0.323903</td>\n",
       "      <td>1.324167</td>\n",
       "      <td>0.506223</td>\n",
       "      <td>2075</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.862605</td>\n",
       "      <td>0.845979</td>\n",
       "      <td>0.846067</td>\n",
       "      <td>0.788917</td>\n",
       "      <td>0.152042</td>\n",
       "      <td>0.563402</td>\n",
       "      <td>0.570734</td>\n",
       "      <td>0.822630</td>\n",
       "      <td>1.282155</td>\n",
       "      <td>0.442472</td>\n",
       "      <td>1852</td>\n",
       "      <td>1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.878554</td>\n",
       "      <td>0.888349</td>\n",
       "      <td>0.888389</td>\n",
       "      <td>0.817576</td>\n",
       "      <td>0.214644</td>\n",
       "      <td>0.600783</td>\n",
       "      <td>0.604704</td>\n",
       "      <td>0.228804</td>\n",
       "      <td>1.229244</td>\n",
       "      <td>0.559041</td>\n",
       "      <td>1947</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.881924</td>\n",
       "      <td>0.887073</td>\n",
       "      <td>0.887113</td>\n",
       "      <td>0.815473</td>\n",
       "      <td>0.066836</td>\n",
       "      <td>0.583941</td>\n",
       "      <td>0.594826</td>\n",
       "      <td>0.741122</td>\n",
       "      <td>1.142968</td>\n",
       "      <td>0.550827</td>\n",
       "      <td>1942</td>\n",
       "      <td>1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.834998</td>\n",
       "      <td>0.814079</td>\n",
       "      <td>0.814156</td>\n",
       "      <td>0.759245</td>\n",
       "      <td>0.046447</td>\n",
       "      <td>0.514217</td>\n",
       "      <td>0.521653</td>\n",
       "      <td>0.330692</td>\n",
       "      <td>1.489743</td>\n",
       "      <td>0.453869</td>\n",
       "      <td>1725</td>\n",
       "      <td>2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.855126</td>\n",
       "      <td>0.842711</td>\n",
       "      <td>0.842787</td>\n",
       "      <td>0.776418</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.555036</td>\n",
       "      <td>0.558803</td>\n",
       "      <td>0.615658</td>\n",
       "      <td>1.373351</td>\n",
       "      <td>0.470887</td>\n",
       "      <td>1795</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.848646</td>\n",
       "      <td>0.867646</td>\n",
       "      <td>0.867698</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.523724</td>\n",
       "      <td>0.529765</td>\n",
       "      <td>0.776051</td>\n",
       "      <td>1.377021</td>\n",
       "      <td>0.490173</td>\n",
       "      <td>2004</td>\n",
       "      <td>1751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.865716</td>\n",
       "      <td>0.857817</td>\n",
       "      <td>0.857870</td>\n",
       "      <td>0.775096</td>\n",
       "      <td>0.290136</td>\n",
       "      <td>0.555437</td>\n",
       "      <td>0.569176</td>\n",
       "      <td>0.921360</td>\n",
       "      <td>1.233573</td>\n",
       "      <td>0.539993</td>\n",
       "      <td>1762</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.869513</td>\n",
       "      <td>0.890414</td>\n",
       "      <td>0.890454</td>\n",
       "      <td>0.820114</td>\n",
       "      <td>0.074026</td>\n",
       "      <td>0.569095</td>\n",
       "      <td>0.580322</td>\n",
       "      <td>0.322273</td>\n",
       "      <td>1.157847</td>\n",
       "      <td>0.514404</td>\n",
       "      <td>2098</td>\n",
       "      <td>1657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.872135</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>0.872292</td>\n",
       "      <td>0.798886</td>\n",
       "      <td>0.312345</td>\n",
       "      <td>0.579529</td>\n",
       "      <td>0.584428</td>\n",
       "      <td>0.592117</td>\n",
       "      <td>1.171810</td>\n",
       "      <td>0.516270</td>\n",
       "      <td>1901</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.869628</td>\n",
       "      <td>0.884085</td>\n",
       "      <td>0.884127</td>\n",
       "      <td>0.801551</td>\n",
       "      <td>0.058037</td>\n",
       "      <td>0.571864</td>\n",
       "      <td>0.578773</td>\n",
       "      <td>0.620852</td>\n",
       "      <td>1.267797</td>\n",
       "      <td>0.554900</td>\n",
       "      <td>1958</td>\n",
       "      <td>1797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.857332</td>\n",
       "      <td>0.857497</td>\n",
       "      <td>0.857570</td>\n",
       "      <td>0.790885</td>\n",
       "      <td>0.018523</td>\n",
       "      <td>0.544231</td>\n",
       "      <td>0.552983</td>\n",
       "      <td>0.334732</td>\n",
       "      <td>1.297207</td>\n",
       "      <td>0.468011</td>\n",
       "      <td>1909</td>\n",
       "      <td>1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.866399</td>\n",
       "      <td>0.860555</td>\n",
       "      <td>0.860607</td>\n",
       "      <td>0.790075</td>\n",
       "      <td>0.040073</td>\n",
       "      <td>0.561734</td>\n",
       "      <td>0.565494</td>\n",
       "      <td>0.670994</td>\n",
       "      <td>1.195607</td>\n",
       "      <td>0.521239</td>\n",
       "      <td>1828</td>\n",
       "      <td>1927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
       "task                                                                          \n",
       "0          0.885874  0.871041        0.871098  0.807054  0.168322  0.606809   \n",
       "1          0.888604  0.887446        0.887491  0.809677  0.062541  0.598409   \n",
       "2          0.854575  0.879469        0.879512  0.812050  0.033761  0.551145   \n",
       "3          0.862605  0.845979        0.846067  0.788917  0.152042  0.563402   \n",
       "4          0.878554  0.888349        0.888389  0.817576  0.214644  0.600783   \n",
       "5          0.881924  0.887073        0.887113  0.815473  0.066836  0.583941   \n",
       "6          0.834998  0.814079        0.814156  0.759245  0.046447  0.514217   \n",
       "7          0.855126  0.842711        0.842787  0.776418  0.037014  0.555036   \n",
       "8          0.848646  0.867646        0.867698  0.788732  0.027189  0.523724   \n",
       "9          0.865716  0.857817        0.857870  0.775096  0.290136  0.555437   \n",
       "10         0.869513  0.890414        0.890454  0.820114  0.074026  0.569095   \n",
       "11         0.872135  0.872236        0.872292  0.798886  0.312345  0.579529   \n",
       "12         0.869628  0.884085        0.884127  0.801551  0.058037  0.571864   \n",
       "13         0.857332  0.857497        0.857570  0.790885  0.018523  0.544231   \n",
       "14         0.866399  0.860555        0.860607  0.790075  0.040073  0.561734   \n",
       "\n",
       "      kappa_max  p_kappa_max   bceloss  auc_pr_cal  num_pos  num_neg  \n",
       "task                                                                  \n",
       "0      0.610906     0.168322  1.157830    0.532272     1788     1967  \n",
       "1      0.603688     0.410355  1.112738    0.560550     1888     1867  \n",
       "2      0.555409     0.323903  1.324167    0.506223     2075     1680  \n",
       "3      0.570734     0.822630  1.282155    0.442472     1852     1903  \n",
       "4      0.604704     0.228804  1.229244    0.559041     1947     1808  \n",
       "5      0.594826     0.741122  1.142968    0.550827     1942     1813  \n",
       "6      0.521653     0.330692  1.489743    0.453869     1725     2030  \n",
       "7      0.558803     0.615658  1.373351    0.470887     1795     1960  \n",
       "8      0.529765     0.776051  1.377021    0.490173     2004     1751  \n",
       "9      0.569176     0.921360  1.233573    0.539993     1762     1993  \n",
       "10     0.580322     0.322273  1.157847    0.514404     2098     1657  \n",
       "11     0.584428     0.592117  1.171810    0.516270     1901     1854  \n",
       "12     0.578773     0.620852  1.267797    0.554900     1958     1797  \n",
       "13     0.552983     0.334732  1.297207    0.468011     1909     1846  \n",
       "14     0.565494     0.670994  1.195607    0.521239     1828     1927  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_va['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e97f62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fc641c6",
   "metadata": {},
   "source": [
    "## Results of run on synthetic data \n",
    "    Run name is 'sc_run_\n",
    "    h40.40_\n",
    "    ldo_r_wd0.0001_\n",
    "    lr0.001_\n",
    "    lrsteps10_\n",
    "    ep20_\n",
    "    fva0_fteNone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ae03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "19     |  0.64258  0.64258  0.86670  0.86844   0.51818  0.79627 |       nan       nan       nan |    1.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f1b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a565db43",
   "metadata": {},
   "source": [
    "## Results of run on synthetic data \n",
    "    Run name is 'sc_run_\n",
    "    h400.400_\n",
    "    ldo_r_wd0.0001_\n",
    "    lr0.001_\n",
    "    lrsteps10_\n",
    "    ep20_\n",
    "    fva: 0 fte: None'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c525e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch  |     logl  bceloss   aucroc    aucpr aucpr_cal   f1_max |      rmse  rsquared  corrcoef | tr_time \n",
    "\n",
    "0      |  0.34269  0.45776  0.80664  0.72646   0.48133  0.74813 |       nan       nan       nan |   13.6 \n",
    "1      |  0.31554  0.42048  0.83178  0.75306   0.51796  0.76370 |       nan       nan       nan |   12.9 \n",
    "2      |  0.31272  0.41163  0.84092  0.76037   0.53157  0.76873 |       nan       nan       nan |   12.8 \n",
    "3      |  0.31439  0.41333  0.84125  0.76524   0.53492  0.77030 |       nan       nan       nan |   12.9 \n",
    "4      |  0.31480  0.41191  0.84390  0.76670   0.53815  0.77059 |       nan       nan       nan |   12.8 \n",
    "5      |  0.31809  0.41840  0.84434  0.76798   0.53912  0.77124 |       nan       nan       nan |   12.9 \n",
    "6      |  0.32237  0.42103  0.84506  0.76737   0.53627  0.77180 |       nan       nan       nan |   12.9 \n",
    "7      |  0.32203  0.42055  0.84465  0.76600   0.53617  0.77124 |       nan       nan       nan |   13.1 \n",
    "8      |  0.32931  0.43144  0.84398  0.76671   0.53747  0.77013 |       nan       nan       nan |   13.1 \n",
    "9      |  0.33162  0.42992  0.84499  0.76793   0.53587  0.77157 |       nan       nan       nan |   13.1 \n",
    "10     |  0.32617  0.42194  0.84909  0.77293   0.54663  0.77418 |       nan       nan       nan |   13.0 \n",
    "11     |  0.32782  0.42469  0.84891  0.77210   0.54406  0.77411 |       nan       nan       nan |   12.9 \n",
    "12     |  0.33080  0.42809  0.84897  0.77252   0.54445  0.77391 |       nan       nan       nan |   12.9 \n",
    "13     |  0.33451  0.43235  0.84840  0.77160   0.54306  0.77383 |       nan       nan       nan |   13.1 \n",
    "14     |  0.33882  0.43660  0.84832  0.77141   0.54322  0.77295 |       nan       nan       nan |   13.1 \n",
    "15     |  0.34108  0.43973  0.84803  0.77172   0.54287  0.77311 |       nan       nan       nan |   13.1 \n",
    "16     |  0.34506  0.44437  0.84782  0.77086   0.54190  0.77230 |       nan       nan       nan |   13.0 \n",
    "17     |  0.34866  0.44951  0.84697  0.77017   0.54043  0.77185 |       nan       nan       nan |   13.0 \n",
    "18     |  0.35135  0.45143  0.84740  0.77087   0.54130  0.77260 |       nan       nan       nan |   13.0 \n",
    "19     |  0.35432  0.45495  0.84742  0.77097   0.54075  0.77233 |       nan       nan       nan |   13.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8bf121",
   "metadata": {},
   "source": [
    "## Results of run on synthetic data \n",
    "    Run name is 'sc_run_\n",
    "    h400.400_\n",
    "    ldo_r_wd0.0001_\n",
    "    lr0.001_\n",
    "    lrsteps10_\n",
    "    ep20_\n",
    "    fva: 0 fte: None'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch  |     logl  bceloss   aucroc    aucpr aucpr_cal   f1_max |      rmse  rsquared  corrcoef | tr_time \n",
    "0      |  0.48793  0.48793  0.84856  0.84747   0.46481  0.78310 |       nan       nan       nan |    6.8 \n",
    "1      |  0.50662  0.50662  0.86016  0.86280   0.50705  0.79179 |       nan       nan       nan |    5.8 \n",
    "2      |  0.57006  0.57006  0.86303  0.86548   0.51272  0.79318 |       nan       nan       nan |    5.9 \n",
    "3      |  0.62017  0.62017  0.86448  0.86568   0.50931  0.79533 |       nan       nan       nan |    5.9 \n",
    "4      |  0.67868  0.67868  0.86434  0.86611   0.51275  0.79361 |       nan       nan       nan |    5.8 \n",
    "5      |  0.72765  0.72765  0.86344  0.86555   0.51187  0.79405 |       nan       nan       nan |    5.9 \n",
    "6      |  0.78053  0.78053  0.86309  0.86354   0.50294  0.79417 |       nan       nan       nan |    5.8 \n",
    "7      |  0.80909  0.80909  0.86289  0.86454   0.50737  0.79399 |       nan       nan       nan |    5.8 \n",
    "8      |  0.84269  0.84269  0.86410  0.86583   0.51109  0.79424 |       nan       nan       nan |    5.8 \n",
    "9      |  0.85616  0.85616  0.86439  0.86607   0.51266  0.79459 |       nan       nan       nan |    5.9 \n",
    "10     |  0.86517  0.86517  0.86582  0.86714   0.51413  0.79524 |       nan       nan       nan |    5.9\n",
    "11     |  0.88092  0.88092  0.86604  0.86750   0.51514  0.79538 |       nan       nan       nan |    5.9 \n",
    "12     |  0.89291  0.89291  0.86629  0.86786   0.51641  0.79579 |       nan       nan       nan |    5.8 \n",
    "13     |  0.90424  0.90424  0.86645  0.86797   0.51655  0.79594 |       nan       nan       nan |    5.8 \n",
    "14     |  0.91264  0.91264  0.86660  0.86817   0.51707  0.79587 |       nan       nan       nan |    5.9 \n",
    "15     |  0.92194  0.92194  0.86690  0.86844   0.51773  0.79623 |       nan       nan       nan |    5.8 \n",
    "16     |  0.92784  0.92784  0.86700  0.86855   0.51805  0.79619 |       nan       nan       nan |    5.8 \n",
    "17     |  0.93727  0.93727  0.86712  0.86872   0.51868  0.79638 |       nan       nan       nan |    5.9 \n",
    "18     |  0.94468  0.94468  0.86731  0.86897   0.51942  0.79633 |       nan       nan       nan |    5.9 \n",
    "19     |  0.95230  0.95230  0.86728  0.86890   0.51925  0.79640 |       nan       nan       nan |    5.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f3153",
   "metadata": {},
   "source": [
    "### Run results on original `chembl_23_mini` data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch  |     logl  bceloss   aucroc    aucpr aucpr_cal   f1_max |      rmse  rsquared  corrcoef | tr_time \n",
    "0      |  0.34269  0.45776  0.80664  0.72646   0.48133  0.74813 |       nan       nan       nan |   13.6 \n",
    "1      |  0.31554  0.42048  0.83178  0.75306   0.51796  0.76370 |       nan       nan       nan |   12.9 \n",
    "2      |  0.31272  0.41163  0.84092  0.76037   0.53157  0.76873 |       nan       nan       nan |   12.8 \n",
    "3      |  0.31439  0.41333  0.84125  0.76524   0.53492  0.77030 |       nan       nan       nan |   12.9 \n",
    "4      |  0.31480  0.41191  0.84390  0.76670   0.53815  0.77059 |       nan       nan       nan |   12.8 \n",
    "5      |  0.31809  0.41840  0.84434  0.76798   0.53912  0.77124 |       nan       nan       nan |   12.9 \n",
    "6      |  0.32237  0.42103  0.84506  0.76737   0.53627  0.77180 |       nan       nan       nan |   12.9 \n",
    "7      |  0.32203  0.42055  0.84465  0.76600   0.53617  0.77124 |       nan       nan       nan |   13.1 \n",
    "8      |  0.32931  0.43144  0.84398  0.76671   0.53747  0.77013 |       nan       nan       nan |   13.1 \n",
    "9      |  0.33162  0.42992  0.84499  0.76793   0.53587  0.77157 |       nan       nan       nan |   13.1 \n",
    "10     |  0.32617  0.42194  0.84909  0.77293   0.54663  0.77418 |       nan       nan       nan |   13.0 \n",
    "11     |  0.32782  0.42469  0.84891  0.77210   0.54406  0.77411 |       nan       nan       nan |   12.9 \n",
    "12     |  0.33080  0.42809  0.84897  0.77252   0.54445  0.77391 |       nan       nan       nan |   12.9 \n",
    "13     |  0.33451  0.43235  0.84840  0.77160   0.54306  0.77383 |       nan       nan       nan |   13.1 \n",
    "14     |  0.33882  0.43660  0.84832  0.77141   0.54322  0.77295 |       nan       nan       nan |   13.1 \n",
    "15     |  0.34108  0.43973  0.84803  0.77172   0.54287  0.77311 |       nan       nan       nan |   13.1 \n",
    "16     |  0.34506  0.44437  0.84782  0.77086   0.54190  0.77230 |       nan       nan       nan |   13.0 \n",
    "17     |  0.34866  0.44951  0.84697  0.77017   0.54043  0.77185 |       nan       nan       nan |   13.0 \n",
    "18     |  0.35135  0.45143  0.84740  0.77087   0.54130  0.77260 |       nan       nan       nan |   13.0 \n",
    "19     |  0.35432  0.45495  0.84742  0.77097   0.54075  0.77233 |       nan       nan       nan |   13.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7b092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyt-gpu)",
   "language": "python",
   "name": "pyt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
