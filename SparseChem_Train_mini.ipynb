{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2b29b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T18:50:52.221512Z",
     "start_time": "2022-03-04T18:50:52.203972Z"
    }
   },
   "source": [
    "## Train SparseChem on Chembl_mini \n",
    "Output to `experiments/SparseChem`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79cc200c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T17:59:49.889006Z",
     "start_time": "2022-04-10T17:59:49.851481Z"
    }
   },
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "810bc0a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T17:59:54.193131Z",
     "start_time": "2022-04-10T17:59:49.892057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../experiments/mini-SparseChem/0410_1959\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2020 KU Leuven\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "import sparsechem as sc\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "import time\n",
    "import json\n",
    "import functools\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "import csv\n",
    "#from apex import amp\n",
    "from contextlib import redirect_stdout\n",
    "from sparsechem import Nothing\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_memlab import MemReporter\n",
    "import multiprocessing\n",
    "from pynvml import *\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions( linewidth=132)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    nvmlInit()\n",
    "\n",
    "multiprocessing.set_start_method('fork', force=True)\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Training a multi-task model.\")\n",
    "parser.add_argument(\"--x\", help=\"Descriptor file (matrix market, .npy or .npz)\", type=str, default=None)\n",
    "parser.add_argument(\"--y_class\", \"--y\", \"--y_classification\", help=\"Activity file (matrix market, .npy or .npz)\", type=str, default=None)\n",
    "parser.add_argument(\"--y_regr\", \"--y_regression\", help=\"Activity file (matrix market, .npy or .npz)\", type=str, default=None)\n",
    "parser.add_argument(\"--y_censor\", help=\"Censor mask for regression (matrix market, .npy or .npz)\", type=str, default=None)\n",
    "parser.add_argument(\"--weights_class\", \"--task_weights\", \"--weights_classification\", help=\"CSV file with columns task_id, training_weight, aggregation_weight, task_type (for classification tasks)\", type=str, default=None)\n",
    "parser.add_argument(\"--weights_regr\", \"--weights_regression\", help=\"CSV file with columns task_id, training_weight, censored_weight, aggregation_weight, aggregation_weight, task_type (for regression tasks)\", type=str, default=None)\n",
    "parser.add_argument(\"--censored_loss\", help=\"Whether censored loss is used for training (default 1)\", type=int, default=1)\n",
    "parser.add_argument(\"--folding\", help=\"Folding file (npy)\", type=str, required=True)\n",
    "parser.add_argument(\"--fold_va\", help=\"Validation fold number\", type=int, default=0)\n",
    "parser.add_argument(\"--fold_te\", help=\"Test fold number (removed from dataset)\", type=int, default=None)\n",
    "parser.add_argument(\"--batch_ratio\", help=\"Batch ratio\", type=float, default=0.02)\n",
    "parser.add_argument(\"--internal_batch_max\", help=\"Maximum size of the internal batch\", type=int, default=None)\n",
    "parser.add_argument(\"--normalize_loss\", help=\"Normalization constant to divide the loss (default uses batch size)\", type=float, default=None)\n",
    "parser.add_argument(\"--normalize_regression\", help=\"Set this to 1 if the regression tasks should be normalized\", type=int, default=0)\n",
    "parser.add_argument(\"--normalize_regr_va\", help=\"Set this to 1 if the regression tasks in validation fold should be normalized together with training folds\", type=int, default=0)\n",
    "parser.add_argument(\"--inverse_normalization\", help=\"Set this to 1 if the regression tasks in validation fold should be inverse normalized at validation time\", type=int, default=0)\n",
    "parser.add_argument(\"--hidden_sizes\", nargs=\"+\", help=\"Hidden sizes of trunk\", default=[], type=int, required=True)\n",
    "parser.add_argument(\"--last_hidden_sizes\", nargs=\"+\", help=\"Hidden sizes in the head (if specified , class and reg heads have this dimension)\", default=None, type=int)\n",
    "#parser.add_argument(\"--middle_dropout\", help=\"Dropout for layers before the last\", type=float, default=0.0)\n",
    "#parser.add_argument(\"--last_dropout\", help=\"Last dropout\", type=float, default=0.2)\n",
    "parser.add_argument(\"--weight_decay\", help=\"Weight decay\", type=float, default=0.0)\n",
    "parser.add_argument(\"--last_non_linearity\", help=\"Last layer non-linearity (depecrated)\", type=str, default=\"relu\", choices=[\"relu\", \"tanh\"])\n",
    "parser.add_argument(\"--middle_non_linearity\", \"--non_linearity\", help=\"Before last layer non-linearity\", type=str, default=\"relu\", choices=[\"relu\", \"tanh\"])\n",
    "parser.add_argument(\"--input_transform\", help=\"Transformation to apply to inputs\", type=str, default=\"none\", choices=[\"binarize\", \"none\", \"tanh\", \"log1p\"])\n",
    "parser.add_argument(\"--lr\", help=\"Learning rate\", type=float, default=1e-3)\n",
    "parser.add_argument(\"--lr_alpha\", help=\"Learning rate decay multiplier\", type=float, default=0.3)\n",
    "parser.add_argument(\"--lr_steps\", nargs=\"+\", help=\"Learning rate decay steps\", type=int, default=[10])\n",
    "parser.add_argument(\"--input_size_freq\", help=\"Number of high importance features\", type=int, default=None)\n",
    "parser.add_argument(\"--fold_inputs\", help=\"Fold input to a fixed set (default no folding)\", type=int, default=None)\n",
    "parser.add_argument(\"--epochs\", help=\"Number of epochs\", type=int, default=20)\n",
    "parser.add_argument(\"--pi_zero\", help=\"Reference class ratio to be used for calibrated aucpr\", type=float, default=0.1)\n",
    "parser.add_argument(\"--min_samples_class\", help=\"Minimum number samples in each class and in each fold for AUC calculation (only used if aggregation_weight is not provided in --weights_class)\", type=int, default=5)\n",
    "parser.add_argument(\"--min_samples_auc\", help=\"Obsolete: use 'min_samples_class'\", type=int, default=None)\n",
    "parser.add_argument(\"--min_samples_regr\", help=\"Minimum number of uncensored samples in each fold for regression metric calculation (only used if aggregation_weight is not provided in --weights_regr)\", type=int, default=10)\n",
    "parser.add_argument(\"--dev\", help=\"Device to use\", type=str, default=\"cuda:0\")\n",
    "parser.add_argument(\"--run_name\", help=\"Run name for results\", type=str, default=None)\n",
    "parser.add_argument(\"--output_dir\", help=\"Output directory, including boards (default 'models')\", type=str, default=\"models\")\n",
    "parser.add_argument(\"--prefix\", help=\"Prefix for run name (default 'run')\", type=str, default='run')\n",
    "parser.add_argument(\"--verbose\", help=\"Verbosity level: 2 = full; 1 = no progress; 0 = no output\", type=int, default=2, choices=[0, 1, 2])\n",
    "parser.add_argument(\"--save_model\",        help=\"Set this to 0 if the model should not be saved\", type=int, default=1)\n",
    "parser.add_argument(\"--save_board\",        help=\"Set this to 0 if the TensorBoard should not be saved\", type=int, default=1)\n",
    "parser.add_argument(\"--profile\",           help=\"Set this to 1 to output memory profile information\", type=int, default=0)\n",
    "parser.add_argument(\"--mixed_precision\",   help=\"Set this to 1 to run in mixed precision mode (vs single precision)\", type=int, default=0)\n",
    "parser.add_argument(\"--eval_train\",        help=\"Set this to 1 to calculate AUCs for train data\", type=int, default=0)\n",
    "parser.add_argument(\"--enable_cat_fusion\", help=\"Set this to 1 to enable catalogue fusion\", type=int, default=0)\n",
    "parser.add_argument(\"--eval_frequency\",    help=\"The gap between AUC eval (in epochs), -1 means to do an eval at the end.\", type=int, default=1)\n",
    "\n",
    "#hybrid model features\n",
    "parser.add_argument(\"--regression_weight\", help=\"between 0 and 1 relative weight of regression loss vs classification loss\", type=float, default=0.5)\n",
    "parser.add_argument(\"--scaling_regularizer\", help=\"L2 regularizer of the scaling layer, if inf scaling layer is switched off\", type=float, default=np.inf)\n",
    "parser.add_argument(\"--class_feature_size\", help=\"Number of leftmost features used from the output of the trunk (default: use all)\", type=int, default=-1)\n",
    "parser.add_argument(\"--regression_feature_size\", help=\"Number of rightmost features used from the output of the trunk (default: use all)\", type=int, default=-1)\n",
    "parser.add_argument(\"--last_hidden_sizes_reg\", nargs=\"+\", help=\"Hidden sizes in the regression head (overwritten by last_hidden_sizes)\", default=None, type=int)\n",
    "parser.add_argument(\"--last_hidden_sizes_class\", nargs=\"+\", help=\"Hidden sizes in the classification head (overwritten by last_hidden_sizes)\", default=None, type=int)\n",
    "parser.add_argument(\"--dropouts_reg\"  , nargs=\"+\", help=\"List of dropout values used in the regression head (needs one per last hidden in reg head, ignored if last_hidden_sizes_reg not specified)\", default=[], type=float)\n",
    "parser.add_argument(\"--dropouts_class\", nargs=\"+\", help=\"List of dropout values used in the classification head (needs one per last hidden in class head, ignored if no last_hidden_sizes_class not specified)\", default=[], type=float)\n",
    "parser.add_argument(\"--dropouts_trunk\", nargs=\"+\", help=\"List of dropout values used in the trunk\", default=[], type=float)\n",
    "\n",
    "dev = \"gpu\" \n",
    "rstr = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "# data_dir=\"chembl23_data\"\n",
    "# data_dir=\"chembl23_run_01152022\"\n",
    "data_dir = \"../MLDatasets/chembl23_mini\"\n",
    "output_dir = f\"../experiments/mini-SparseChem/{rstr}\"\n",
    "print(output_dir)\n",
    "\n",
    "rm_output=False\n",
    "\n",
    "# rstr = \"synthetic_data_model\" ##random_str(12)\n",
    "# rstr = \"synthetic_data_model_03042022\" ##random_str(12)\n",
    "\n",
    "# output_dir = f\"./models-{rstr}/\"\n",
    "# output_dir = f\"./{data_dir}/models-{rstr}/\"\n",
    "\n",
    "# output dir kbardool/kusanagi/experiments/SparseChem/0116_0843\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1951f906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T17:59:54.268012Z",
     "start_time": "2022-04-10T17:59:54.197660Z"
    }
   },
   "outputs": [],
   "source": [
    "# dev = \"gpu\" \n",
    "# data_dir=\"chembl23_data\"\n",
    "# data_dir=\"chembl23_run_01152022\"\n",
    "# data_dir = \"/home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic\"\n",
    "\n",
    "# rm_output=False\n",
    "\n",
    "# rstr = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "# rstr = \"synthetic_data_model\" ##random_str(12)\n",
    "# rstr = \"synthetic_data_model_03042022\" ##random_str(12)\n",
    "\n",
    "# output_dir = f\"./models-{rstr}/\"\n",
    "# output_dir = f\"./{data_dir}/models-{rstr}/\"\n",
    "\n",
    "# output dir kbardool/kusanagi/experiments/SparseChem/0116_0843\n",
    "# output_dir = f\"/home/kbardool/kusanagi/experiments/SparseChem/{rstr}\"\n",
    "# print(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6d5b25",
   "metadata": {},
   "source": [
    "### Two layer network as specified in `https://git.infra.melloddy.eu/wp2/sparsechem/-/blob/master/docs/main.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c06402bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T17:59:54.318975Z",
     "start_time": "2022-04-10T17:59:54.270587Z"
    }
   },
   "outputs": [],
   "source": [
    "cmd = (\n",
    "  f\" --x              {data_dir}/chembl_23mini_x.npy \" +\n",
    "  f\" --y_class        {data_dir}/chembl_23mini_y.npy \" +\n",
    "  f\" --folding        {data_dir}/chembl_23mini_folds.npy \" +\n",
    "\n",
    "  f\" --output_dir     {output_dir}\" +\n",
    "  F\" --dev              cuda:0 \"\n",
    "  f\" --fold_va              0 \" +\n",
    "  f\" --fold_inputs      32000 \" +\n",
    "  f\" --batch_ratio       0.01 \" +\n",
    "  f\" --hidden_sizes     40 40 40\" +\n",
    "  f\" --dropouts_trunk    0  0  0\" +\n",
    "  f\" --weight_decay      1e-4 \" +\n",
    "  f\" --epochs             100 \" +\n",
    "  f\" --lr                1e-3 \" +\n",
    "  f\" --lr_steps            10 \" +\n",
    "  f\" --lr_alpha           0.3 \" + \n",
    "  f\" --prefix              sc \" +\n",
    "  f\" --min_samples_class    1 \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed2a96b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:22.065859Z",
     "start_time": "2022-04-10T18:02:21.337434Z"
    }
   },
   "outputs": [],
   "source": [
    "# cmd = (\n",
    "#   f\" --x       /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic/chembl_23mini_x.npy \" +\n",
    "#   f\" --y_class /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic/chembl_23mini_adashare_y_all_bin_sparse.npy \" +\n",
    "#   f\" --folding /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic/chembl_23mini_folds.npy \" +\n",
    "#   f\" --output_dir {output_dir}\" +    \n",
    "#   f\" --fold_va           0 \" +\n",
    "#   f\" --batch_ratio    0.02 \" +\n",
    "#   f\" --hidden_sizes   25 25 25 25 25 25 \" +\n",
    "#   f\" --dropouts_trunk  0  0  0  0  0  0 \" +\n",
    "#   f\" --weight_decay   1e-4 \" \n",
    "#   f\" --epochs           40 \" +\n",
    "#   f\" --lr             1e-3 \" +\n",
    "#   f\" --lr_steps         10 \" +\n",
    "#   f\" --lr_alpha        0.3\" \n",
    "# )\n",
    "\n",
    "# cmd = (\n",
    "#   f\" --x       {data_dir}/chembl_23mini_x.npy \" +\n",
    "#   f\" --y_class {data_dir}/chembl_23mini_adashare_y_all_bin_sparse.npy \" +\n",
    "#   f\" --folding {data_dir}/chembl_23mini_folds.npy \" +\n",
    "#   f\" --output_dir {output_dir}\" +    \n",
    "#   f\" --fold_va            0 \" +\n",
    "#   f\" --batch_ratio     0.02 \" +\n",
    "#   f\" --hidden_sizes   40 40 \" +\n",
    "#   f\" --dropouts_trunk  0  0 \" +\n",
    "#   f\" --weight_decay   1e-4 \" +\n",
    "#   f\" --epochs           20 \" +\n",
    "#   f\" --lr             1e-3 \" +\n",
    "#   f\" --lr_steps         10 \" +\n",
    "#   f\" --lr_alpha        0.3 \" \n",
    "# )\n",
    "\n",
    "#   f\" --hidden_sizes   400 400 \" +\n",
    "#   f\" --last_dropout   0.2 \" +\n",
    "#   f\" --middle_dropout 0.2 \" +\n",
    "#   f\" --x       ./{data_dir}/chembl_23_x.mtx \" +\n",
    "#   f\" --y_class ./{data_dir}/chembl_23_y.mtx \" +\n",
    "#   f\" --folding ./{data_dir}/folding_hier_0.6.npy \" +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f809416e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:22.131696Z",
     "start_time": "2022-04-10T18:02:22.069627Z"
    }
   },
   "outputs": [],
   "source": [
    "#### copied from SparseChemDev \n",
    "\n",
    "# cmd = (\n",
    "#         f\" --x       ./{data_dir}/chembl_23mini_x.npy\" +\n",
    "#         f\" --y_class ./{data_dir}/chembl_23mini_y.npy\" +\n",
    "#         f\" --folding ./{data_dir}/chembl_23mini_folds.npy\" +\n",
    "#         f\" --hidden_sizes 20 30 40 \" +  \n",
    "#         f\" --output_dir {output_dir}\" +\n",
    "#         f\" --batch_ratio 0.1\" +\n",
    "#         f\" --epochs 2\" +\n",
    "#         f\" --lr 1e-3\" +\n",
    "#         f\" --lr_steps 1\" +\n",
    "#         f\" --dev {dev}\" +\n",
    "#         f\" --verbose 1\")\n",
    "#         f\" --input_size_freq  40\"\n",
    "#         f\" --tail_hidden_size  10\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d1085",
   "metadata": {},
   "source": [
    "### Initializations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31290fa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:22.185818Z",
     "start_time": "2022-04-10T18:02:22.133804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'batch_ratio': 0.01,\n",
      "    'censored_loss': 1,\n",
      "    'class_feature_size': -1,\n",
      "    'dev': 'cuda:0',\n",
      "    'dropouts_class': [],\n",
      "    'dropouts_reg': [],\n",
      "    'dropouts_trunk': [0.0, 0.0, 0.0],\n",
      "    'enable_cat_fusion': 0,\n",
      "    'epochs': 100,\n",
      "    'eval_frequency': 1,\n",
      "    'eval_train': 0,\n",
      "    'fold_inputs': 32000,\n",
      "    'fold_te': None,\n",
      "    'fold_va': 0,\n",
      "    'folding': '../MLDatasets/chembl23_mini/chembl_23mini_folds.npy',\n",
      "    'hidden_sizes': [40, 40, 40],\n",
      "    'input_size_freq': None,\n",
      "    'input_transform': 'none',\n",
      "    'internal_batch_max': None,\n",
      "    'inverse_normalization': 0,\n",
      "    'last_hidden_sizes': None,\n",
      "    'last_hidden_sizes_class': None,\n",
      "    'last_hidden_sizes_reg': None,\n",
      "    'last_non_linearity': 'relu',\n",
      "    'lr': 0.001,\n",
      "    'lr_alpha': 0.3,\n",
      "    'lr_steps': [10],\n",
      "    'middle_non_linearity': 'relu',\n",
      "    'min_samples_auc': None,\n",
      "    'min_samples_class': 1,\n",
      "    'min_samples_regr': 10,\n",
      "    'mixed_precision': 0,\n",
      "    'normalize_loss': None,\n",
      "    'normalize_regr_va': 0,\n",
      "    'normalize_regression': 0,\n",
      "    'output_dir': '../experiments/mini-SparseChem/0410_1959',\n",
      "    'pi_zero': 0.1,\n",
      "    'prefix': 'sc',\n",
      "    'profile': 0,\n",
      "    'regression_feature_size': -1,\n",
      "    'regression_weight': 0.5,\n",
      "    'run_name': None,\n",
      "    'save_board': 1,\n",
      "    'save_model': 1,\n",
      "    'scaling_regularizer': inf,\n",
      "    'verbose': 2,\n",
      "    'weight_decay': 0.0001,\n",
      "    'weights_class': None,\n",
      "    'weights_regr': None,\n",
      "    'x': '../MLDatasets/chembl23_mini/chembl_23mini_x.npy',\n",
      "    'y_censor': None,\n",
      "    'y_class': '../MLDatasets/chembl23_mini/chembl_23mini_y.npy',\n",
      "    'y_regr': None}\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(cmd.split())\n",
    "\n",
    "\n",
    "# %tb\n",
    "# args = parser.parse_args()\n",
    "\n",
    "def vprint(s=\"\"):\n",
    "    if args.verbose:\n",
    "        print(s)\n",
    "\n",
    "pp.pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "200d78ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:22.239064Z",
     "start_time": "2022-04-10T18:02:22.198582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name is 'sc_40.40.40_lr0.001_do0.0'.\n"
     ]
    }
   ],
   "source": [
    "if args.run_name is not None:\n",
    "    name = args.run_name\n",
    "else:\n",
    "    name  = f\"{args.prefix}\"\n",
    "    name += f\"_{'.'.join([str(h) for h in args.hidden_sizes])}\"\n",
    "#     name += f\"_do{'.'.join([str(d) for d in args.dropouts_trunk])}\"\n",
    "    name += f\"_lr{args.lr}\"\n",
    "    name += f\"_do{args.dropouts_trunk[0]}\"\n",
    "#     name += f\"_wd{args.weight_decay}\"\n",
    "#     name += f\"_hs{'.'.join([str(h) for h in args.hidden_sizes])}\"\n",
    "    \n",
    "#     name += f\"_lrsteps{'.'.join([str(s) for s in args.lr_steps])}_ep{args.epochs}\"\n",
    "#     name += f\"_fva{args.fold_va}_fte{args.fold_te}\"\n",
    "    if args.mixed_precision == 1:\n",
    "        name += f\"_mixed_precision\"\n",
    "vprint(f\"Run name is '{name}'.\")\n",
    "\n",
    "# if args.run_name is not None:\n",
    "#     name = args.run_name\n",
    "# else:\n",
    "#     name  = f\"sc_{args.prefix}_h{'.'.join([str(h) for h in args.hidden_sizes])}_ldo_r{'.'.join([str(d) for d in args.dropouts_reg])}_wd{args.weight_decay}\"\n",
    "#     name += f\"_lr{args.lr}_lrsteps{'.'.join([str(s) for s in args.lr_steps])}_ep{args.epochs}\"\n",
    "#     name += f\"_fva{args.fold_va}_fte{args.fold_te}\"\n",
    "#     if args.mixed_precision == 1:\n",
    "#         name += f\"_mixed_precision\"\n",
    "# vprint(f\"Run name is '{name}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c0fb5c",
   "metadata": {},
   "source": [
    "### Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31a37333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:22.379218Z",
     "start_time": "2022-04-10T18:02:22.304804Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if (args.last_hidden_sizes is not None) and ((args.last_hidden_sizes_class is not None) or (args.last_hidden_sizes_reg is not None)):\n",
    "    raise ValueError(\"Head specific and general last_hidden_sizes argument were both specified!\")\n",
    "if (args.last_hidden_sizes is not None):\n",
    "    args.last_hidden_sizes_class = args.last_hidden_sizes\n",
    "    args.last_hidden_sizes_reg   = args.last_hidden_sizes\n",
    "\n",
    "if args.last_hidden_sizes_reg is not None:\n",
    "    assert len(args.last_hidden_sizes_reg) == len(args.dropouts_reg), \"Number of hiddens and number of dropout values specified must be equal in the regression head!\"\n",
    "if args.last_hidden_sizes_class is not None:\n",
    "    assert len(args.last_hidden_sizes_class) == len(args.dropouts_class), \"Number of hiddens and number of dropout values specified must be equal in the classification head!\"\n",
    "if args.hidden_sizes is not None:\n",
    "    assert len(args.hidden_sizes) == len(args.dropouts_trunk), \"Number of hiddens and number of dropout values specified must be equal in the trunk!\"\n",
    "\n",
    "if args.class_feature_size == -1:\n",
    "    args.class_feature_size = args.hidden_sizes[-1]\n",
    "if args.regression_feature_size == -1:\n",
    "    args.regression_feature_size = args.hidden_sizes[-1]\n",
    "\n",
    "assert args.regression_feature_size <= args.hidden_sizes[-1], \"Regression feature size cannot be larger than the trunk output\"\n",
    "assert args.class_feature_size <= args.hidden_sizes[-1], \"Classification feature size cannot be larger than the trunk output\"\n",
    "assert args.regression_feature_size + args.class_feature_size >= args.hidden_sizes[-1], \"Unused features in the trunk! Set regression_feature_size + class_feature_size >= trunk output!\"\n",
    "#if args.regression_feature_size != args.hidden_sizes[-1] or args.class_feature_size != args.hidden_sizes[-1]:\n",
    "#    raise ValueError(\"Hidden spliting not implemented yet!\")\n",
    "\n",
    "assert args.input_size_freq is None, \"Using tail compression not yet supported.\"\n",
    "\n",
    "if (args.y_class is None) and (args.y_regr is None):\n",
    "    raise ValueError(\"No label data specified, please add --y_class and/or --y_regr.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba30c7a",
   "metadata": {},
   "source": [
    "### Summary writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34215554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:22.684156Z",
     "start_time": "2022-04-10T18:02:22.592351Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.profile == 1:\n",
    "    assert (args.save_board==1), \"Tensorboard should be enabled to be able to profile memory usage.\"\n",
    "if args.save_board:\n",
    "    tb_name = os.path.join(args.output_dir, \"\", name)\n",
    "    writer  = SummaryWriter(tb_name)\n",
    "else:\n",
    "    writer = Nothing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8345390",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a8df58d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:23.121412Z",
     "start_time": "2022-04-10T18:02:22.893064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count non zero:80\n",
      "Input dimension: 32000\n",
      "#samples:        18388\n",
      "#classification tasks:  100\n",
      "#regression tasks:      0\n",
      "Using 20 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "Using 0 regression tasks for calculating metrics (RMSE, Rsquared, correlation).\n"
     ]
    }
   ],
   "source": [
    "ecfp     = sc.load_sparse(args.x)\n",
    "y_class  = sc.load_sparse(args.y_class)\n",
    "y_regr   = sc.load_sparse(args.y_regr)\n",
    "y_censor = sc.load_sparse(args.y_censor)\n",
    "\n",
    "if (y_regr is None) and (y_censor is not None):\n",
    "    raise ValueError(\"y_censor provided please also provide --y_regr.\")\n",
    "if y_class is None:\n",
    "    y_class = scipy.sparse.csr_matrix((ecfp.shape[0], 0))\n",
    "if y_regr is None:\n",
    "    y_regr  = scipy.sparse.csr_matrix((ecfp.shape[0], 0))\n",
    "if y_censor is None:\n",
    "    y_censor = scipy.sparse.csr_matrix(y_regr.shape)\n",
    "\n",
    "folding = np.load(args.folding)\n",
    "assert ecfp.shape[0] == folding.shape[0], \"x and folding must have same number of rows\"\n",
    "\n",
    "## Loading task weights\n",
    "tasks_class = sc.load_task_weights(args.weights_class, y=y_class, label=\"y_class\")\n",
    "tasks_regr  = sc.load_task_weights(args.weights_regr, y=y_regr, label=\"y_regr\")\n",
    "\n",
    "## Input transformation\n",
    "ecfp = sc.fold_transform_inputs(ecfp, folding_size=args.fold_inputs, transform=args.input_transform)\n",
    "print(f\"count non zero:{ecfp[0].count_nonzero()}\")\n",
    "num_pos    = np.array((y_class == +1).sum(0)).flatten()\n",
    "num_neg    = np.array((y_class == -1).sum(0)).flatten()\n",
    "num_class  = np.array((y_class != 0).sum(0)).flatten()\n",
    "if (num_class != num_pos + num_neg).any():\n",
    "    raise ValueError(\"For classification all y values (--y_class/--y) must be 1 or -1.\")\n",
    "\n",
    "num_regr   = np.bincount(y_regr.indices, minlength=y_regr.shape[1])\n",
    "\n",
    "assert args.min_samples_auc is None, \"Parameter 'min_samples_auc' is obsolete. Use '--min_samples_class' that specifies how many samples a task needs per FOLD and per CLASS to be aggregated.\"\n",
    "\n",
    "if tasks_class.aggregation_weight is None:\n",
    "    ## using min_samples rule\n",
    "    fold_pos, fold_neg = sc.class_fold_counts(y_class, folding)\n",
    "    n = args.min_samples_class\n",
    "    tasks_class.aggregation_weight = ((fold_pos >= n).all(0) & (fold_neg >= n)).all(0).astype(np.float64)\n",
    "\n",
    "if tasks_regr.aggregation_weight is None:\n",
    "    if y_censor.nnz == 0:\n",
    "        y_regr2 = y_regr.copy()\n",
    "        y_regr2.data[:] = 1\n",
    "    else:\n",
    "        ## only counting uncensored data\n",
    "        y_regr2      = y_censor.copy()\n",
    "        y_regr2.data = (y_regr2.data == 0).astype(np.int32)\n",
    "    fold_regr, _ = sc.class_fold_counts(y_regr2, folding)\n",
    "    del y_regr2\n",
    "    tasks_regr.aggregation_weight = (fold_regr >= args.min_samples_regr).all(0).astype(np.float64)\n",
    "\n",
    "vprint(f\"Input dimension: {ecfp.shape[1]}\")\n",
    "vprint(f\"#samples:        {ecfp.shape[0]}\")\n",
    "vprint(f\"#classification tasks:  {y_class.shape[1]}\")\n",
    "vprint(f\"#regression tasks:      {y_regr.shape[1]}\")\n",
    "vprint(f\"Using {(tasks_class.aggregation_weight > 0).sum()} classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\")\n",
    "vprint(f\"Using {(tasks_regr.aggregation_weight > 0).sum()} regression tasks for calculating metrics (RMSE, Rsquared, correlation).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445468cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6345093",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:23.478650Z",
     "start_time": "2022-04-10T18:02:23.395310Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/c7a329a446/ipykernel_65004/2168207603.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pos_rate = num_pos_va/(num_pos_va+num_neg_va)\n"
     ]
    }
   ],
   "source": [
    "if args.fold_te is not None and args.fold_te >= 0:\n",
    "    ## removing test data\n",
    "    assert args.fold_te != args.fold_va, \"fold_va and fold_te must not be equal.\"\n",
    "    keep    = folding != args.fold_te\n",
    "    ecfp    = ecfp[keep]\n",
    "    y_class = y_class[keep]\n",
    "    y_regr  = y_regr[keep]\n",
    "    y_censor = y_censor[keep]\n",
    "    folding = folding[keep]\n",
    "\n",
    "normalize_inv = None\n",
    "if args.normalize_regression == 1 and args.normalize_regr_va == 1:\n",
    "   y_regr, mean_save, var_save = sc.normalize_regr(y_regr)\n",
    "fold_va = args.fold_va\n",
    "idx_tr  = np.where(folding != fold_va)[0]\n",
    "idx_va  = np.where(folding == fold_va)[0]\n",
    "\n",
    "y_class_tr = y_class[idx_tr]\n",
    "y_class_va = y_class[idx_va]\n",
    "y_regr_tr  = y_regr[idx_tr]\n",
    "y_regr_va  = y_regr[idx_va]\n",
    "y_censor_tr = y_censor[idx_tr]\n",
    "y_censor_va = y_censor[idx_va]\n",
    "\n",
    "if args.normalize_regression == 1 and args.normalize_regr_va == 0:\n",
    "   y_regr_tr, mean_save, var_save = sc.normalize_regr(y_regr_tr) \n",
    "   if args.inverse_normalization == 1:\n",
    "      normalize_inv = {}\n",
    "      normalize_inv[\"mean\"] = mean_save\n",
    "      normalize_inv[\"var\"]  = var_save\n",
    "num_pos_va  = np.array((y_class_va == +1).sum(0)).flatten()\n",
    "num_neg_va  = np.array((y_class_va == -1).sum(0)).flatten()\n",
    "num_regr_va = np.bincount(y_regr_va.indices, minlength=y_regr.shape[1])\n",
    "pos_rate = num_pos_va/(num_pos_va+num_neg_va)\n",
    "pos_rate_ref = args.pi_zero\n",
    "pos_rate = np.clip(pos_rate, 0, 0.99)\n",
    "cal_fact_aucpr = pos_rate*(1-pos_rate_ref)/(pos_rate_ref*(1-pos_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc713075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:23.640703Z",
     "start_time": "2022-04-10T18:02:23.562764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension   : 32000\n",
      "Input dimension   : 32000\n",
      "Training dataset  : (14633, 32000)\n",
      "Validation dataset: (3755, 32000)\n",
      "\n",
      "#classification tasks:  100\n",
      "#regression tasks    :      0\n",
      "Using  20 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "Using   0 regression tasks for calculating metrics (RMSE, Rsquared, correlation).\n"
     ]
    }
   ],
   "source": [
    "vprint(f\"Input dimension   : {ecfp.shape[1]}\")\n",
    "vprint(f\"Input dimension   : {ecfp.shape[1]}\")\n",
    "vprint(f\"Training dataset  : {ecfp[idx_tr].shape}\")\n",
    "vprint(f\"Validation dataset: {ecfp[idx_va].shape}\")\n",
    "vprint()\n",
    "vprint(f\"#classification tasks:  {y_class.shape[1]}\")\n",
    "vprint(f\"#regression tasks    :      {y_regr.shape[1]}\")\n",
    "vprint(f\"Using {(tasks_class.aggregation_weight > 0).sum():3d} classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\")\n",
    "vprint(f\"Using {(tasks_regr.aggregation_weight > 0).sum():3d} regression tasks for calculating metrics (RMSE, Rsquared, correlation).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5501c67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:23.787279Z",
     "start_time": "2022-04-10T18:02:23.714898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig batch size:   128\n",
      "orig num int batches:   1\n",
      "batch size:   128\n",
      "num_int_batches:   1\n"
     ]
    }
   ],
   "source": [
    "num_int_batches = 1\n",
    "batch_size = 128\n",
    "# batch_size  = int(np.ceil(args.batch_ratio * idx_tr.shape[0]))\n",
    "\n",
    "print(f\"orig batch size:   {batch_size}\")\n",
    "print(f\"orig num int batches:   {num_int_batches}\")\n",
    "\n",
    "if args.internal_batch_max is not None:\n",
    "    if args.internal_batch_max < batch_size:\n",
    "        num_int_batches = int(np.ceil(batch_size / args.internal_batch_max))\n",
    "        batch_size      = int(np.ceil(batch_size / num_int_batches))\n",
    "print(f\"batch size:   {batch_size}\")\n",
    "print(f\"num_int_batches:   {num_int_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6c2fc55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:23.928097Z",
     "start_time": "2022-04-10T18:02:23.859746Z"
    }
   },
   "outputs": [],
   "source": [
    "# #import ipdb; ipdb.set_trace()\n",
    "# batch_size  = int(np.ceil(args.batch_ratio * idx_tr.shape[0]))\n",
    "# num_int_batches = 1\n",
    "\n",
    "# if args.internal_batch_max is not None:\n",
    "#     if args.internal_batch_max < batch_size:\n",
    "#         num_int_batches = int(np.ceil(batch_size / args.internal_batch_max))\n",
    "#         batch_size      = int(np.ceil(batch_size / num_int_batches))\n",
    "# vprint(f\"#internal batch size:   {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eef41e32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:24.101595Z",
     "start_time": "2022-04-10T18:02:24.032148Z"
    }
   },
   "outputs": [],
   "source": [
    "tasks_cat_id_list = None\n",
    "select_cat_ids = None\n",
    "if tasks_class.cat_id is not None:\n",
    "    tasks_cat_id_list = [[x,i] for i,x in enumerate(tasks_class.cat_id) if str(x) != 'nan']\n",
    "    tasks_cat_ids = [i for i,x in enumerate(tasks_class.cat_id) if str(x) != 'nan']\n",
    "    select_cat_ids = np.array(tasks_cat_ids)\n",
    "    cat_id_size = len(tasks_cat_id_list)\n",
    "else:\n",
    "    cat_id_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e73fc10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0e269e4",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd9d061d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:26.648793Z",
     "start_time": "2022-04-10T18:02:24.489502Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/leuven/326/vsc32647/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/torch/nn/init.py:388: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "dataset_tr = sc.ClassRegrSparseDataset(x=ecfp[idx_tr], y_class=y_class_tr, y_regr=y_regr_tr, y_censor=y_censor_tr, y_cat_columns=select_cat_ids)\n",
    "dataset_va = sc.ClassRegrSparseDataset(x=ecfp[idx_va], y_class=y_class_va, y_regr=y_regr_va, y_censor=y_censor_va, y_cat_columns=select_cat_ids)\n",
    "\n",
    "loader_tr = DataLoader(dataset_tr, batch_size=batch_size, num_workers = 8, pin_memory=True, collate_fn=dataset_tr.collate, shuffle=True)\n",
    "loader_va = DataLoader(dataset_va, batch_size=batch_size, num_workers = 4, pin_memory=True, collate_fn=dataset_va.collate, shuffle=False)\n",
    "\n",
    "args.input_size  = dataset_tr.input_size\n",
    "args.output_size = dataset_tr.output_size\n",
    "\n",
    "args.class_output_size = dataset_tr.class_output_size\n",
    "args.regr_output_size  = dataset_tr.regr_output_size\n",
    "args.cat_id_size = cat_id_size\n",
    "\n",
    "dev  = torch.device(args.dev)\n",
    "net  = sc.SparseFFN(args).to(dev)\n",
    "loss_class = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "loss_regr  = sc.censored_mse_loss\n",
    "if not args.censored_loss:\n",
    "    loss_regr = functools.partial(loss_regr, censored_enabled=False)\n",
    "\n",
    "tasks_class.training_weight = tasks_class.training_weight.to(dev)\n",
    "tasks_regr.training_weight  = tasks_regr.training_weight.to(dev)\n",
    "tasks_regr.censored_weight  = tasks_regr.censored_weight.to(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd06c57",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29294e00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:26.687184Z",
     "start_time": "2022-04-10T18:02:26.651405Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:\n",
      "SparseFFN(\n",
      "  (net): Sequential(\n",
      "    (0): SparseInputNet(\n",
      "      (net_freq): SparseLinear(in_features=32000, out_features=40, bias=True)\n",
      "    )\n",
      "    (1): MiddleNet(\n",
      "      (net): Sequential(\n",
      "        (layer_0): Sequential(\n",
      "          (0): ReLU()\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=40, out_features=40, bias=True)\n",
      "        )\n",
      "        (layer_1): Sequential(\n",
      "          (0): ReLU()\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=40, out_features=40, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classLast): LastNet(\n",
      "    (net): Sequential(\n",
      "      (initial_layer): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=40, out_features=100, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (regrLast): Sequential(\n",
      "    (0): LastNet(\n",
      "      (net): Sequential(\n",
      "        (initial_layer): Sequential(\n",
      "          (0): Tanh()\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "          (2): Linear(in_features=40, out_features=0, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vprint(\"Network:\")\n",
    "vprint(net)\n",
    "reporter = None\n",
    "h = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b3679",
   "metadata": {},
   "source": [
    "### setup memory profiling reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b500e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:26.719013Z",
     "start_time": "2022-04-10T18:02:26.688392Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.profile == 1:\n",
    "   torch_gpu_id = torch.cuda.current_device()\n",
    "   if \"CUDA_VISIBLE_DEVICES\" in os.environ:\n",
    "      ids = list(map(int, os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"\").split(\",\")))\n",
    "      nvml_gpu_id = ids[torch_gpu_id] # remap\n",
    "   else:\n",
    "      nvml_gpu_id = torch_gpu_id\n",
    "   h = nvmlDeviceGetHandleByIndex(nvml_gpu_id)\n",
    "\n",
    "if args.profile == 1:\n",
    "   #####   output saving   #####\n",
    "   if not os.path.exists(args.output_dir):\n",
    "       os.makedirs(args.output_dir)\n",
    "\n",
    "   reporter = MemReporter(net)\n",
    "\n",
    "   with open(f\"{args.output_dir}/memprofile.txt\", \"w+\") as profile_file:\n",
    "        with redirect_stdout(profile_file):\n",
    "             profile_file.write(f\"\\nInitial model detailed report:\\n\\n\")\n",
    "             reporter.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5351de96",
   "metadata": {},
   "source": [
    "###  Optimizer, Scheduler, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce9acd52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:27.866263Z",
     "start_time": "2022-04-10T18:02:27.796499Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "scheduler = MultiStepLR(optimizer, milestones=args.lr_steps, gamma=args.lr_alpha)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "num_prints = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e39cc7dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:28.939809Z",
     "start_time": "2022-04-10T18:02:28.867025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "dev              :    cuda:0\n",
      "args.lr          :    0.001\n",
      "args.weight_decay:    0.0001\n",
      "args.lr_steps    :    [10]\n",
      "args.lr_steps    :    [10]\n",
      "num_int_batches  :    1\n",
      "batch_size       :    128\n",
      "EPOCHS           :    100\n",
      "scaler           :    <torch.cuda.amp.grad_scaler.GradScaler object at 0x2b73210736d0>\n",
      "args.normalize_loss    :    None\n",
      "loss_class       :    BCEWithLogitsLoss()\n",
      "mixed precision  :    0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(optimizer)\n",
    "# args.eval_train = 0 \n",
    "# args.epochs     = 5\n",
    "print(f\"dev              :    {dev}\")\n",
    "print(f\"args.lr          :    {args.lr}\")\n",
    "print(f\"args.weight_decay:    {args.weight_decay}\")\n",
    "print(f\"args.lr_steps    :    {args.lr_steps}\")\n",
    "print(f\"args.lr_steps    :    {args.lr_steps}\")\n",
    "print(f\"num_int_batches  :    {num_int_batches}\")\n",
    "print(f\"batch_size       :    {batch_size}\")\n",
    "print(f\"EPOCHS           :    {args.epochs}\")\n",
    "print(f\"scaler           :    {scaler}\")\n",
    "print(f\"args.normalize_loss    :    {args.normalize_loss}\")\n",
    "print(f\"loss_class       :    {loss_class}\")\n",
    "print(f\"mixed precision  :    {args.mixed_precision}\")\n",
    "print(args.eval_train)\n",
    "current_epoch = 0\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cfdac1",
   "metadata": {},
   "source": [
    "##  Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e29f32ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:05:03.143953Z",
     "start_time": "2022-04-10T18:02:30.077142Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  |      logl   bceloss  avg prec   auc roc    auc pr aucpr_cal    f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "0      |   0.08678   0.24621   0.88100   0.83707   0.87880   0.77458   0.88615 |       nan       nan       nan |    1.6 \n",
      "1      |   0.07841   0.25434   0.91099   0.87245   0.89624   0.79673   0.92320 |       nan       nan       nan |    1.5 \n",
      "2      |   0.07423   0.22931   0.91612   0.88930   0.90144   0.80599   0.92193 |       nan       nan       nan |    1.1 \n",
      "3      |   0.07755   0.25578   0.92877   0.86402   0.92531   0.80459   0.93024 |       nan       nan       nan |    1.0 \n",
      "4      |   0.07954   0.25474   0.93618   0.88056   0.93324   0.82355   0.93585 |       nan       nan       nan |    1.0 \n",
      "5      |   0.08637   0.29669   0.92689   0.86190   0.92340   0.80521   0.92895 |       nan       nan       nan |    1.0 \n",
      "6      |   0.08779   0.32310   0.90733   0.89057   0.89193   0.82575   0.91613 |       nan       nan       nan |    1.0 \n",
      "7      |   0.09774   0.34855   0.92651   0.86040   0.92304   0.80399   0.92868 |       nan       nan       nan |    1.1 \n",
      "8      |   0.09841   0.34926   0.90192   0.86122   0.88578   0.77291   0.91315 |       nan       nan       nan |    1.0 \n",
      "9      |   0.10267   0.34968   0.90157   0.86422   0.88487   0.76518   0.91082 |       nan       nan       nan |    1.0 \n",
      "10     |   0.10203   0.35734   0.90043   0.86496   0.88370   0.76303   0.91089 |       nan       nan       nan |    1.1 \n",
      "11     |   0.10223   0.36084   0.90037   0.86409   0.88364   0.76191   0.91029 |       nan       nan       nan |    1.1 \n",
      "12     |   0.10220   0.35936   0.90025   0.86399   0.88352   0.76086   0.91029 |       nan       nan       nan |    1.1 \n",
      "13     |   0.10287   0.36104   0.90023   0.86397   0.88350   0.76078   0.91029 |       nan       nan       nan |    1.0 \n",
      "14     |   0.10439   0.36172   0.90131   0.86649   0.88464   0.76141   0.91022 |       nan       nan       nan |    0.9 \n",
      "15     |   0.10377   0.35924   0.90131   0.86676   0.88464   0.76207   0.91029 |       nan       nan       nan |    1.1 \n",
      "16     |   0.10426   0.36188   0.90150   0.86669   0.88483   0.76131   0.91029 |       nan       nan       nan |    1.0 \n",
      "17     |   0.10485   0.36113   0.90151   0.86678   0.88484   0.76185   0.91022 |       nan       nan       nan |    1.1 \n",
      "18     |   0.10546   0.36834   0.90153   0.86696   0.88485   0.76183   0.91021 |       nan       nan       nan |    1.1 \n",
      "19     |   0.10644   0.37686   0.90157   0.86707   0.88490   0.76164   0.91021 |       nan       nan       nan |    1.1 \n",
      "Epoch  |      logl   bceloss  avg prec   auc roc    auc pr aucpr_cal    f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "20     |   0.10482   0.37461   0.90041   0.86405   0.88371   0.76148   0.90778 |       nan       nan       nan |    1.1 \n",
      "21     |   0.10733   0.38183   0.92508   0.86430   0.92087   0.78830   0.92358 |       nan       nan       nan |    1.1 \n",
      "22     |   0.10533   0.36638   0.90142   0.86649   0.88474   0.76085   0.90935 |       nan       nan       nan |    1.0 \n",
      "23     |   0.10775   0.39172   0.90060   0.86558   0.88390   0.76051   0.90699 |       nan       nan       nan |    1.0 \n",
      "24     |   0.10665   0.36953   0.90145   0.86711   0.88477   0.76139   0.90825 |       nan       nan       nan |    1.0 \n",
      "25     |   0.10756   0.38500   0.92730   0.86738   0.92315   0.79060   0.92649 |       nan       nan       nan |    1.0 \n",
      "26     |   0.10776   0.40266   0.89677   0.86233   0.87903   0.74858   0.90685 |       nan       nan       nan |    1.1 \n",
      "27     |   0.10871   0.40371   0.90553   0.87496   0.88874   0.76959   0.90982 |       nan       nan       nan |    1.0 \n",
      "28     |   0.11082   0.40068   0.90756   0.87360   0.89144   0.77193   0.90899 |       nan       nan       nan |    1.3 \n",
      "29     |   0.11178   0.40533   0.92916   0.87148   0.92500   0.79169   0.92584 |       nan       nan       nan |    1.2 \n",
      "30     |   0.10646   0.37578   0.90600   0.87099   0.89018   0.77123   0.90804 |       nan       nan       nan |    1.1 \n",
      "31     |   0.10349   0.37431   0.90896   0.87522   0.89339   0.76940   0.90925 |       nan       nan       nan |    1.2 \n",
      "32     |   0.10923   0.40856   0.90043   0.86522   0.88380   0.75516   0.90550 |       nan       nan       nan |    1.0 \n",
      "33     |   0.10757   0.37761   0.90688   0.87426   0.89123   0.77301   0.90778 |       nan       nan       nan |    0.9 \n",
      "34     |   0.11106   0.40438   0.89750   0.87539   0.88577   0.77370   0.90166 |       nan       nan       nan |    1.0 \n",
      "35     |   0.11178   0.39087   0.90627   0.88249   0.89037   0.77576   0.90703 |       nan       nan       nan |    1.0 \n",
      "36     |   0.11417   0.39571   0.89991   0.88281   0.88861   0.77739   0.89677 |       nan       nan       nan |    1.0 \n",
      "37     |   0.11154   0.39745   0.90037   0.88487   0.88896   0.78531   0.89677 |       nan       nan       nan |    1.0 \n",
      "38     |   0.11128   0.39316   0.89425   0.88200   0.88621   0.77649   0.88844 |       nan       nan       nan |    0.9 \n",
      "39     |   0.11160   0.39982   0.91078   0.89299   0.89534   0.79248   0.90509 |       nan       nan       nan |    1.0 \n",
      "Epoch  |      logl   bceloss  avg prec   auc roc    auc pr aucpr_cal    f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "40     |   0.10968   0.38262   0.90190   0.88781   0.89062   0.78701   0.89931 |       nan       nan       nan |    1.0 \n",
      "41     |   0.12245   0.49319   0.87775   0.85045   0.87172   0.73454   0.87714 |       nan       nan       nan |    0.9 \n",
      "42     |   0.11485   0.40227   0.88624   0.87704   0.87795   0.77179   0.88663 |       nan       nan       nan |    1.7 \n",
      "43     |   0.11364   0.41630   0.89139   0.87942   0.88415   0.77167   0.88873 |       nan       nan       nan |    1.0 \n",
      "44     |   0.11827   0.41413   0.88732   0.87936   0.87908   0.77196   0.88585 |       nan       nan       nan |    0.9 \n",
      "45     |   0.11428   0.42569   0.89315   0.88014   0.88504   0.77554   0.88842 |       nan       nan       nan |    1.0 \n",
      "46     |   0.11411   0.42212   0.88450   0.89091   0.87651   0.77339   0.88644 |       nan       nan       nan |    1.0 \n",
      "47     |   0.11382   0.40658   0.89427   0.87297   0.88497   0.75501   0.89459 |       nan       nan       nan |    1.0 \n",
      "48     |   0.11832   0.42830   0.88359   0.86078   0.87506   0.73607   0.88530 |       nan       nan       nan |    0.9 \n",
      "49     |   0.11455   0.40913   0.89309   0.86997   0.88365   0.75218   0.89491 |       nan       nan       nan |    1.1 \n",
      "50     |   0.11908   0.43471   0.89546   0.87413   0.88609   0.75669   0.89484 |       nan       nan       nan |    1.0 \n",
      "51     |   0.11851   0.42868   0.89629   0.87089   0.88475   0.75491   0.89636 |       nan       nan       nan |    0.9 \n",
      "52     |   0.11862   0.42769   0.89539   0.86895   0.88311   0.74679   0.89776 |       nan       nan       nan |    1.1 \n",
      "53     |   0.11974   0.43699   0.89116   0.86432   0.87777   0.73568   0.89717 |       nan       nan       nan |    0.9 \n",
      "54     |   0.11845   0.43055   0.89516   0.86750   0.88293   0.74571   0.89820 |       nan       nan       nan |    0.9 \n",
      "55     |   0.12549   0.46092   0.89478   0.87007   0.88240   0.74771   0.89603 |       nan       nan       nan |    1.1 \n",
      "56     |   0.11853   0.43136   0.89464   0.86943   0.88237   0.74251   0.89743 |       nan       nan       nan |    0.9 \n",
      "57     |   0.11805   0.43191   0.89944   0.87466   0.88824   0.76280   0.89631 |       nan       nan       nan |    0.9 \n",
      "58     |   0.11694   0.42163   0.89945   0.87348   0.88818   0.75174   0.89760 |       nan       nan       nan |    1.0 \n",
      "59     |   0.12313   0.49219   0.88735   0.86220   0.88013   0.74695   0.88320 |       nan       nan       nan |    1.0 \n",
      "Epoch  |      logl   bceloss  avg prec   auc roc    auc pr aucpr_cal    f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "60     |   0.12228   0.43935   0.89727   0.87251   0.88517   0.76122   0.89841 |       nan       nan       nan |    1.0 \n",
      "61     |   0.12290   0.46143   0.90253   0.86391   0.88695   0.75156   0.90310 |       nan       nan       nan |    1.1 \n",
      "62     |   0.12305   0.44683   0.90490   0.87303   0.88868   0.75390   0.90677 |       nan       nan       nan |    1.1 \n",
      "63     |   0.12091   0.45582   0.89275   0.86638   0.88053   0.74793   0.89785 |       nan       nan       nan |    1.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64     |   0.12107   0.45638   0.89492   0.86951   0.88270   0.74319   0.89815 |       nan       nan       nan |    1.0 \n",
      "65     |   0.12115   0.45452   0.89490   0.86936   0.88270   0.74699   0.89800 |       nan       nan       nan |    0.9 \n",
      "66     |   0.12020   0.45389   0.89625   0.87237   0.88417   0.75242   0.89872 |       nan       nan       nan |    0.9 \n",
      "67     |   0.12303   0.44464   0.90776   0.87469   0.89243   0.76183   0.90633 |       nan       nan       nan |    1.0 \n",
      "68     |   0.11959   0.43532   0.93644   0.88348   0.93360   0.80713   0.92341 |       nan       nan       nan |    1.0 \n",
      "69     |   0.12561   0.48717   0.89600   0.86559   0.88464   0.75252   0.89549 |       nan       nan       nan |    1.5 \n",
      "70     |   0.14155   0.58338   0.88125   0.84610   0.86754   0.72236   0.89207 |       nan       nan       nan |    1.0 \n",
      "71     |   0.13307   0.49568   0.90106   0.88409   0.88948   0.76588   0.90057 |       nan       nan       nan |    0.9 \n",
      "72     |   0.13368   0.52828   0.89270   0.87210   0.88034   0.75208   0.89163 |       nan       nan       nan |    1.1 \n",
      "73     |   0.13546   0.52651   0.89313   0.87210   0.88083   0.75184   0.89377 |       nan       nan       nan |    1.0 \n",
      "74     |   0.13165   0.51147   0.89778   0.87275   0.88029   0.75094   0.90233 |       nan       nan       nan |    1.0 \n",
      "75     |   0.13084   0.50910   0.89764   0.87235   0.88006   0.74668   0.90164 |       nan       nan       nan |    1.1 \n",
      "76     |   0.12914   0.50416   0.89858   0.87418   0.88110   0.75461   0.90252 |       nan       nan       nan |    1.1 \n",
      "77     |   0.12708   0.49462   0.89108   0.87450   0.87782   0.74736   0.89427 |       nan       nan       nan |    1.1 \n",
      "78     |   0.12576   0.48545   0.89177   0.87534   0.87943   0.75729   0.89356 |       nan       nan       nan |    1.0 \n",
      "79     |   0.12487   0.49470   0.88295   0.87361   0.87288   0.74928   0.88556 |       nan       nan       nan |    1.1 \n",
      "Epoch  |      logl   bceloss  avg prec   auc roc    auc pr aucpr_cal    f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "80     |   0.12271   0.48425   0.90084   0.88722   0.88355   0.77067   0.90337 |       nan       nan       nan |    1.1 \n",
      "81     |   0.12169   0.47353   0.90018   0.87026   0.88266   0.74379   0.90494 |       nan       nan       nan |    1.1 \n",
      "82     |   0.12684   0.50242   0.89876   0.87335   0.88143   0.75473   0.90294 |       nan       nan       nan |    1.2 \n",
      "83     |   0.12985   0.51004   0.90386   0.87897   0.88750   0.76424   0.90320 |       nan       nan       nan |    1.1 \n",
      "84     |   0.12928   0.47681   0.88940   0.88215   0.88160   0.76378   0.88913 |       nan       nan       nan |    1.1 \n",
      "85     |   0.13361   0.54015   0.87537   0.85992   0.86671   0.74583   0.87933 |       nan       nan       nan |    1.0 \n",
      "86     |   0.13100   0.50760   0.88955   0.86598   0.87944   0.72952   0.88965 |       nan       nan       nan |    1.0 \n",
      "87     |   0.13749   0.51923   0.89134   0.87241   0.88373   0.75283   0.88685 |       nan       nan       nan |    1.1 \n",
      "88     |   0.14169   0.50741   0.90877   0.88036   0.89388   0.76952   0.90826 |       nan       nan       nan |    1.0 \n",
      "89     |   0.13392   0.50806   0.90099   0.88019   0.88995   0.77198   0.89544 |       nan       nan       nan |    1.0 \n",
      "90     |   0.12930   0.50032   0.90088   0.87520   0.88357   0.75229   0.90424 |       nan       nan       nan |    1.1 \n",
      "91     |   0.13122   0.50239   0.89689   0.88022   0.88480   0.76251   0.89531 |       nan       nan       nan |    1.0 \n",
      "92     |   0.12467   0.48903   0.90878   0.88400   0.89365   0.77281   0.90400 |       nan       nan       nan |    1.1 \n",
      "93     |   0.12179   0.46504   0.90888   0.89517   0.89372   0.78216   0.90396 |       nan       nan       nan |    1.1 \n",
      "94     |   0.12845   0.48631   0.90315   0.87870   0.88697   0.76280   0.90426 |       nan       nan       nan |    1.0 \n",
      "95     |   0.13276   0.50397   0.88325   0.85996   0.87706   0.72942   0.87982 |       nan       nan       nan |    1.1 \n",
      "96     |   0.13506   0.50550   0.88217   0.85637   0.87295   0.72125   0.88653 |       nan       nan       nan |    1.1 \n",
      "97     |   0.13772   0.50045   0.88860   0.86423   0.88042   0.73637   0.88661 |       nan       nan       nan |    0.9 \n",
      "98     |   0.13147   0.49276   0.88943   0.86671   0.88117   0.73566   0.88643 |       nan       nan       nan |    1.1 \n",
      "99     |   0.13171   0.48375   0.88761   0.86713   0.88103   0.73806   0.88294 |       nan       nan       nan |    1.1 \n"
     ]
    }
   ],
   "source": [
    "end_epoch = current_epoch + args.epochs\n",
    "\n",
    "for epoch in range(current_epoch, end_epoch, 1):\n",
    "    t0 = time.time()\n",
    "    sc.train_class_regr(\n",
    "        net, optimizer,\n",
    "        loader          = loader_tr,\n",
    "        loss_class      = loss_class,\n",
    "        loss_regr       = loss_regr,\n",
    "        dev             = dev,\n",
    "        weights_class   = tasks_class.training_weight * (1-args.regression_weight) * 2,\n",
    "        weights_regr    = tasks_regr.training_weight * args.regression_weight * 2,\n",
    "        censored_weight = tasks_regr.censored_weight,\n",
    "        normalize_loss  = args.normalize_loss,\n",
    "        num_int_batches = num_int_batches,\n",
    "        progress        = False,\n",
    "        writer = writer,\n",
    "        epoch = epoch,\n",
    "        args = args,\n",
    "        scaler = scaler,\n",
    "        nvml_handle = h)\n",
    "\n",
    "    if args.profile == 1:\n",
    "       with open(f\"{args.output_dir}/memprofile.txt\", \"a+\") as profile_file:\n",
    "            profile_file.write(f\"\\nAfter epoch {epoch} model detailed report:\\n\\n\")\n",
    "            with redirect_stdout(profile_file):\n",
    "                 reporter.report()\n",
    "\n",
    "    t1 = time.time()\n",
    "    eval_round = (args.eval_frequency > 0) and ((epoch + 1) % args.eval_frequency == 0)\n",
    "    last_round = epoch == args.epochs - 1\n",
    "\n",
    "    if eval_round or last_round:\n",
    "\n",
    "        results_va = sc.evaluate_class_regr(net, loader_va, \n",
    "                                            loss_class, \n",
    "                                            loss_regr, \n",
    "                                            tasks_class=tasks_class, \n",
    "                                            tasks_regr=tasks_regr, \n",
    "                                            dev=dev, \n",
    "                                            progress = False, \n",
    "                                            normalize_inv=normalize_inv, \n",
    "                                            cal_fact_aucpr=cal_fact_aucpr)\n",
    "        \n",
    "        for key, val in results_va[\"classification_agg\"].items():\n",
    "            writer.add_scalar(\"val_metrics:aggregated/\"+key, val, epoch*batch_size)\n",
    "#             writer.add_scalar(key+\"/va\", val, epoch)            \n",
    "#         for key, val in results_va[\"regression_agg\"].items():\n",
    "#             writer.add_scalar(key+\"/va\", val, epoch)\n",
    "\n",
    "        if args.eval_train:\n",
    "            results_tr = sc.evaluate_class_regr(net, loader_tr, loss_class, loss_regr, tasks_class=tasks_class, tasks_regr=tasks_regr, dev=dev, progress = args.verbose >= 2)\n",
    "            for key, val in results_tr[\"classification_agg\"].items():\n",
    "                writer.add_scalar(\"trn_metrics:aggregated/\"+key, val, epoch *batch_size)                \n",
    "#                 writer.add_scalar(key+\"/tr\", val, epoch)\n",
    "#             for key, val in results_tr[\"regression_agg\"].items():\n",
    "#                 writer.add_scalar(key+\"/tr\", val, epoch)\n",
    "        else:\n",
    "            results_tr = None\n",
    "\n",
    "        if args.verbose:\n",
    "            ## printing a new header every 20 lines\n",
    "            header = num_prints % 20 == 0\n",
    "            num_prints += 1\n",
    "            sc.print_metrics_cr(epoch, t1 - t0, results_tr, results_va, header)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "#print(\"DEBUG data for hidden spliting\")\n",
    "#print (f\"Classification mask: Sum = {net.classmask.sum()}\\t Uniques: {np.unique(net.classmask)}\")\n",
    "#print (f\"Regression mask:     Sum = {net.regmask.sum()}\\t Uniques: {np.unique(net.regmask)}\")\n",
    "#print (f\"overlap: {(net.regmask * net.classmask).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfc869b",
   "metadata": {},
   "source": [
    "## Post Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6a5b742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:05:03.768701Z",
     "start_time": "2022-04-10T18:05:03.146242Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving performance metrics (AUCs) and model.\n",
      "Saved model weights into '../experiments/mini-SparseChem/0410_1959/sc_40.40.40_lr0.001_do0.0.pt'.\n",
      "Saved config and results into '../experiments/mini-SparseChem/0410_1959/sc_40.40.40_lr0.001_do0.0.json'.\n",
      "You can load the results by:\n",
      "  import sparsechem as sc\n",
      "  res = sc.load_results('../experiments/mini-SparseChem/0410_1959/sc_40.40.40_lr0.001_do0.0.json')\n"
     ]
    }
   ],
   "source": [
    "writer.close()\n",
    "vprint()\n",
    "if args.profile == 1:\n",
    "   multiplexer = sc.create_multiplexer(tb_name)\n",
    "#   sc.export_scalars(multiplexer, '.', \"GPUmem\", \"testcsv.csv\")\n",
    "   data = sc.extract_scalars(multiplexer, '.', \"GPUmem\")\n",
    "   vprint(f\"Peak GPU memory used: {sc.return_max_val(data)}MB\")\n",
    "vprint(\"Saving performance metrics (AUCs) and model.\")\n",
    "\n",
    "#####   model saving   #####\n",
    "if not os.path.exists(args.output_dir):\n",
    "   os.makedirs(args.output_dir)\n",
    "\n",
    "model_file = f\"{args.output_dir}/{name}.pt\"\n",
    "out_file   = f\"{args.output_dir}/{name}.json\"\n",
    "\n",
    "if args.save_model:\n",
    "   torch.save(net.state_dict(), model_file)\n",
    "   vprint(f\"Saved model weights into '{model_file}'.\")\n",
    "\n",
    "results_va[\"classification\"][\"num_pos\"] = num_pos_va\n",
    "results_va[\"classification\"][\"num_neg\"] = num_neg_va\n",
    "results_va[\"regression\"][\"num_samples\"] = num_regr_va\n",
    "\n",
    "if results_tr is not None:\n",
    "    results_tr[\"classification\"][\"num_pos\"] = num_pos - num_pos_va\n",
    "    results_tr[\"classification\"][\"num_neg\"] = num_neg - num_neg_va\n",
    "    results_tr[\"regression\"][\"num_samples\"] = num_regr - num_regr_va\n",
    "\n",
    "stats=None\n",
    "if args.normalize_regression == 1 :\n",
    "   stats={}\n",
    "   stats[\"mean\"] = mean_save\n",
    "   stats[\"var\"]  = np.array(var_save)[0]\n",
    "sc.save_results(out_file, args, validation=results_va, training=results_tr, stats=stats)\n",
    "\n",
    "vprint(f\"Saved config and results into '{out_file}'.\\nYou can load the results by:\\n  import sparsechem as sc\\n  res = sc.load_results('{out_file}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4a64acb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:05:03.817295Z",
     "start_time": "2022-04-10T18:05:03.769963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>avg_prec_score</th>\n",
       "      <th>f1_max</th>\n",
       "      <th>p_f1_max</th>\n",
       "      <th>kappa</th>\n",
       "      <th>kappa_max</th>\n",
       "      <th>p_kappa_max</th>\n",
       "      <th>bceloss</th>\n",
       "      <th>auc_pr_cal</th>\n",
       "      <th>num_pos</th>\n",
       "      <th>num_neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972634</td>\n",
       "      <td>0.995563</td>\n",
       "      <td>0.995550</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.701485</td>\n",
       "      <td>0.774872</td>\n",
       "      <td>0.857835</td>\n",
       "      <td>0.701485</td>\n",
       "      <td>0.172520</td>\n",
       "      <td>0.868535</td>\n",
       "      <td>115</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980237</td>\n",
       "      <td>0.024701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>0.997543</td>\n",
       "      <td>0.974935</td>\n",
       "      <td>0.797642</td>\n",
       "      <td>0.797642</td>\n",
       "      <td>0.974935</td>\n",
       "      <td>0.032356</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.967762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.967762</td>\n",
       "      <td>1.698649</td>\n",
       "      <td>0.444742</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.996024</td>\n",
       "      <td>0.996063</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>0.995515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658683</td>\n",
       "      <td>0.995515</td>\n",
       "      <td>0.175056</td>\n",
       "      <td>0.833314</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998376</td>\n",
       "      <td>0.024788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.961665</td>\n",
       "      <td>0.660793</td>\n",
       "      <td>0.793566</td>\n",
       "      <td>0.996210</td>\n",
       "      <td>0.066284</td>\n",
       "      <td>0.989078</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988565</td>\n",
       "      <td>1.092640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
       "task                                                                          \n",
       "0          0.972634  0.995563        0.995550  0.982759  0.701485  0.774872   \n",
       "1               NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "2               NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "3               NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "4               NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "5          1.000000  1.000000        1.000000  1.000000  0.980237  1.000000   \n",
       "6          0.988506  0.999828        0.999828  0.997543  0.974935  0.797642   \n",
       "7          0.750000  0.711111        0.755556  0.750000  0.967762  0.000000   \n",
       "8          0.900000  0.996024        0.996063  0.990991  0.995515  0.000000   \n",
       "9          1.000000  1.000000        1.000000  1.000000  0.998376  0.000000   \n",
       "10              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "11              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "12              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "13              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "14         0.993333  0.999823        0.999825  0.993377  0.961665  0.660793   \n",
       "15              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "16              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "17              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "18              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "19         1.000000  1.000000        1.000000  1.000000  0.988565  0.000000   \n",
       "\n",
       "      kappa_max  p_kappa_max   bceloss  auc_pr_cal  num_pos  num_neg  \n",
       "task                                                                  \n",
       "0      0.857835     0.701485  0.172520    0.868535      115       17  \n",
       "1           NaN          NaN       NaN         NaN       31        0  \n",
       "2           NaN          NaN       NaN         NaN       17        0  \n",
       "3           NaN          NaN       NaN         NaN       54        0  \n",
       "4           NaN          NaN       NaN         NaN        7        0  \n",
       "5      1.000000     0.980237  0.024701    1.000000       18        1  \n",
       "6      0.797642     0.974935  0.032356    0.974026      203        3  \n",
       "7      0.461538     0.967762  1.698649    0.444742        3        4  \n",
       "8      0.658683     0.995515  0.175056    0.833314       55        2  \n",
       "9      1.000000     0.998376  0.024788    1.000000       76        2  \n",
       "10          NaN          NaN       NaN         NaN       63        0  \n",
       "11          NaN          NaN       NaN         NaN        1        0  \n",
       "12          NaN          NaN       NaN         NaN       42        0  \n",
       "13          NaN          NaN       NaN         NaN        0        1  \n",
       "14     0.793566     0.996210  0.066284    0.989078       75        2  \n",
       "15          NaN          NaN       NaN         NaN       36        0  \n",
       "16          NaN          NaN       NaN         NaN        0        0  \n",
       "17          NaN          NaN       NaN         NaN        1        0  \n",
       "18          NaN          NaN       NaN         NaN       43        0  \n",
       "19     1.000000     0.988565  1.092640    1.000000        2        2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_va['classification'][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85cf5728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T17:08:58.823079Z",
     "start_time": "2022-04-10T17:08:58.126972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'classification':       roc_auc_score    auc_pr  avg_prec_score  f1_max  p_f1_max     kappa  \\\n",
      "task                                                                        \n",
      "0          0.993095  0.998994        0.998963  0.9869  0.912304  0.786753   \n",
      "1               NaN       NaN             NaN     NaN       NaN       NaN   \n",
      "2               NaN       NaN             NaN     NaN       NaN       NaN   \n",
      "3               NaN       NaN             NaN     NaN       NaN       NaN   \n",
      "4               NaN       NaN             NaN     NaN       NaN       NaN   \n",
      "...             ...       ...             ...     ...       ...       ...   \n",
      "95              NaN       NaN             NaN     NaN       NaN       NaN   \n",
      "96              NaN       NaN             NaN     NaN       NaN       NaN   \n",
      "97              NaN       NaN             NaN     NaN       NaN       NaN   \n",
      "98         1.000000  1.000000        1.000000  1.0000  0.969434  0.545455   \n",
      "99              NaN       NaN             NaN     NaN       NaN       NaN   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  auc_pr_cal  num_pos  num_neg  \n",
      "task                                                                  \n",
      "0      0.901198     0.912304  0.088834    0.975227      115       17  \n",
      "1           NaN          NaN       NaN         NaN       31        0  \n",
      "2           NaN          NaN       NaN         NaN       17        0  \n",
      "3           NaN          NaN       NaN         NaN       54        0  \n",
      "4           NaN          NaN       NaN         NaN        7        0  \n",
      "...         ...          ...       ...         ...      ...      ...  \n",
      "95          NaN          NaN       NaN         NaN        0        0  \n",
      "96          NaN          NaN       NaN         NaN        3        0  \n",
      "97          NaN          NaN       NaN         NaN        0        0  \n",
      "98     1.000000     0.969434  0.186290    1.000000        1        4  \n",
      "99          NaN          NaN       NaN         NaN        0        0  \n",
      "\n",
      "[100 rows x 12 columns],\n",
      "    'classification_agg': roc_auc_score        0.899007\n",
      "auc_pr               0.940963\n",
      "avg_prec_score       0.942523\n",
      "f1_max               0.930783\n",
      "p_f1_max             0.720770\n",
      "kappa                0.602302\n",
      "kappa_max            0.805113\n",
      "p_kappa_max          0.806334\n",
      "bceloss              0.300770\n",
      "auc_pr_cal           0.819782\n",
      "logloss              0.101692\n",
      "num_tasks_total    100.000000\n",
      "num_tasks_agg       20.000000\n",
      "dtype: float64,\n",
      "    'regression': Empty DataFrame\n",
      "Columns: [rmse, rmse_uncen, rsquared, corrcoef, num_samples]\n",
      "Index: [],\n",
      "    'regression_agg': rmse               NaN\n",
      "rmse_uncen         NaN\n",
      "rsquared           NaN\n",
      "corrcoef           NaN\n",
      "mseloss            NaN\n",
      "num_tasks_total    0.0\n",
      "num_tasks_agg      0.0\n",
      "dtype: float64}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(results_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b214fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f086f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5420fd9c",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc641c6",
   "metadata": {},
   "source": [
    "### Results of run on synthetic data \n",
    "    Run name is 'sc_run_\n",
    "    h40.40_\n",
    "    ldo_r_wd0.0001_\n",
    "    lr0.001_\n",
    "    lrsteps10_\n",
    "    ep20_\n",
    "    fva0_fteNone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ae03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "19     |  0.64258  0.64258  0.86670  0.86844   0.51818  0.79627 |       nan       nan       nan |    1.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f1b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a565db43",
   "metadata": {},
   "source": [
    "### Results of run on synthetic data \n",
    "    Run name is 'sc_run_\n",
    "    h400.400_\n",
    "    ldo_r_wd0.0001_\n",
    "    lr0.001_\n",
    "    lrsteps10_\n",
    "    ep20_\n",
    "    fva: 0 fte: None'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c525e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch  |     logl  bceloss   aucroc    aucpr aucpr_cal   f1_max |      rmse  rsquared  corrcoef | tr_time \n",
    "\n",
    "0      |  0.34269  0.45776  0.80664  0.72646   0.48133  0.74813 |       nan       nan       nan |   13.6 \n",
    "1      |  0.31554  0.42048  0.83178  0.75306   0.51796  0.76370 |       nan       nan       nan |   12.9 \n",
    "2      |  0.31272  0.41163  0.84092  0.76037   0.53157  0.76873 |       nan       nan       nan |   12.8 \n",
    "3      |  0.31439  0.41333  0.84125  0.76524   0.53492  0.77030 |       nan       nan       nan |   12.9 \n",
    "4      |  0.31480  0.41191  0.84390  0.76670   0.53815  0.77059 |       nan       nan       nan |   12.8 \n",
    "5      |  0.31809  0.41840  0.84434  0.76798   0.53912  0.77124 |       nan       nan       nan |   12.9 \n",
    "6      |  0.32237  0.42103  0.84506  0.76737   0.53627  0.77180 |       nan       nan       nan |   12.9 \n",
    "7      |  0.32203  0.42055  0.84465  0.76600   0.53617  0.77124 |       nan       nan       nan |   13.1 \n",
    "8      |  0.32931  0.43144  0.84398  0.76671   0.53747  0.77013 |       nan       nan       nan |   13.1 \n",
    "9      |  0.33162  0.42992  0.84499  0.76793   0.53587  0.77157 |       nan       nan       nan |   13.1 \n",
    "10     |  0.32617  0.42194  0.84909  0.77293   0.54663  0.77418 |       nan       nan       nan |   13.0 \n",
    "11     |  0.32782  0.42469  0.84891  0.77210   0.54406  0.77411 |       nan       nan       nan |   12.9 \n",
    "12     |  0.33080  0.42809  0.84897  0.77252   0.54445  0.77391 |       nan       nan       nan |   12.9 \n",
    "13     |  0.33451  0.43235  0.84840  0.77160   0.54306  0.77383 |       nan       nan       nan |   13.1 \n",
    "14     |  0.33882  0.43660  0.84832  0.77141   0.54322  0.77295 |       nan       nan       nan |   13.1 \n",
    "15     |  0.34108  0.43973  0.84803  0.77172   0.54287  0.77311 |       nan       nan       nan |   13.1 \n",
    "16     |  0.34506  0.44437  0.84782  0.77086   0.54190  0.77230 |       nan       nan       nan |   13.0 \n",
    "17     |  0.34866  0.44951  0.84697  0.77017   0.54043  0.77185 |       nan       nan       nan |   13.0 \n",
    "18     |  0.35135  0.45143  0.84740  0.77087   0.54130  0.77260 |       nan       nan       nan |   13.0 \n",
    "19     |  0.35432  0.45495  0.84742  0.77097   0.54075  0.77233 |       nan       nan       nan |   13.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fab734b",
   "metadata": {},
   "source": [
    "### SparseChem/0116_0843/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                       \n",
    "\n",
    "Saving performance metrics (AUCs) and model.\n",
    "Saved model weights into '/home/kbardool/kusanagi/experiments/SparseChem/0116_0843/sc_run_h25.25.25.25.25.25_ldo_r_wd0.0001_lr0.001_lrsteps10_ep40_fva0_fteNone.pt'.\n",
    "Saved config and results into '/home/kbardool/kusanagi/experiments/SparseChem/0116_0843/sc_run_h25.25.25.25.25.25_ldo_r_wd0.0001_lr0.001_lrsteps10_ep40_fva0_fteNone.json'.\n",
    "You can load the results by:\n",
    "  import sparsechem as sc\n",
    "  res = sc.load_results('/home/kbardool/kusanagi/experiments/SparseChem/0116_0843/sc_run_h25.25.25.25.25.25_ldo_r_wd0.0001_lr0.001_lrsteps10_ep40_fva0_fteNone.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyt-gpu)",
   "language": "python",
   "name": "pyt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
