{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c58a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T18:50:52.221512Z",
     "start_time": "2022-03-04T18:50:52.203972Z"
    }
   },
   "source": [
    "## Train SparseChem on Chembl_mini \n",
    "Output to `experiments/SparseChem`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55155d2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:25.941578Z",
     "start_time": "2022-04-14T14:00:21.197972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find CUDA deivces and reset CUDA stats and cache\n"
     ]
    }
   ],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Copyright (c) 2020 KU Leuven\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os.path\n",
    "import time\n",
    "import json\n",
    "import functools\n",
    "import types\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "import csv\n",
    "import copy \n",
    "from contextlib import redirect_stdout\n",
    "import sparsechem as sc\n",
    "from sparsechem import Nothing\n",
    "from sparsechem.notebook_helper import (check_for_improvement,init_wandb, initialize,\n",
    "                                        assertions)\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_memlab import MemReporter\n",
    "from pynvml import *\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions( linewidth=132)\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'SparseChem_Train_mini.ipynb'\n",
    "if torch.cuda.is_available():\n",
    "    nvmlInit()\n",
    "\n",
    "#import warnings\n",
    "# from torch.serialization import SourceChangeWarning \n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning)    \n",
    "\n",
    "# import multiprocessing\n",
    "# multiprocessing.set_start_method('fork', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db6bd47",
   "metadata": {},
   "source": [
    "### Setup command line parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c1586e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:25.970080Z",
     "start_time": "2022-04-14T14:00:25.943977Z"
    }
   },
   "outputs": [],
   "source": [
    "datadir=\"../MLDatasets/chembl23_mini\"\n",
    "outdir =\"../experiments/mini-SparseChem\"\n",
    "\n",
    "cmd = (\n",
    "  f\" --data_dir                    {datadir} \" +\n",
    "  f\" --output_dir                   {outdir} \" +\n",
    "  f\" --x                 chembl_23mini_x.npy \" +\n",
    "  f\" --y_class           chembl_23mini_y.npy \" +\n",
    "  f\" --folding       chembl_23mini_folds.npy \" +\n",
    "  f\" --dev                               cpu \" +\n",
    "  f\" --fold_va                             0 \" +\n",
    "  f\" --fold_inputs                     32000 \" +\n",
    "  f\" --batch_ratio                      0.01 \" +\n",
    "  f\" --batch_size                        128 \" +\n",
    "  f\" --hidden_sizes              600 600 600 \" +\n",
    "  f\" --dropouts_trunk            0.65 0.65 0.65 \" +\n",
    "  f\" --dropouts_class                      0 \" +\n",
    "  f\" --weight_decay                     1e-4 \" +\n",
    "  f\" --epochs                            100 \" +\n",
    "  f\" --lr                               1e-3 \" +\n",
    "  f\" --lr_steps                           10 \" +\n",
    "  f\" --lr_alpha                          0.3 \" + \n",
    "  f\" --prefix                             sc \" +\n",
    "  f\" --min_samples_class                   1 \"\n",
    ")\n",
    "\n",
    "# f\" --dev              cuda:0 \"\n",
    "# f\" --dev              cuda:0 \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9201bca",
   "metadata": {},
   "source": [
    "### Initializations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784ef5d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:26.004088Z",
     "start_time": "2022-04-14T14:00:25.971321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  command line parms : \n",
      "------------------------\n",
      " data_dir.................  ../MLDatasets/chembl23_mini\n",
      " output_dir...............  ../experiments/mini-SparseChem\n",
      " x........................  chembl_23mini_x.npy\n",
      " y_class..................  chembl_23mini_y.npy\n",
      " y_regr...................  None\n",
      " y_censor.................  None\n",
      " project_name.............  SparseChem-Mini\n",
      " exp_id...................  None\n",
      " exp_name.................  None\n",
      " folder_sfx...............  None\n",
      " weights_class............  None\n",
      " weights_regr.............  None\n",
      " censored_loss............  1\n",
      " folding..................  chembl_23mini_folds.npy\n",
      " fold_va..................  0\n",
      " fold_te..................  None\n",
      " batch_ratio..............  0.01\n",
      " internal_batch_max.......  None\n",
      " normalize_loss...........  None\n",
      " normalize_regression.....  0\n",
      " normalize_regr_va........  0\n",
      " inverse_normalization....  0\n",
      " hidden_sizes.............  [600, 600, 600]\n",
      " last_hidden_sizes........  None\n",
      " weight_decay.............  0.0001\n",
      " last_non_linearity.......  relu\n",
      " middle_non_linearity.....  relu\n",
      " input_transform..........  none\n",
      " lr.......................  0.001\n",
      " lr_alpha.................  0.3\n",
      " lr_steps.................  [10]\n",
      " input_size_freq..........  None\n",
      " fold_inputs..............  32000\n",
      " epochs...................  100\n",
      " pi_zero..................  0.1\n",
      " min_samples_class........  1\n",
      " min_samples_auc..........  None\n",
      " min_samples_regr.........  10\n",
      " dev......................  cpu\n",
      " run_name.................  None\n",
      " prefix...................  sc\n",
      " verbose..................  2\n",
      " save_model...............  1\n",
      " save_board...............  1\n",
      " profile..................  0\n",
      " mixed_precision..........  0\n",
      " eval_train...............  0\n",
      " enable_cat_fusion........  0\n",
      " eval_frequency...........  1\n",
      " batch_size...............  128\n",
      " regression_weight........  0.5\n",
      " scaling_regularizer......  inf\n",
      " class_feature_size.......  -1\n",
      " regression_feature_size..  -1\n",
      " last_hidden_sizes_reg....  None\n",
      " last_hidden_sizes_class..  None\n",
      " dropouts_reg.............  []\n",
      " dropouts_class...........  [0.0]\n",
      " dropouts_trunk...........  [0.65, 0.65, 0.65]\n",
      "\n",
      "\n",
      "\n",
      "../experiments/mini-SparseChem/0414_1600\n",
      "../MLDatasets/chembl23_mini/chembl_23mini_x.npy\n",
      "../MLDatasets/chembl23_mini/chembl_23mini_y.npy\n",
      "../MLDatasets/chembl23_mini/chembl_23mini_folds.npy\n",
      "Run name is 'sc_600.600.600_lr0.001_do0.65'.\n"
     ]
    }
   ],
   "source": [
    "args = initialize(cmd)\n",
    "def vprint(s=\"\"):\n",
    "    if args.verbose:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c7b0ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:26.038042Z",
     "start_time": "2022-04-14T14:00:26.005327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'batch_ratio': 0.01,\n",
      "    'batch_size': 128,\n",
      "    'censored_loss': 1,\n",
      "    'class_feature_size': -1,\n",
      "    'data_dir': '../MLDatasets/chembl23_mini',\n",
      "    'dev': 'cpu',\n",
      "    'dropouts_class': [0.0],\n",
      "    'dropouts_reg': [],\n",
      "    'dropouts_trunk': [0.65, 0.65, 0.65],\n",
      "    'enable_cat_fusion': 0,\n",
      "    'epochs': 100,\n",
      "    'eval_frequency': 1,\n",
      "    'eval_train': 0,\n",
      "    'exp_id': '575n9nj4',\n",
      "    'exp_name': '0414_1600',\n",
      "    'fold_inputs': 32000,\n",
      "    'fold_te': None,\n",
      "    'fold_va': 0,\n",
      "    'folder_sfx': None,\n",
      "    'folding': '../MLDatasets/chembl23_mini/chembl_23mini_folds.npy',\n",
      "    'hidden_sizes': [600, 600, 600],\n",
      "    'input_size_freq': None,\n",
      "    'input_transform': 'none',\n",
      "    'internal_batch_max': None,\n",
      "    'inverse_normalization': 0,\n",
      "    'last_hidden_sizes': None,\n",
      "    'last_hidden_sizes_class': None,\n",
      "    'last_hidden_sizes_reg': None,\n",
      "    'last_non_linearity': 'relu',\n",
      "    'lr': 0.001,\n",
      "    'lr_alpha': 0.3,\n",
      "    'lr_steps': [10],\n",
      "    'middle_non_linearity': 'relu',\n",
      "    'min_samples_auc': None,\n",
      "    'min_samples_class': 1,\n",
      "    'min_samples_regr': 10,\n",
      "    'mixed_precision': 0,\n",
      "    'name': 'sc_600.600.600_lr0.001_do0.65',\n",
      "    'normalize_loss': None,\n",
      "    'normalize_regr_va': 0,\n",
      "    'normalize_regression': 0,\n",
      "    'output_dir': '../experiments/mini-SparseChem/0414_1600',\n",
      "    'pi_zero': 0.1,\n",
      "    'prefix': 'sc',\n",
      "    'profile': 0,\n",
      "    'project_name': 'SparseChem-Mini',\n",
      "    'regression_feature_size': -1,\n",
      "    'regression_weight': 0.5,\n",
      "    'run_name': None,\n",
      "    'save_board': 1,\n",
      "    'save_model': 1,\n",
      "    'scaling_regularizer': inf,\n",
      "    'verbose': 2,\n",
      "    'weight_decay': 0.0001,\n",
      "    'weights_class': None,\n",
      "    'weights_regr': None,\n",
      "    'x': '../MLDatasets/chembl23_mini/chembl_23mini_x.npy',\n",
      "    'y_censor': None,\n",
      "    'y_class': '../MLDatasets/chembl23_mini/chembl_23mini_y.npy',\n",
      "    'y_regr': None}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(vars(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493d6f8",
   "metadata": {},
   "source": [
    "### Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf084ca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:26.062664Z",
     "start_time": "2022-04-14T14:00:26.039819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All assertions passed successfully\n"
     ]
    }
   ],
   "source": [
    "assertions(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3163a92a",
   "metadata": {},
   "source": [
    "### Summary writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af4ac10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:26.097188Z",
     "start_time": "2022-04-14T14:00:26.063836Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.profile == 1:\n",
    "    assert (args.save_board==1), \"Tensorboard should be enabled to be able to profile memory usage.\"\n",
    "if args.save_board:\n",
    "    tb_name = os.path.join(args.output_dir, \"\", args.name)\n",
    "    writer  = SummaryWriter(tb_name)\n",
    "else:\n",
    "    writer = Nothing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1cc295",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8eb691c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:26.258988Z",
     "start_time": "2022-04-14T14:00:26.098731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count non zero:80\n",
      "Input dimension: 32000\n",
      "#samples:        18388\n",
      "#classification tasks:  100\n",
      "#regression tasks:      0\n",
      "Using 20 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "Using 0 regression tasks for calculating metrics (RMSE, Rsquared, correlation).\n"
     ]
    }
   ],
   "source": [
    "ecfp     = sc.load_sparse(args.x)\n",
    "y_class  = sc.load_sparse(args.y_class)\n",
    "y_regr   = sc.load_sparse(args.y_regr)\n",
    "y_censor = sc.load_sparse(args.y_censor)\n",
    "\n",
    "if (y_regr is None) and (y_censor is not None):\n",
    "    raise ValueError(\"y_censor provided please also provide --y_regr.\")\n",
    "if y_class is None:\n",
    "    y_class = scipy.sparse.csr_matrix((ecfp.shape[0], 0))\n",
    "if y_regr is None:\n",
    "    y_regr  = scipy.sparse.csr_matrix((ecfp.shape[0], 0))\n",
    "if y_censor is None:\n",
    "    y_censor = scipy.sparse.csr_matrix(y_regr.shape)\n",
    "\n",
    "folding = np.load(args.folding)\n",
    "assert ecfp.shape[0] == folding.shape[0], \"x and folding must have same number of rows\"\n",
    "\n",
    "## Loading task weights\n",
    "tasks_class = sc.load_task_weights(args.weights_class, y=y_class, label=\"y_class\")\n",
    "tasks_regr  = sc.load_task_weights(args.weights_regr, y=y_regr, label=\"y_regr\")\n",
    "\n",
    "## Input transformation\n",
    "ecfp = sc.fold_transform_inputs(ecfp, folding_size=args.fold_inputs, transform=args.input_transform)\n",
    "print(f\"count non zero:{ecfp[0].count_nonzero()}\")\n",
    "num_pos    = np.array((y_class == +1).sum(0)).flatten()\n",
    "num_neg    = np.array((y_class == -1).sum(0)).flatten()\n",
    "num_class  = np.array((y_class != 0).sum(0)).flatten()\n",
    "if (num_class != num_pos + num_neg).any():\n",
    "    raise ValueError(\"For classification all y values (--y_class/--y) must be 1 or -1.\")\n",
    "\n",
    "num_regr   = np.bincount(y_regr.indices, minlength=y_regr.shape[1])\n",
    "\n",
    "assert args.min_samples_auc is None, \"Parameter 'min_samples_auc' is obsolete. Use '--min_samples_class' that specifies how many samples a task needs per FOLD and per CLASS to be aggregated.\"\n",
    "\n",
    "if tasks_class.aggregation_weight is None:\n",
    "    ## using min_samples rule\n",
    "    fold_pos, fold_neg = sc.class_fold_counts(y_class, folding)\n",
    "    n = args.min_samples_class\n",
    "    tasks_class.aggregation_weight = ((fold_pos >= n).all(0) & (fold_neg >= n)).all(0).astype(np.float64)\n",
    "\n",
    "if tasks_regr.aggregation_weight is None:\n",
    "    if y_censor.nnz == 0:\n",
    "        y_regr2 = y_regr.copy()\n",
    "        y_regr2.data[:] = 1\n",
    "    else:\n",
    "        ## only counting uncensored data\n",
    "        y_regr2      = y_censor.copy()\n",
    "        y_regr2.data = (y_regr2.data == 0).astype(np.int32)\n",
    "    fold_regr, _ = sc.class_fold_counts(y_regr2, folding)\n",
    "    del y_regr2\n",
    "    tasks_regr.aggregation_weight = (fold_regr >= args.min_samples_regr).all(0).astype(np.float64)\n",
    "\n",
    "vprint(f\"Input dimension: {ecfp.shape[1]}\")\n",
    "vprint(f\"#samples:        {ecfp.shape[0]}\")\n",
    "vprint(f\"#classification tasks:  {y_class.shape[1]}\")\n",
    "vprint(f\"#regression tasks:      {y_regr.shape[1]}\")\n",
    "vprint(f\"Using {(tasks_class.aggregation_weight > 0).sum()} classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\")\n",
    "vprint(f\"Using {(tasks_regr.aggregation_weight > 0).sum()} regression tasks for calculating metrics (RMSE, Rsquared, correlation).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aefd037",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:26.299577Z",
     "start_time": "2022-04-14T14:00:26.260614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension   : 32000\n",
      "Input dimension   : 32000\n",
      "Training dataset  : (14633, 32000)\n",
      "Validation dataset: (3755, 32000)\n",
      "\n",
      "#classification tasks:  100\n",
      "#regression tasks    :      0\n",
      "Using  20 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "Using   0 regression tasks for calculating metrics (RMSE, Rsquared, correlation).\n",
      "orig batch size:   128\n",
      "orig num int batches:   1\n",
      "batch size:   128\n",
      "num_int_batches:   1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ed17558e38/ipykernel_11202/3254692387.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pos_rate = num_pos_va/(num_pos_va+num_neg_va)\n"
     ]
    }
   ],
   "source": [
    "if args.fold_te is not None and args.fold_te >= 0:\n",
    "    ## removing test data\n",
    "    assert args.fold_te != args.fold_va, \"fold_va and fold_te must not be equal.\"\n",
    "    keep    = folding != args.fold_te\n",
    "    ecfp    = ecfp[keep]\n",
    "    y_class = y_class[keep]\n",
    "    y_regr  = y_regr[keep]\n",
    "    y_censor = y_censor[keep]\n",
    "    folding = folding[keep]\n",
    "\n",
    "normalize_inv = None\n",
    "if args.normalize_regression == 1 and args.normalize_regr_va == 1:\n",
    "   y_regr, mean_save, var_save = sc.normalize_regr(y_regr)\n",
    "fold_va = args.fold_va\n",
    "idx_tr  = np.where(folding != fold_va)[0]\n",
    "idx_va  = np.where(folding == fold_va)[0]\n",
    "\n",
    "y_class_tr = y_class[idx_tr]\n",
    "y_class_va = y_class[idx_va]\n",
    "y_regr_tr  = y_regr[idx_tr]\n",
    "y_regr_va  = y_regr[idx_va]\n",
    "y_censor_tr = y_censor[idx_tr]\n",
    "y_censor_va = y_censor[idx_va]\n",
    "\n",
    "if args.normalize_regression == 1 and args.normalize_regr_va == 0:\n",
    "   y_regr_tr, mean_save, var_save = sc.normalize_regr(y_regr_tr) \n",
    "   if args.inverse_normalization == 1:\n",
    "      normalize_inv = {}\n",
    "      normalize_inv[\"mean\"] = mean_save\n",
    "      normalize_inv[\"var\"]  = var_save\n",
    "num_pos_va  = np.array((y_class_va == +1).sum(0)).flatten()\n",
    "num_neg_va  = np.array((y_class_va == -1).sum(0)).flatten()\n",
    "num_regr_va = np.bincount(y_regr_va.indices, minlength=y_regr.shape[1])\n",
    "pos_rate = num_pos_va/(num_pos_va+num_neg_va)\n",
    "pos_rate_ref = args.pi_zero\n",
    "pos_rate = np.clip(pos_rate, 0, 0.99)\n",
    "cal_fact_aucpr = pos_rate*(1-pos_rate_ref)/(pos_rate_ref*(1-pos_rate))\n",
    "\n",
    "vprint(f\"Input dimension   : {ecfp.shape[1]}\")\n",
    "vprint(f\"Input dimension   : {ecfp.shape[1]}\")\n",
    "vprint(f\"Training dataset  : {ecfp[idx_tr].shape}\")\n",
    "vprint(f\"Validation dataset: {ecfp[idx_va].shape}\")\n",
    "vprint()\n",
    "vprint(f\"#classification tasks:  {y_class.shape[1]}\")\n",
    "vprint(f\"#regression tasks    :      {y_regr.shape[1]}\")\n",
    "vprint(f\"Using {(tasks_class.aggregation_weight > 0).sum():3d} classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\")\n",
    "vprint(f\"Using {(tasks_regr.aggregation_weight > 0).sum():3d} regression tasks for calculating metrics (RMSE, Rsquared, correlation).\")\n",
    "\n",
    "num_int_batches = 1\n",
    "if args.batch_size is not None:\n",
    "    batch_size = args.batch_size\n",
    "else:\n",
    "    batch_size = int(np.ceil(args.batch_ratio * idx_tr.shape[0]))\n",
    "\n",
    "print(f\"orig batch size:   {batch_size}\")\n",
    "print(f\"orig num int batches:   {num_int_batches}\")\n",
    "\n",
    "if args.internal_batch_max is not None:\n",
    "    if args.internal_batch_max < batch_size:\n",
    "        num_int_batches = int(np.ceil(batch_size / args.internal_batch_max))\n",
    "        batch_size      = int(np.ceil(batch_size / num_int_batches))\n",
    "print(f\"batch size:   {batch_size}\")\n",
    "print(f\"num_int_batches:   {num_int_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cec6aa84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:26.327042Z",
     "start_time": "2022-04-14T14:00:26.300982Z"
    }
   },
   "outputs": [],
   "source": [
    "# #import ipdb; ipdb.set_trace()\n",
    "# batch_size  = int(np.ceil(args.batch_ratio * idx_tr.shape[0]))\n",
    "# num_int_batches = 1\n",
    "\n",
    "# if args.internal_batch_max is not None:\n",
    "#     if args.internal_batch_max < batch_size:\n",
    "#         num_int_batches = int(np.ceil(batch_size / args.internal_batch_max))\n",
    "#         batch_size      = int(np.ceil(batch_size / num_int_batches))\n",
    "# vprint(f\"#internal batch size:   {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4ea279f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:26.354776Z",
     "start_time": "2022-04-14T14:00:26.328454Z"
    }
   },
   "outputs": [],
   "source": [
    "tasks_cat_id_list = None\n",
    "select_cat_ids = None\n",
    "if tasks_class.cat_id is not None:\n",
    "    tasks_cat_id_list = [[x,i] for i,x in enumerate(tasks_class.cat_id) if str(x) != 'nan']\n",
    "    tasks_cat_ids = [i for i,x in enumerate(tasks_class.cat_id) if str(x) != 'nan']\n",
    "    select_cat_ids = np.array(tasks_cat_ids)\n",
    "    cat_id_size = len(tasks_cat_id_list)\n",
    "else:\n",
    "    cat_id_size = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22caef4",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d7561ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:26.393402Z",
     "start_time": "2022-04-14T14:00:26.356048Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_tr = sc.ClassRegrSparseDataset(x=ecfp[idx_tr], y_class=y_class_tr, y_regr=y_regr_tr, y_censor=y_censor_tr, y_cat_columns=select_cat_ids)\n",
    "dataset_va = sc.ClassRegrSparseDataset(x=ecfp[idx_va], y_class=y_class_va, y_regr=y_regr_va, y_censor=y_censor_va, y_cat_columns=select_cat_ids)\n",
    "\n",
    "loader_tr = DataLoader(dataset_tr, batch_size=batch_size, num_workers = 8, pin_memory=True, collate_fn=dataset_tr.collate, shuffle=True)\n",
    "loader_va = DataLoader(dataset_va, batch_size=batch_size, num_workers = 4, pin_memory=True, collate_fn=dataset_va.collate, shuffle=False)\n",
    "\n",
    "args.input_size  = dataset_tr.input_size\n",
    "args.output_size = dataset_tr.output_size\n",
    "\n",
    "args.class_output_size = dataset_tr.class_output_size\n",
    "args.regr_output_size  = dataset_tr.regr_output_size\n",
    "args.cat_id_size = cat_id_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868699b",
   "metadata": {},
   "source": [
    "###  WandB setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f275b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:33.237159Z",
     "start_time": "2022-04-14T14:00:26.395102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575n9nj4 0414_1600 SparseChem-Mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkbardool\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vsc-hard-mounts/leuven-data/326/vsc32647/projs/SparseChem/wandb/run-20220414_160026-575n9nj4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kbardool/SparseChem-Mini/runs/575n9nj4\" target=\"_blank\">0414_1600</a></strong> to <a href=\"https://wandb.ai/kbardool/SparseChem-Mini\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PROJECT NAME: SparseChem-Mini\n",
      " RUN ID      : 575n9nj4 \n",
      " RUN NAME    : 0414_1600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_metric.Metric at 0x2b9121202250>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------------------------------------------------------\n",
    "# ### WandB setup\n",
    "#------------------------------------------------------------------\n",
    "ns = types.SimpleNamespace()\n",
    "ns.current_epoch  = 0\n",
    "ns.current_iter   = 0\n",
    "ns.best_results   = {}\n",
    "ns.best_metrics   = None\n",
    "ns.best_value     = 0 \n",
    "ns.best_iter      = 0\n",
    "ns.best_epoch     = 0\n",
    "ns.p_epoch        = 0\n",
    "ns.num_prints     = 0\n",
    "\n",
    "init_wandb(ns, args)\n",
    "wandb.define_metric(\"best_accuracy\", summary=\"last\")\n",
    "wandb.define_metric(\"best_epoch\", summary=\"last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b834837",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00ec1303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:33.549255Z",
     "start_time": "2022-04-14T14:00:33.239249Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:\n",
      "SparseFFN(\n",
      "  (net): Sequential(\n",
      "    (0): SparseInputNet(\n",
      "      (net_freq): SparseLinear(in_features=32000, out_features=600, bias=True)\n",
      "    )\n",
      "    (1): MiddleNet(\n",
      "      (net): Sequential(\n",
      "        (layer_0): Sequential(\n",
      "          (0): ReLU()\n",
      "          (1): Dropout(p=0.65, inplace=False)\n",
      "          (2): Linear(in_features=600, out_features=600, bias=True)\n",
      "        )\n",
      "        (layer_1): Sequential(\n",
      "          (0): ReLU()\n",
      "          (1): Dropout(p=0.65, inplace=False)\n",
      "          (2): Linear(in_features=600, out_features=600, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classLast): LastNet(\n",
      "    (net): Sequential(\n",
      "      (initial_layer): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): Dropout(p=0.65, inplace=False)\n",
      "        (2): Linear(in_features=600, out_features=100, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (regrLast): Sequential(\n",
      "    (0): LastNet(\n",
      "      (net): Sequential(\n",
      "        (initial_layer): Sequential(\n",
      "          (0): Tanh()\n",
      "          (1): Dropout(p=0.65, inplace=False)\n",
      "          (2): Linear(in_features=600, out_features=0, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/leuven/326/vsc32647/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/torch/nn/init.py:388: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------\n",
    "# ### Network\n",
    "#------------------------------------------------------------------\n",
    "dev  = torch.device(args.dev)\n",
    "\n",
    "net  = sc.SparseFFN(args).to(dev)\n",
    "loss_class = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "loss_regr  = sc.censored_mse_loss\n",
    "\n",
    "if not args.censored_loss:\n",
    "    loss_regr = functools.partial(loss_regr, censored_enabled=False)\n",
    "\n",
    "tasks_class.training_weight = tasks_class.training_weight.to(dev)\n",
    "tasks_regr.training_weight  = tasks_regr.training_weight.to(dev)\n",
    "tasks_regr.censored_weight  = tasks_regr.censored_weight.to(dev)\n",
    "\n",
    "print(\"Network:\")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0b4f16",
   "metadata": {},
   "source": [
    "###  Optimizer, Scheduler, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebcc9050",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:33.583354Z",
     "start_time": "2022-04-14T14:00:33.552499Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/leuven/326/vsc32647/miniconda3/envs/pyt-gpu/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------\n",
    "# ###  Optimizer, Scheduler, GradScaler\n",
    "#------------------------------------------------------------------\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "scheduler = MultiStepLR(optimizer, milestones=args.lr_steps, gamma=args.lr_alpha)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "wandb.watch(net, log='all', log_freq= 10)     ###  Weights and Biases Initialization \n",
    "reporter = None\n",
    "h = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080e975d",
   "metadata": {},
   "source": [
    "### setup memory profiling reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f357697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:33.615187Z",
     "start_time": "2022-04-14T14:00:33.585926Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.profile == 1:\n",
    "   torch_gpu_id = torch.cuda.current_device()\n",
    "   if \"CUDA_VISIBLE_DEVICES\" in os.environ:\n",
    "      ids = list(map(int, os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"\").split(\",\")))\n",
    "      nvml_gpu_id = ids[torch_gpu_id] # remap\n",
    "   else:\n",
    "      nvml_gpu_id = torch_gpu_id\n",
    "   h = nvmlDeviceGetHandleByIndex(nvml_gpu_id)\n",
    "\n",
    "if args.profile == 1:\n",
    "   #####   output saving   #####\n",
    "   if not os.path.exists(args.output_dir):\n",
    "       os.makedirs(args.output_dir)\n",
    "\n",
    "   reporter = MemReporter(net)\n",
    "\n",
    "   with open(f\"{args.output_dir}/memprofile.txt\", \"w+\") as profile_file:\n",
    "        with redirect_stdout(profile_file):\n",
    "             profile_file.write(f\"\\nInitial model detailed report:\\n\\n\")\n",
    "             reporter.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "810b495f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:33.644665Z",
     "start_time": "2022-04-14T14:00:33.616510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "dev                  :    cpu\n",
      "args.lr              :    [600, 600, 600]\n",
      "args.lr              :    0.001\n",
      "args.weight_decay    :    0.0001\n",
      "args.lr_steps        :    [10]\n",
      "args.lr_steps        :    [10]\n",
      "num_int_batches      :    1\n",
      "batch_size           :    128\n",
      "EPOCHS               :    100\n",
      "scaler               :    <torch.cuda.amp.grad_scaler.GradScaler object at 0x2b912178bbe0>\n",
      "args.normalize_loss  :    None\n",
      "loss_class           :    BCEWithLogitsLoss()\n",
      "mixed precision      :    0\n",
      "args.eval_train      :    0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------\n",
    "# ### Display network and other values\n",
    "#------------------------------------------------------------------\n",
    "print(optimizer)\n",
    "# args.eval_train = 0 \n",
    "# args.epochs     = 5\n",
    "print(f\"dev                  :    {dev}\")\n",
    "print(f\"args.lr              :    {args.hidden_sizes}\")\n",
    "print(f\"args.lr              :    {args.lr}\")\n",
    "print(f\"args.weight_decay    :    {args.weight_decay}\")\n",
    "print(f\"args.lr_steps        :    {args.lr_steps}\")\n",
    "print(f\"args.lr_steps        :    {args.lr_steps}\")\n",
    "print(f\"num_int_batches      :    {num_int_batches}\")\n",
    "print(f\"batch_size           :    {batch_size}\")\n",
    "print(f\"EPOCHS               :    {args.epochs}\")\n",
    "print(f\"scaler               :    {scaler}\")\n",
    "print(f\"args.normalize_loss  :    {args.normalize_loss}\")\n",
    "print(f\"loss_class           :    {loss_class}\")\n",
    "print(f\"mixed precision      :    {args.mixed_precision}\")\n",
    "print(f\"args.eval_train      :    {args.eval_train}\")\n",
    "print(dev.type == 'cpu') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64267731",
   "metadata": {},
   "source": [
    "##  Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "628e976d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:00:43.300018Z",
     "start_time": "2022-04-14T14:00:43.266216Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# from torch.serialization import SourceChangeWarning \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9f8fa8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:44:55.040997Z",
     "start_time": "2022-04-14T14:00:43.520880Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  |      logl   bceloss  avg prec   auc roc    auc pr aucpr_cal    f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "0      |   0.12110   0.33791   0.85121   0.82580   0.84244   0.70208   0.86863 |       nan       nan       nan |   11.5 \n",
      "Previous best_epoch:     0   best iter:     0,   best_value: 0.00000\n",
      "New      best_epoch:     0   best iter:     0,   best_value: 0.85121\n",
      "1      |   0.09937   0.27976   0.90203   0.89778   0.89653   0.81097   0.89691 |       nan       nan       nan |   13.1 \n",
      "Previous best_epoch:     0   best iter:     0,   best_value: 0.85121\n",
      "New      best_epoch:     1   best iter:     0,   best_value: 0.90203\n",
      "2      |   0.09358   0.25963   0.93406   0.90278   0.93111   0.83246   0.92854 |       nan       nan       nan |   11.8 \n",
      "Previous best_epoch:     1   best iter:     0,   best_value: 0.90203\n",
      "New      best_epoch:     2   best iter:     0,   best_value: 0.93406\n",
      "3      |   0.08420   0.24055   0.94384   0.90958   0.94219   0.85367   0.94488 |       nan       nan       nan |   13.3 \n",
      "Previous best_epoch:     2   best iter:     0,   best_value: 0.93406\n",
      "New      best_epoch:     3   best iter:     0,   best_value: 0.94384\n",
      "4      |   0.07918   0.23929   0.90470   0.91077   0.89814   0.81224   0.89903 |       nan       nan       nan |   12.9 \n",
      "5      |   0.08189   0.24947   0.94150   0.90678   0.93797   0.83557   0.93486 |       nan       nan       nan |   12.6 \n",
      "6      |   0.08149   0.24779   0.94581   0.90105   0.94371   0.83840   0.93959 |       nan       nan       nan |   12.6 \n",
      "Previous best_epoch:     3   best iter:     0,   best_value: 0.94384\n",
      "New      best_epoch:     6   best iter:     0,   best_value: 0.94581\n",
      "7      |   0.08263   0.24006   0.95077   0.91327   0.94893   0.85061   0.94146 |       nan       nan       nan |   12.8 \n",
      "Previous best_epoch:     6   best iter:     0,   best_value: 0.94581\n",
      "New      best_epoch:     7   best iter:     0,   best_value: 0.95077\n",
      "8      |   0.07771   0.23607   0.89378   0.90338   0.88298   0.79839   0.89704 |       nan       nan       nan |   12.5 \n",
      "9      |   0.08269   0.23958   0.95915   0.93534   0.95745   0.89045   0.94579 |       nan       nan       nan |   12.7 \n",
      "Previous best_epoch:     7   best iter:     0,   best_value: 0.95077\n",
      "New      best_epoch:     9   best iter:     0,   best_value: 0.95915\n",
      "10     |   0.08395   0.24552   0.96186   0.94720   0.95997   0.89609   0.94804 |       nan       nan       nan |   13.6 \n",
      "Previous best_epoch:     9   best iter:     0,   best_value: 0.95915\n",
      "New      best_epoch:    10   best iter:     0,   best_value: 0.96186\n",
      "11     |   0.09128   0.26882   0.96051   0.94483   0.95852   0.89710   0.94568 |       nan       nan       nan |   16.7 \n",
      "12     |   0.08572   0.25431   0.95764   0.94209   0.95512   0.88631   0.94303 |       nan       nan       nan |   18.5 \n",
      "13     |   0.09698   0.28539   0.95166   0.93332   0.94832   0.87644   0.94246 |       nan       nan       nan |   19.0 \n",
      "14     |   0.09665   0.28361   0.95530   0.92212   0.95328   0.88164   0.94185 |       nan       nan       nan |   18.9 \n",
      "15     |   0.09730   0.29775   0.95087   0.92278   0.94784   0.86650   0.93748 |       nan       nan       nan |   19.2 \n",
      "16     |   0.09748   0.28969   0.95197   0.92411   0.94943   0.87580   0.93796 |       nan       nan       nan |   18.7 \n",
      "17     |   0.10048   0.30306   0.95171   0.91296   0.94919   0.85225   0.93921 |       nan       nan       nan |   19.8 \n",
      "18     |   0.10102   0.30589   0.95187   0.90819   0.94991   0.86065   0.94059 |       nan       nan       nan |   30.6 \n",
      "19     |   0.10346   0.31906   0.95914   0.92413   0.95801   0.87743   0.94985 |       nan       nan       nan |   44.0 \n",
      "Epoch  |      logl   bceloss  avg prec   auc roc    auc pr aucpr_cal    f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "20     |   0.10465   0.30668   0.96130   0.93181   0.95983   0.88525   0.94825 |       nan       nan       nan |   44.7 \n",
      "21     |   0.10542   0.31398   0.95324   0.91398   0.95123   0.86501   0.94657 |       nan       nan       nan |   43.5 \n",
      "22     |   0.10973   0.32024   0.94774   0.89723   0.94529   0.84392   0.94574 |       nan       nan       nan |   46.2 \n",
      "23     |   0.11274   0.32826   0.94898   0.90087   0.94658   0.84620   0.94574 |       nan       nan       nan |   42.4 \n",
      "24     |   0.10722   0.31464   0.95077   0.90487   0.94823   0.85029   0.94659 |       nan       nan       nan |   44.6 \n",
      "25     |   0.11778   0.34606   0.95345   0.90716   0.95098   0.86061   0.95142 |       nan       nan       nan |   41.3 \n",
      "26     |   0.10682   0.31680   0.95578   0.91708   0.95365   0.85942   0.95144 |       nan       nan       nan |   46.6 \n",
      "27     |   0.11752   0.34692   0.95096   0.90037   0.94820   0.85009   0.94678 |       nan       nan       nan |   42.6 \n",
      "28     |   0.10867   0.31947   0.94969   0.90061   0.94708   0.84754   0.94647 |       nan       nan       nan |   44.4 \n",
      "29     |   0.10729   0.32490   0.94755   0.89737   0.94529   0.84494   0.94654 |       nan       nan       nan |   45.8 \n",
      "30     |   0.10664   0.33427   0.95479   0.91563   0.95354   0.86222   0.94828 |       nan       nan       nan |   42.6 \n",
      "31     |   0.11168   0.34976   0.94781   0.89845   0.94589   0.83983   0.94773 |       nan       nan       nan |   41.6 \n",
      "32     |   0.11616   0.35816   0.94795   0.89809   0.94616   0.84141   0.94547 |       nan       nan       nan |   42.7 \n",
      "33     |   0.10966   0.33896   0.95077   0.90593   0.94909   0.84751   0.94754 |       nan       nan       nan |   47.2 \n",
      "34     |   0.12607   0.36715   0.94451   0.88598   0.94273   0.83994   0.94797 |       nan       nan       nan |   45.7 \n",
      "35     |   0.11833   0.35811   0.94752   0.89713   0.94578   0.84125   0.94757 |       nan       nan       nan |   46.3 \n",
      "36     |   0.11336   0.36700   0.94491   0.88807   0.94307   0.84250   0.94819 |       nan       nan       nan |   44.3 \n",
      "37     |   0.11214   0.38021   0.94493   0.89929   0.94251   0.82645   0.94228 |       nan       nan       nan |   35.1 \n",
      "38     |   0.11711   0.41063   0.94369   0.89120   0.94159   0.83195   0.94194 |       nan       nan       nan |   20.6 \n",
      "39     |   0.11293   0.37929   0.94237   0.88752   0.94023   0.83434   0.94221 |       nan       nan       nan |   20.4 \n",
      "Epoch  |      logl   bceloss  avg prec   auc roc    auc pr aucpr_cal    f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "40     |   0.11482   0.40578   0.91522   0.88424   0.90040   0.80255   0.92476 |       nan       nan       nan |   20.9 \n",
      "41     |   0.11950   0.40474   0.93924   0.88082   0.93658   0.82164   0.94216 |       nan       nan       nan |   21.5 \n",
      "42     |   0.12057   0.40011   0.94266   0.88483   0.94052   0.83206   0.94221 |       nan       nan       nan |   21.7 \n",
      "43     |   0.13401   0.43613   0.94275   0.88576   0.94061   0.83282   0.94245 |       nan       nan       nan |   20.9 \n",
      "44     |   0.11573   0.37473   0.94524   0.89669   0.94298   0.83508   0.94105 |       nan       nan       nan |   20.4 \n",
      "45     |   0.12620   0.38536   0.94572   0.89768   0.94373   0.82358   0.94273 |       nan       nan       nan |   21.1 \n",
      "46     |   0.12970   0.43069   0.94126   0.88381   0.93903   0.82512   0.94050 |       nan       nan       nan |   22.1 \n",
      "47     |   0.11649   0.39176   0.94791   0.90370   0.94624   0.84186   0.94614 |       nan       nan       nan |   21.0 \n",
      "48     |   0.12440   0.41333   0.94086   0.88945   0.93828   0.82208   0.93770 |       nan       nan       nan |   20.8 \n",
      "49     |   0.12701   0.41301   0.93990   0.89259   0.93730   0.81773   0.93697 |       nan       nan       nan |   20.8 \n",
      "50     |   0.12018   0.43530   0.93932   0.88682   0.93667   0.82044   0.93773 |       nan       nan       nan |   20.6 \n",
      "51     |   0.12741   0.44017   0.94200   0.88993   0.93975   0.83080   0.94038 |       nan       nan       nan |   21.3 \n",
      "52     |   0.11904   0.38289   0.94266   0.89554   0.94004   0.82661   0.94016 |       nan       nan       nan |   20.8 \n",
      "53     |   0.12052   0.40168   0.94305   0.89719   0.94038   0.82719   0.94051 |       nan       nan       nan |   22.2 \n",
      "54     |   0.12063   0.42455   0.93561   0.87980   0.93231   0.81228   0.93766 |       nan       nan       nan |   20.9 \n",
      "55     |   0.12147   0.43488   0.93824   0.88624   0.93509   0.81092   0.93473 |       nan       nan       nan |   21.4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56     |   0.11581   0.39291   0.94053   0.88350   0.93810   0.83249   0.94432 |       nan       nan       nan |   20.8 \n",
      "57     |   0.11451   0.39450   0.93595   0.87821   0.93266   0.81969   0.94025 |       nan       nan       nan |   21.2 \n",
      "58     |   0.11954   0.42541   0.94006   0.88000   0.93730   0.82085   0.94124 |       nan       nan       nan |   22.7 \n",
      "59     |   0.11878   0.44885   0.93932   0.87645   0.93711   0.82294   0.94245 |       nan       nan       nan |   21.2 \n",
      "Epoch  |      logl   bceloss  avg prec   auc roc    auc pr aucpr_cal    f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "60     |   0.12070   0.41997   0.93738   0.87837   0.93457   0.81765   0.93866 |       nan       nan       nan |   21.1 \n",
      "61     |   0.12292   0.43225   0.94017   0.88359   0.93792   0.82866   0.93875 |       nan       nan       nan |   21.9 \n",
      "62     |   0.12901   0.46336   0.93782   0.88185   0.93548   0.82303   0.93931 |       nan       nan       nan |   22.0 \n",
      "63     |   0.12029   0.40952   0.93655   0.87857   0.93418   0.82251   0.93460 |       nan       nan       nan |   21.3 \n",
      "64     |   0.13632   0.43957   0.93978   0.88108   0.93745   0.82487   0.94232 |       nan       nan       nan |   21.3 \n",
      "65     |   0.12484   0.39222   0.93997   0.88055   0.93779   0.82635   0.93929 |       nan       nan       nan |   22.5 \n",
      "66     |   0.12723   0.43756   0.93820   0.87806   0.93594   0.81894   0.94007 |       nan       nan       nan |   21.5 \n",
      "67     |   0.11504   0.42009   0.94099   0.88154   0.93877   0.82435   0.94220 |       nan       nan       nan |   21.8 \n",
      "68     |   0.11309   0.39943   0.94039   0.88240   0.93812   0.82523   0.93956 |       nan       nan       nan |   21.6 \n",
      "69     |   0.11195   0.37836   0.94388   0.88810   0.94152   0.83127   0.94438 |       nan       nan       nan |   22.2 \n",
      "70     |   0.11759   0.39842   0.93914   0.88824   0.93599   0.81093   0.93441 |       nan       nan       nan |   22.7 \n",
      "71     |   0.11500   0.39807   0.94267   0.89919   0.93967   0.81974   0.93572 |       nan       nan       nan |   22.2 \n",
      "72     |   0.10963   0.36412   0.94429   0.90532   0.94138   0.82389   0.93741 |       nan       nan       nan |   22.5 \n",
      "73     |   0.12013   0.36391   0.95043   0.91245   0.94865   0.84566   0.94065 |       nan       nan       nan |   23.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74     |   0.11376   0.41420   0.93751   0.88444   0.93486   0.82702   0.94046 |       nan       nan       nan |   22.4 \n",
      "75     |   0.11521   0.40900   0.91412   0.88579   0.89899   0.80038   0.92706 |       nan       nan       nan |   22.8 \n",
      "76     |   0.11651   0.39107   0.94958   0.90976   0.94781   0.84980   0.94627 |       nan       nan       nan |   24.0 \n",
      "77     |   0.11822   0.38818   0.94944   0.91101   0.94781   0.85226   0.94132 |       nan       nan       nan |   23.1 \n",
      "78     |   0.11836   0.37622   0.94912   0.90968   0.94728   0.84470   0.94232 |       nan       nan       nan |   22.9 \n",
      "79     |   0.12005   0.37983   0.94952   0.91610   0.94744   0.84840   0.94615 |       nan       nan       nan |   23.4 \n",
      "Epoch  |      logl   bceloss  avg prec   auc roc    auc pr aucpr_cal    f1_max |      rmse  rsquared  corrcoef | tr_time \n",
      "80     |   0.12450   0.43207   0.93301   0.88633   0.92901   0.82380   0.94112 |       nan       nan       nan |   22.7 \n",
      "81     |   0.12400   0.40750   0.93314   0.88923   0.92957   0.81888   0.94116 |       nan       nan       nan |   22.6 \n",
      "82     |   0.12078   0.40008   0.93097   0.87764   0.92735   0.82051   0.93771 |       nan       nan       nan |   22.3 \n",
      "83     |   0.12183   0.45303   0.93248   0.88147   0.92893   0.82100   0.94112 |       nan       nan       nan |   23.0 \n",
      "84     |   0.12477   0.43186   0.93046   0.87907   0.92638   0.80152   0.93515 |       nan       nan       nan |   22.3 \n",
      "85     |   0.11877   0.38802   0.94076   0.89120   0.93824   0.82753   0.94075 |       nan       nan       nan |   23.4 \n",
      "86     |   0.11566   0.36816   0.91121   0.87718   0.89585   0.78936   0.91898 |       nan       nan       nan |   23.4 \n",
      "87     |   0.11357   0.36794   0.91002   0.88260   0.89392   0.78609   0.92206 |       nan       nan       nan |   23.5 \n",
      "88     |   0.11344   0.39942   0.91166   0.88474   0.89566   0.78622   0.91832 |       nan       nan       nan |   23.3 \n",
      "89     |   0.11909   0.41219   0.89794   0.87640   0.88594   0.78199   0.91106 |       nan       nan       nan |   23.2 \n",
      "90     |   0.11712   0.40613   0.94020   0.88823   0.93761   0.83666   0.94666 |       nan       nan       nan |   22.9 \n",
      "91     |   0.11371   0.37238   0.92882   0.87326   0.92485   0.81316   0.93552 |       nan       nan       nan |   23.7 \n",
      "92     |   0.12530   0.37357   0.93890   0.89654   0.93513   0.82595   0.94621 |       nan       nan       nan |   23.2 \n",
      "93     |   0.12002   0.36969   0.94377   0.90204   0.94134   0.83260   0.94250 |       nan       nan       nan |   24.1 \n",
      "94     |   0.11382   0.37648   0.94026   0.88991   0.93782   0.83493   0.94288 |       nan       nan       nan |   23.4 \n",
      "95     |   0.11548   0.39294   0.92994   0.86893   0.92618   0.79797   0.93938 |       nan       nan       nan |   23.0 \n",
      "96     |   0.11478   0.39432   0.91755   0.85842   0.91057   0.78094   0.92856 |       nan       nan       nan |   23.1 \n",
      "97     |   0.12088   0.37204   0.92629   0.86592   0.92239   0.80300   0.92993 |       nan       nan       nan |   23.7 \n",
      "98     |   0.10472   0.39098   0.93051   0.87629   0.92690   0.82419   0.93302 |       nan       nan       nan |   22.8 \n",
      "99     |   0.11945   0.40774   0.93332   0.86962   0.93054   0.81167   0.93354 |       nan       nan       nan |   23.2 \n"
     ]
    }
   ],
   "source": [
    "ns.end_epoch = ns.current_epoch + args.epochs\n",
    "\n",
    "for ns.current_epoch in range(ns.current_epoch, ns.end_epoch, 1):\n",
    "    t0 = time.time()\n",
    "    sc.train_class_regr(\n",
    "        net, optimizer,\n",
    "        loader          = loader_tr,\n",
    "        loss_class      = loss_class,\n",
    "        loss_regr       = loss_regr,\n",
    "        dev             = dev,\n",
    "        weights_class   = tasks_class.training_weight * (1-args.regression_weight) * 2,\n",
    "        weights_regr    = tasks_regr.training_weight * args.regression_weight * 2,\n",
    "        censored_weight = tasks_regr.censored_weight,\n",
    "        normalize_loss  = args.normalize_loss,\n",
    "        num_int_batches = num_int_batches,\n",
    "        progress        = False,\n",
    "        writer          = writer,\n",
    "        epoch           = ns.current_epoch,\n",
    "        args            = args,\n",
    "        scaler          = scaler,\n",
    "        nvml_handle     = h)\n",
    "\n",
    "    if args.profile == 1:\n",
    "       with open(f\"{args.output_dir}/memprofile.txt\", \"a+\") as profile_file:\n",
    "            profile_file.write(f\"\\nAfter epoch {epoch} model detailed report:\\n\\n\")\n",
    "            with redirect_stdout(profile_file):\n",
    "                 reporter.report()\n",
    "\n",
    "    t1 = time.time()\n",
    "    eval_round = (args.eval_frequency > 0) and ((ns.current_epoch + 1) % args.eval_frequency == 0)\n",
    "    last_round = ns.current_epoch == args.epochs - 1\n",
    "\n",
    "    if eval_round or last_round:\n",
    "\n",
    "        results_va = sc.evaluate_class_regr(net, loader_va, loss_class, loss_regr, \n",
    "                                            tasks_class= tasks_class, \n",
    "                                            tasks_regr = tasks_regr, \n",
    "                                            dev        = dev, \n",
    "                                            progress   = False, \n",
    "                                            normalize_inv=normalize_inv, \n",
    "                                            cal_fact_aucpr=cal_fact_aucpr)\n",
    "        \n",
    "        for key, val in results_va[\"classification_agg\"].items():\n",
    "            writer.add_scalar(\"val_metrics:aggregated/\"+key, val, ns.current_epoch * batch_size)\n",
    "\n",
    "\n",
    "        if args.eval_train:\n",
    "            results_tr = sc.evaluate_class_regr(net, loader_tr, loss_class, loss_regr, \n",
    "                                                tasks_class = tasks_class, \n",
    "                                                tasks_regr  = tasks_regr, \n",
    "                                                dev         = dev, \n",
    "                                                progress    = args.verbose >= 2)\n",
    "            for key, val in results_tr[\"classification_agg\"].items():\n",
    "                writer.add_scalar(\"trn_metrics:aggregated/\"+key, val, ns.current_epoch * batch_size)\n",
    "\n",
    "        else:\n",
    "            results_tr = None\n",
    "\n",
    "        if args.verbose:\n",
    "            ## printing a new header every 20 lines\n",
    "            header = ns.num_prints % 20 == 0\n",
    "            ns.num_prints += 1\n",
    "            sc.print_metrics_cr(ns.current_epoch, t1 - t0, results_tr, results_va, header)\n",
    "            \n",
    "        wandb.log(results_va[\"classification_agg\"].to_dict())\n",
    "\n",
    "        check_for_improvement(ns, results_va)\n",
    "    \n",
    "    scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3da4a4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T13:58:55.449841Z",
     "start_time": "2022-04-14T13:58:55.364304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch :       44\n",
      "Best Iteration :   0 \n",
      "Best Precision :   0.97445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best Precision :   {ns.best_value:.5f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49c2d58b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T10:50:40.698481Z",
     "start_time": "2022-04-14T10:50:39.736732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch :       60\n",
      "Best Iteration :   0 \n",
      "Best Precision :   0.94426\n",
      "\n",
      "\n",
      "{   'auc_pr': 0.9345455193395412,\n",
      "    'auc_pr_cal': 0.8043372361813058,\n",
      "    'avg_prec_score': 0.9380538265076385,\n",
      "    'bceloss': 0.27802124503068626,\n",
      "    'f1_max': 0.9326228087525288,\n",
      "    'kappa': 0.6152092853635318,\n",
      "    'kappa_max': 0.8013483423275729,\n",
      "    'logloss': 0.08353786508343729,\n",
      "    'num_tasks_agg': 20.0,\n",
      "    'num_tasks_total': 100.0,\n",
      "    'p_f1_max': 0.6366572086059022,\n",
      "    'p_kappa_max': 0.7515333876013757,\n",
      "    'roc_auc_score': 0.8945680896661536}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best Precision :   {ns.best_value:.5f}\\n\")\n",
    "print()\n",
    "pp.pprint(results_va['classification_agg'].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a36fa",
   "metadata": {},
   "source": [
    "## Post Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bbb2748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T11:10:44.092444Z",
     "start_time": "2022-04-14T11:10:42.989121Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving performance metrics (AUCs) and model.\n",
      "Saved model weights into '../experiments/mini-SparseChem/0414_1250/sc_50_lr0.001_do0.0.pt'.\n",
      "Saved config and results into '../experiments/mini-SparseChem/0414_1250/sc_50_lr0.001_do0.0.json'.\n",
      "You can load the results by:\n",
      "  import sparsechem as sc\n",
      "  res = sc.load_results('../experiments/mini-SparseChem/0414_1250/sc_50_lr0.001_do0.0.json')\n"
     ]
    }
   ],
   "source": [
    "#print(\"DEBUG data for hidden spliting\")\n",
    "#print (f\"Classification mask: Sum = {net.classmask.sum()}\\t Uniques: {np.unique(net.classmask)}\")\n",
    "#print (f\"Regression mask:     Sum = {net.regmask.sum()}\\t Uniques: {np.unique(net.regmask)}\")\n",
    "#print (f\"overlap: {(net.regmask * net.classmask).sum()}\")\n",
    "\n",
    "writer.close()\n",
    "vprint()\n",
    "if args.profile == 1:\n",
    "   multiplexer = sc.create_multiplexer(tb_name)\n",
    "#   sc.export_scalars(multiplexer, '.', \"GPUmem\", \"testcsv.csv\")\n",
    "   data = sc.extract_scalars(multiplexer, '.', \"GPUmem\")\n",
    "   vprint(f\"Peak GPU memory used: {sc.return_max_val(data)}MB\")\n",
    "vprint(\"Saving performance metrics (AUCs) and model.\")\n",
    "\n",
    "#####   model saving   #####\n",
    "if not os.path.exists(args.output_dir):\n",
    "   os.makedirs(args.output_dir)\n",
    "\n",
    "model_file = f\"{args.output_dir}/{args.name}.pt\"\n",
    "out_file   = f\"{args.output_dir}/{args.name}.json\"\n",
    "\n",
    "if args.save_model:\n",
    "   torch.save(net.state_dict(), model_file)\n",
    "   vprint(f\"Saved model weights into '{model_file}'.\")\n",
    "\n",
    "results_va[\"classification\"][\"num_pos\"] = num_pos_va\n",
    "results_va[\"classification\"][\"num_neg\"] = num_neg_va\n",
    "results_va[\"regression\"][\"num_samples\"] = num_regr_va\n",
    "\n",
    "if results_tr is not None:\n",
    "    results_tr[\"classification\"][\"num_pos\"] = num_pos - num_pos_va\n",
    "    results_tr[\"classification\"][\"num_neg\"] = num_neg - num_neg_va\n",
    "    results_tr[\"regression\"][\"num_samples\"] = num_regr - num_regr_va\n",
    "\n",
    "stats=None\n",
    "if args.normalize_regression == 1 :\n",
    "   stats={}\n",
    "   stats[\"mean\"] = mean_save\n",
    "   stats[\"var\"]  = np.array(var_save)[0]\n",
    "sc.save_results(out_file, args, validation=results_va, training=results_tr, stats=stats)\n",
    "\n",
    "vprint(f\"Saved config and results into '{out_file}'.\\nYou can load the results by:\\n  import sparsechem as sc\\n  res = sc.load_results('{out_file}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "def44851",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T11:10:49.132692Z",
     "start_time": "2022-04-14T11:10:44.094437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae8bc98d3ad4d828613ebd7b1bee6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "WARNING:\n",
      "\n",
      "You should always run with libnvidia-ml.so that is installed with your\n",
      "NVIDIA Display Driver. By default it's installed in /usr/lib and /usr/lib64.\n",
      "libnvidia-ml.so in GDK package is a stub library that is attached only for\n",
      "build purposes (e.g. machine that you build your application doesn't have\n",
      "to have Display Driver installed).\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Linked to libnvidia-ml library at wrong path : /usr/lib64/libnvidia-ml.so.1\n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "WARNING:\n",
      "\n",
      "You should always run with libnvidia-ml.so that is installed with your\n",
      "NVIDIA Display Driver. By default it's installed in /usr/lib and /usr/lib64.\n",
      "libnvidia-ml.so in GDK package is a stub library that is attached only for\n",
      "build purposes (e.g. machine that you build your application doesn't have\n",
      "to have Display Driver installed).\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Linked to libnvidia-ml library at wrong path : /usr/lib64/libnvidia-ml.so.1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_pr</td><td></td></tr><tr><td>auc_pr_cal</td><td></td></tr><tr><td>avg_prec_score</td><td></td></tr><tr><td>bceloss</td><td></td></tr><tr><td>best_accuracy</td><td></td></tr><tr><td>best_epoch</td><td></td></tr><tr><td>f1_max</td><td></td></tr><tr><td>kappa</td><td></td></tr><tr><td>kappa_max</td><td></td></tr><tr><td>logloss</td><td></td></tr><tr><td>num_tasks_agg</td><td></td></tr><tr><td>num_tasks_total</td><td></td></tr><tr><td>p_f1_max</td><td></td></tr><tr><td>p_kappa_max</td><td></td></tr><tr><td>roc_auc_score</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_pr</td><td>0.93237</td></tr><tr><td>auc_pr_cal</td><td>0.79555</td></tr><tr><td>avg_prec_score</td><td>0.93618</td></tr><tr><td>bceloss</td><td>0.29972</td></tr><tr><td>f1_max</td><td>0.94027</td></tr><tr><td>kappa</td><td>0.60585</td></tr><tr><td>kappa_max</td><td>0.79729</td></tr><tr><td>logloss</td><td>0.0851</td></tr><tr><td>num_tasks_agg</td><td>20.0</td></tr><tr><td>num_tasks_total</td><td>100.0</td></tr><tr><td>p_f1_max</td><td>0.62478</td></tr><tr><td>p_kappa_max</td><td>0.73756</td></tr><tr><td>roc_auc_score</td><td>0.88429</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0414_1250</strong>: <a href=\"https://wandb.ai/kbardool/SparseChem-Mini/runs/25la5fe7\" target=\"_blank\">https://wandb.ai/kbardool/SparseChem-Mini/runs/25la5fe7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220414_125058-25la5fe7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de95601",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8acb7361",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T16:18:49.749390Z",
     "start_time": "2022-04-12T16:18:49.710376Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>auc_pr</th>\n",
       "      <th>avg_prec_score</th>\n",
       "      <th>f1_max</th>\n",
       "      <th>p_f1_max</th>\n",
       "      <th>kappa</th>\n",
       "      <th>kappa_max</th>\n",
       "      <th>p_kappa_max</th>\n",
       "      <th>bceloss</th>\n",
       "      <th>auc_pr_cal</th>\n",
       "      <th>num_pos</th>\n",
       "      <th>num_neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987980</td>\n",
       "      <td>0.998324</td>\n",
       "      <td>0.998300</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.984143</td>\n",
       "      <td>0.786753</td>\n",
       "      <td>0.877266</td>\n",
       "      <td>0.984143</td>\n",
       "      <td>0.116708</td>\n",
       "      <td>0.975328</td>\n",
       "      <td>115</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.996995</td>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.422583</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.997202</td>\n",
       "      <td>0.120043</td>\n",
       "      <td>0.949860</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989261</td>\n",
       "      <td>0.797642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989261</td>\n",
       "      <td>0.016063</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943416</td>\n",
       "      <td>1.419727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.999672</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>0.968706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.983577</td>\n",
       "      <td>0.107240</td>\n",
       "      <td>0.985099</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999539</td>\n",
       "      <td>0.660870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999539</td>\n",
       "      <td>0.017546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.955267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793566</td>\n",
       "      <td>0.998676</td>\n",
       "      <td>0.060385</td>\n",
       "      <td>0.989078</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977183</td>\n",
       "      <td>0.461593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
       "task                                                                          \n",
       "0          0.987980  0.998324        0.998300  0.982301  0.984143  0.786753   \n",
       "1               NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "2               NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "3               NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "4               NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "5          0.944444  0.996995        0.997076  0.972973  0.422583 -0.055556   \n",
       "6          1.000000  1.000000        1.000000  1.000000  0.989261  0.797642   \n",
       "7          1.000000  1.000000        1.000000  1.000000  0.943416  0.000000   \n",
       "8          0.990909  0.999672        0.999675  0.990991  0.968706  0.000000   \n",
       "9          1.000000  1.000000        1.000000  1.000000  0.999539  0.660870   \n",
       "10              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "11              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "12              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "13              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "14         0.993333  0.999823        0.999825  0.993377  0.955267  0.000000   \n",
       "15              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "16              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "17              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "18              NaN       NaN             NaN       NaN       NaN       NaN   \n",
       "19         1.000000  1.000000        1.000000  1.000000  0.977183  0.000000   \n",
       "\n",
       "      kappa_max  p_kappa_max   bceloss  auc_pr_cal  num_pos  num_neg  \n",
       "task                                                                  \n",
       "0      0.877266     0.984143  0.116708    0.975328      115       17  \n",
       "1           NaN          NaN       NaN         NaN       31        0  \n",
       "2           NaN          NaN       NaN         NaN       17        0  \n",
       "3           NaN          NaN       NaN         NaN       54        0  \n",
       "4           NaN          NaN       NaN         NaN        7        0  \n",
       "5      0.641509     0.997202  0.120043    0.949860       18        1  \n",
       "6      1.000000     0.989261  0.016063    1.000000      203        3  \n",
       "7      1.000000     0.943416  1.419727    1.000000        3        4  \n",
       "8      0.791209     0.983577  0.107240    0.985099       55        2  \n",
       "9      1.000000     0.999539  0.017546    1.000000       76        2  \n",
       "10          NaN          NaN       NaN         NaN       63        0  \n",
       "11          NaN          NaN       NaN         NaN        1        0  \n",
       "12          NaN          NaN       NaN         NaN       42        0  \n",
       "13          NaN          NaN       NaN         NaN        0        1  \n",
       "14     0.793566     0.998676  0.060385    0.989078       75        2  \n",
       "15          NaN          NaN       NaN         NaN       36        0  \n",
       "16          NaN          NaN       NaN         NaN        0        0  \n",
       "17          NaN          NaN       NaN         NaN        1        0  \n",
       "18          NaN          NaN       NaN         NaN       43        0  \n",
       "19     1.000000     0.977183  0.461593    1.000000        2        2  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_va['classification'][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c39c504f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T16:18:49.788513Z",
     "start_time": "2022-04-12T16:18:49.750439Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'classification':       roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0           0.98798  0.998324          0.9983  0.982301  0.984143  0.786753   \n",
      "1               NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "2               NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "3               NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "4               NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "...             ...       ...             ...       ...       ...       ...   \n",
      "95              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "96              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "97              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "98          1.00000  1.000000          1.0000  1.000000  0.834234  1.000000   \n",
      "99              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  auc_pr_cal  num_pos  num_neg  \n",
      "task                                                                  \n",
      "0      0.877266     0.984143  0.116708    0.975328      115       17  \n",
      "1           NaN          NaN       NaN         NaN       31        0  \n",
      "2           NaN          NaN       NaN         NaN       17        0  \n",
      "3           NaN          NaN       NaN         NaN       54        0  \n",
      "4           NaN          NaN       NaN         NaN        7        0  \n",
      "...         ...          ...       ...         ...      ...      ...  \n",
      "95          NaN          NaN       NaN         NaN        0        0  \n",
      "96          NaN          NaN       NaN         NaN        3        0  \n",
      "97          NaN          NaN       NaN         NaN        0        0  \n",
      "98     1.000000     0.834234  0.212859    1.000000        1        4  \n",
      "99          NaN          NaN       NaN         NaN        0        0  \n",
      "\n",
      "[100 rows x 12 columns],\n",
      "    'classification_agg': roc_auc_score        0.873713\n",
      "auc_pr               0.914305\n",
      "avg_prec_score       0.922531\n",
      "f1_max               0.927992\n",
      "p_f1_max             0.624488\n",
      "kappa                0.551012\n",
      "kappa_max            0.759049\n",
      "p_kappa_max          0.826102\n",
      "bceloss              0.356790\n",
      "auc_pr_cal           0.771486\n",
      "logloss              0.104300\n",
      "num_tasks_total    100.000000\n",
      "num_tasks_agg       20.000000\n",
      "dtype: float64,\n",
      "    'regression': Empty DataFrame\n",
      "Columns: [rmse, rmse_uncen, rsquared, corrcoef, num_samples]\n",
      "Index: [],\n",
      "    'regression_agg': rmse               NaN\n",
      "rmse_uncen         NaN\n",
      "rsquared           NaN\n",
      "corrcoef           NaN\n",
      "mseloss            NaN\n",
      "num_tasks_total    0.0\n",
      "num_tasks_agg      0.0\n",
      "dtype: float64}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(results_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3695c150",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0412_1319\n"
     ]
    }
   ],
   "source": [
    "print(rstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7bd71",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fa96df3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff228568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T07:37:52.305993Z",
     "start_time": "2022-04-13T07:37:52.296939Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "def restart_wandb(exp_id, exp_name, project_name, resume = \"allow\" ):\n",
    "    print(exp_id, exp_name, project_name) \n",
    "    wandb_run = wandb.init(project = project_name, \n",
    "                                     entity  = \"kbardool\", \n",
    "                                     id      = exp_id, \n",
    "                                     name    = exp_name,\n",
    "                                     resume=resume )\n",
    "    \n",
    "    print(f\" PROJECT NAME: {wandb_run.project}\\n\"\n",
    "          f\" RUN ID      : {wandb_run.id} \\n\"\n",
    "          f\" RUN NAME    : {wandb_run.name}\")     \n",
    " \n",
    "    return wandb_run \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51adf2f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T07:37:58.779180Z",
     "start_time": "2022-04-13T07:37:53.070725Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d2rw3bdq 0413_0509 SparseChem-Mini\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:d2rw3bdq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8471011283e94d06a59a2d75df43c046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "WARNING:\n",
      "\n",
      "You should always run with libnvidia-ml.so that is installed with your\n",
      "NVIDIA Display Driver. By default it's installed in /usr/lib and /usr/lib64.\n",
      "libnvidia-ml.so in GDK package is a stub library that is attached only for\n",
      "build purposes (e.g. machine that you build your application doesn't have\n",
      "to have Display Driver installed).\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Linked to libnvidia-ml library at wrong path : /usr/lib64/libnvidia-ml.so.1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0413_0509</strong>: <a href=\"https://wandb.ai/kbardool/SparseChem-Mini/runs/d2rw3bdq\" target=\"_blank\">https://wandb.ai/kbardool/SparseChem-Mini/runs/d2rw3bdq</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220413_093712-d2rw3bdq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:d2rw3bdq). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.14 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vsc-hard-mounts/leuven-data/326/vsc32647/projs/SparseChem/wandb/run-20220413_093753-d2rw3bdq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/kbardool/SparseChem-Mini/runs/d2rw3bdq\" target=\"_blank\">0413_0509</a></strong> to <a href=\"https://wandb.ai/kbardool/SparseChem-Mini\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PROJECT NAME: SparseChem-Mini\n",
      " RUN ID      : d2rw3bdq \n",
      " RUN NAME    : 0413_0509\n"
     ]
    }
   ],
   "source": [
    "run = restart_wandb(\"d2rw3bdq\",\"0413_0509\",\"SparseChem-Mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcc605ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T07:49:06.657692Z",
     "start_time": "2022-04-13T07:49:06.645775Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/a5e50704be/ipykernel_31013/1322073845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "271944b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T07:48:13.315835Z",
     "start_time": "2022-04-13T07:48:13.311428Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b561a453",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T07:49:03.347430Z",
     "start_time": "2022-04-13T07:49:03.342915Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ffe3f20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:22.065859Z",
     "start_time": "2022-04-10T18:02:21.337434Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# cmd = (\n",
    "#   f\" --x       /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic/chembl_23mini_x.npy \" +\n",
    "#   f\" --y_class /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic/chembl_23mini_adashare_y_all_bin_sparse.npy \" +\n",
    "#   f\" --folding /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic/chembl_23mini_folds.npy \" +\n",
    "#   f\" --output_dir {output_dir}\" +    \n",
    "#   f\" --fold_va           0 \" +\n",
    "#   f\" --batch_ratio    0.02 \" +\n",
    "#   f\" --hidden_sizes   25 25 25 25 25 25 \" +\n",
    "#   f\" --dropouts_trunk  0  0  0  0  0  0 \" +\n",
    "#   f\" --weight_decay   1e-4 \" \n",
    "#   f\" --epochs           40 \" +\n",
    "#   f\" --lr             1e-3 \" +\n",
    "#   f\" --lr_steps         10 \" +\n",
    "#   f\" --lr_alpha        0.3\" \n",
    "# )\n",
    "\n",
    "# cmd = (\n",
    "#   f\" --x       {data_dir}/chembl_23mini_x.npy \" +\n",
    "#   f\" --y_class {data_dir}/chembl_23mini_adashare_y_all_bin_sparse.npy \" +\n",
    "#   f\" --folding {data_dir}/chembl_23mini_folds.npy \" +\n",
    "#   f\" --output_dir {output_dir}\" +    \n",
    "#   f\" --fold_va            0 \" +\n",
    "#   f\" --batch_ratio     0.02 \" +\n",
    "#   f\" --hidden_sizes   40 40 \" +\n",
    "#   f\" --dropouts_trunk  0  0 \" +\n",
    "#   f\" --weight_decay   1e-4 \" +\n",
    "#   f\" --epochs           20 \" +\n",
    "#   f\" --lr             1e-3 \" +\n",
    "#   f\" --lr_steps         10 \" +\n",
    "#   f\" --lr_alpha        0.3 \" \n",
    "# )\n",
    "\n",
    "#   f\" --hidden_sizes   400 400 \" +\n",
    "#   f\" --last_dropout   0.2 \" +\n",
    "#   f\" --middle_dropout 0.2 \" +\n",
    "#   f\" --x       ./{data_dir}/chembl_23_x.mtx \" +\n",
    "#   f\" --y_class ./{data_dir}/chembl_23_y.mtx \" +\n",
    "#   f\" --folding ./{data_dir}/folding_hier_0.6.npy \" +\n",
    "\n",
    "#### copied from SparseChemDev \n",
    "\n",
    "# cmd = (\n",
    "#         f\" --x       ./{data_dir}/chembl_23mini_x.npy\" +\n",
    "#         f\" --y_class ./{data_dir}/chembl_23mini_y.npy\" +\n",
    "#         f\" --folding ./{data_dir}/chembl_23mini_folds.npy\" +\n",
    "#         f\" --hidden_sizes 20 30 40 \" +  \n",
    "#         f\" --output_dir {output_dir}\" +\n",
    "#         f\" --batch_ratio 0.1\" +\n",
    "#         f\" --epochs 2\" +\n",
    "#         f\" --lr 1e-3\" +\n",
    "#         f\" --lr_steps 1\" +\n",
    "#         f\" --dev {dev}\" +\n",
    "#         f\" --verbose 1\")\n",
    "#         f\" --input_size_freq  40\"\n",
    "#         f\" --tail_hidden_size  10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c68af3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data_dir=\"chembl23_data\"\n",
    "# data_dir=\"chembl23_run_01152022\"\n",
    "# rstr = \"synthetic_data_model\" ##random_str(12)\n",
    "# rstr = \"synthetic_data_model_03042022\" ##random_str(12)\n",
    "# output_dir = f\"./models-{rstr}/\"\n",
    "# output_dir = f\"./{data_dir}/models-{rstr}/\"\n",
    "# output dir kbardool/kusanagi/experiments/SparseChem/0116_0843\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd7fea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T17:59:54.268012Z",
     "start_time": "2022-04-10T17:59:54.197660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dev = \"gpu\" \n",
    "# data_dir=\"chembl23_data\"\n",
    "# data_dir=\"chembl23_run_01152022\"\n",
    "# data_dir = \"/home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic\"\n",
    "\n",
    "# rm_output=False\n",
    "\n",
    "# rstr = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "# rstr = \"synthetic_data_model\" ##random_str(12)\n",
    "# rstr = \"synthetic_data_model_03042022\" ##random_str(12)\n",
    "\n",
    "# output_dir = f\"./models-{rstr}/\"\n",
    "# output_dir = f\"./{data_dir}/models-{rstr}/\"\n",
    "\n",
    "# output dir kbardool/kusanagi/experiments/SparseChem/0116_0843\n",
    "# output_dir = f\"/home/kbardool/kusanagi/experiments/SparseChem/{rstr}\"\n",
    "# print(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyt-gpu)",
   "language": "python",
   "name": "pyt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
