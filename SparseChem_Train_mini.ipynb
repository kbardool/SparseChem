{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c58a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T18:50:52.221512Z",
     "start_time": "2022-03-04T18:50:52.203972Z"
    }
   },
   "source": [
    "## Train SparseChem on Chembl_mini \n",
    "Output to `experiments/SparseChem`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55155d2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:37.458210Z",
     "start_time": "2022-05-01T10:29:37.393210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Copyright (c) 2020 KU Leuven\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os.path\n",
    "import time\n",
    "import json\n",
    "import functools\n",
    "import types\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "import csv\n",
    "import copy \n",
    "from contextlib import redirect_stdout\n",
    "import sparsechem as sc\n",
    "from sparsechem import Nothing\n",
    "from sparsechem.notebook_modules import (check_for_improvement,init_wandb, initialize,\n",
    "                                        assertions)\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_memlab import MemReporter\n",
    "from pynvml import *\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan')\n",
    "torch.set_printoptions( linewidth=132)\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'SparseChem_Train_mini.ipynb'\n",
    "if torch.cuda.is_available():\n",
    "    nvmlInit()\n",
    "\n",
    "#import warnings\n",
    "# from torch.serialization import SourceChangeWarning \n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning)    \n",
    "\n",
    "# import multiprocessing\n",
    "# multiprocessing.set_start_method('fork', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db6bd47",
   "metadata": {},
   "source": [
    "### Setup command line parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "58c1586e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:37.498020Z",
     "start_time": "2022-05-01T10:29:37.464764Z"
    }
   },
   "outputs": [],
   "source": [
    "datadir=\"../MLDatasets/chembl23_mini\"\n",
    "outdir =\"../experiments/mini-SparseChem\"\n",
    "\n",
    "cmd = (\n",
    "  f\" --data_dir                    {datadir} \" +\n",
    "  f\" --output_dir                   {outdir} \" +\n",
    "  f\" --x                 chembl_23mini_x.npy \" +\n",
    "  f\" --y_class           chembl_23mini_y.npy \" +\n",
    "  f\" --folding       chembl_23mini_folds.npy \" +\n",
    "  f\" --dev                               cpu \" +\n",
    "  f\" --fold_va                             0 \" +\n",
    "  f\" --fold_inputs                     32000 \" +\n",
    "  f\" --batch_ratio                      0.01 \" +\n",
    "  f\" --batch_size                        128 \" +\n",
    "  f\" --hidden_sizes                     1000 \" +\n",
    "  f\" --dropouts_trunk                   0.45 \" +\n",
    "  f\" --dropouts_class                      0 \" +\n",
    "  f\" --weight_decay                     1e-4 \" +\n",
    "  f\" --epochs                            100 \" +\n",
    "  f\" --lr                               1e-3 \" +\n",
    "  f\" --lr_steps                           10 \" +\n",
    "  f\" --lr_alpha                          0.3 \" + \n",
    "  f\" --prefix                             sc \" +\n",
    "  f\" --min_samples_class                   1 \"\n",
    ")\n",
    "\n",
    "# f\" --dev              cuda:0 \"\n",
    "# f\" --dev              cuda:0 \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9201bca",
   "metadata": {},
   "source": [
    "### Initializations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "784ef5d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:37.580927Z",
     "start_time": "2022-05-01T10:29:37.503380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  command line parms : \n",
      "------------------------\n",
      " data_dir.................  ../MLDatasets/chembl23_mini\n",
      " output_dir...............  ../experiments/mini-SparseChem\n",
      " x........................  chembl_23mini_x.npy\n",
      " y_class..................  chembl_23mini_y.npy\n",
      " project_name.............  SparseChem-Mini\n",
      " exp_id...................  None\n",
      " exp_name.................  None\n",
      " exp_desc.................  \n",
      " folder_sfx...............  None\n",
      " hidden_sizes.............  [1000]\n",
      " dropouts_trunk...........  [0.45]\n",
      " class_feature_size.......  -1\n",
      " last_hidden_sizes........  None\n",
      " epochs...................  100\n",
      " batch_size...............  128\n",
      " weight_decay.............  0.0001\n",
      " last_non_linearity.......  relu\n",
      " middle_non_linearity.....  relu\n",
      " input_transform..........  none\n",
      " lr.......................  0.001\n",
      " lr_alpha.................  0.3\n",
      " lr_steps.................  [10]\n",
      " weights_class............  None\n",
      " weights_regr.............  None\n",
      " fold_va..................  0\n",
      " fold_te..................  None\n",
      " batch_ratio..............  0.01\n",
      " internal_batch_max.......  None\n",
      " censored_loss............  1\n",
      " folding..................  chembl_23mini_folds.npy\n",
      " y_regr...................  None\n",
      " y_censor.................  None\n",
      " normalize_loss...........  None\n",
      " normalize_regression.....  0\n",
      " normalize_regr_va........  0\n",
      " inverse_normalization....  0\n",
      " input_size_freq..........  None\n",
      " fold_inputs..............  32000\n",
      " pi_zero..................  0.1\n",
      " min_samples_class........  1\n",
      " min_samples_auc..........  None\n",
      " min_samples_regr.........  10\n",
      " dev......................  cpu\n",
      " run_name.................  None\n",
      " prefix...................  sc\n",
      " verbose..................  2\n",
      " save_model...............  1\n",
      " save_board...............  1\n",
      " profile..................  0\n",
      " mixed_precision..........  0\n",
      " eval_train...............  0\n",
      " enable_cat_fusion........  0\n",
      " eval_frequency...........  1\n",
      " regression_weight........  0.5\n",
      " scaling_regularizer......  inf\n",
      " regression_feature_size..  -1\n",
      " last_hidden_sizes_reg....  None\n",
      " last_hidden_sizes_class..  None\n",
      " dropouts_reg.............  []\n",
      " dropouts_class...........  [0.0]\n",
      "\n",
      "\n",
      "\n",
      "../experiments/mini-SparseChem/1000x0_0501_1229_lr0.001_do0.45\n",
      "../MLDatasets/chembl23_mini/chembl_23mini_x.npy\n",
      "../MLDatasets/chembl23_mini/chembl_23mini_y.npy\n",
      "../MLDatasets/chembl23_mini/chembl_23mini_folds.npy\n",
      "0 1000\n",
      "Run name is 'sc_1000_lr0.001_do0.45'.\n"
     ]
    }
   ],
   "source": [
    "args = initialize(cmd)\n",
    "def vprint(s=\"\"):\n",
    "    if args.verbose:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "01c7b0ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:37.664026Z",
     "start_time": "2022-05-01T10:29:37.586204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'batch_ratio': 0.01,\n",
      "    'batch_size': 128,\n",
      "    'censored_loss': 1,\n",
      "    'class_feature_size': -1,\n",
      "    'data_dir': '../MLDatasets/chembl23_mini',\n",
      "    'dev': 'cpu',\n",
      "    'dropouts_class': [0.0],\n",
      "    'dropouts_reg': [],\n",
      "    'dropouts_trunk': [0.45],\n",
      "    'enable_cat_fusion': 0,\n",
      "    'epochs': 100,\n",
      "    'eval_frequency': 1,\n",
      "    'eval_train': 0,\n",
      "    'exp_desc': '',\n",
      "    'exp_id': '1inin34j',\n",
      "    'exp_name': '0501_1229',\n",
      "    'fold_inputs': 32000,\n",
      "    'fold_te': None,\n",
      "    'fold_va': 0,\n",
      "    'folder_sfx': None,\n",
      "    'folding': '../MLDatasets/chembl23_mini/chembl_23mini_folds.npy',\n",
      "    'hdn_layer_size': 1000,\n",
      "    'hidden_sizes': [1000],\n",
      "    'input_size_freq': None,\n",
      "    'input_transform': 'none',\n",
      "    'internal_batch_max': None,\n",
      "    'inverse_normalization': 0,\n",
      "    'last_hidden_sizes': None,\n",
      "    'last_hidden_sizes_class': None,\n",
      "    'last_hidden_sizes_reg': None,\n",
      "    'last_non_linearity': 'relu',\n",
      "    'lr': 0.001,\n",
      "    'lr_alpha': 0.3,\n",
      "    'lr_steps': [10],\n",
      "    'middle_non_linearity': 'relu',\n",
      "    'min_samples_auc': None,\n",
      "    'min_samples_class': 1,\n",
      "    'min_samples_regr': 10,\n",
      "    'mixed_precision': 0,\n",
      "    'name': 'sc_1000_lr0.001_do0.45',\n",
      "    'normalize_loss': None,\n",
      "    'normalize_regr_va': 0,\n",
      "    'normalize_regression': 0,\n",
      "    'num_hdn_layers': 0,\n",
      "    'output_dir': '../experiments/mini-SparseChem/1000x0_0501_1229_lr0.001_do0.45',\n",
      "    'pi_zero': 0.1,\n",
      "    'prefix': 'sc',\n",
      "    'profile': 0,\n",
      "    'project_name': 'SparseChem-Mini',\n",
      "    'regression_feature_size': -1,\n",
      "    'regression_weight': 0.5,\n",
      "    'run_name': None,\n",
      "    'save_board': 1,\n",
      "    'save_model': 1,\n",
      "    'scaling_regularizer': inf,\n",
      "    'verbose': 2,\n",
      "    'weight_decay': 0.0001,\n",
      "    'weights_class': None,\n",
      "    'weights_regr': None,\n",
      "    'x': '../MLDatasets/chembl23_mini/chembl_23mini_x.npy',\n",
      "    'y_censor': None,\n",
      "    'y_class': '../MLDatasets/chembl23_mini/chembl_23mini_y.npy',\n",
      "    'y_regr': None}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(vars(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493d6f8",
   "metadata": {},
   "source": [
    "### Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf084ca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:37.703231Z",
     "start_time": "2022-05-01T10:29:37.667746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All assertions passed successfully\n"
     ]
    }
   ],
   "source": [
    "assertions(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3163a92a",
   "metadata": {},
   "source": [
    "### Summary writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7af4ac10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:37.749887Z",
     "start_time": "2022-05-01T10:29:37.707602Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.profile == 1:\n",
    "    assert (args.save_board==1), \"Tensorboard should be enabled to be able to profile memory usage.\"\n",
    "if args.save_board:\n",
    "    # tb_name = os.path.join(args.output_dir, \"\", args.name)\n",
    "    writer  = SummaryWriter(args.output_dir)\n",
    "else:\n",
    "    writer = Nothing()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1cc295",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c8eb691c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:37.990103Z",
     "start_time": "2022-05-01T10:29:37.754223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count non zero:80\n",
      "Input dimension: 32000\n",
      "#samples:        18388\n",
      "#classification tasks:  100\n",
      "#regression tasks:      0\n",
      "Using 20 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "Using 0 regression tasks for calculating metrics (RMSE, Rsquared, correlation).\n"
     ]
    }
   ],
   "source": [
    "ecfp     = sc.load_sparse(args.x)\n",
    "y_class  = sc.load_sparse(args.y_class)\n",
    "y_regr   = sc.load_sparse(args.y_regr)\n",
    "y_censor = sc.load_sparse(args.y_censor)\n",
    "\n",
    "if (y_regr is None) and (y_censor is not None):\n",
    "    raise ValueError(\"y_censor provided please also provide --y_regr.\")\n",
    "if y_class is None:\n",
    "    y_class = scipy.sparse.csr_matrix((ecfp.shape[0], 0))\n",
    "if y_regr is None:\n",
    "    y_regr  = scipy.sparse.csr_matrix((ecfp.shape[0], 0))\n",
    "if y_censor is None:\n",
    "    y_censor = scipy.sparse.csr_matrix(y_regr.shape)\n",
    "\n",
    "# Load folding\n",
    "folding = np.load(args.folding)\n",
    "assert ecfp.shape[0] == folding.shape[0], \"x and folding must have same number of rows\"\n",
    "\n",
    "## Loading task weights\n",
    "tasks_class = sc.load_task_weights(args.weights_class, y=y_class, label=\"y_class\")\n",
    "tasks_regr  = sc.load_task_weights(args.weights_regr, y=y_regr, label=\"y_regr\")\n",
    "\n",
    "## Input and folding transformation\n",
    "ecfp = sc.fold_transform_inputs(ecfp, folding_size=args.fold_inputs, transform=args.input_transform)\n",
    "print(f\"count non zero:{ecfp[0].count_nonzero()}\")\n",
    "\n",
    "\n",
    "num_pos    = np.array((y_class == +1).sum(0)).flatten()\n",
    "num_neg    = np.array((y_class == -1).sum(0)).flatten()\n",
    "num_class  = np.array((y_class != 0).sum(0)).flatten()\n",
    "if (num_class != num_pos + num_neg).any():\n",
    "    raise ValueError(\"For classification all y values (--y_class/--y) must be 1 or -1.\")\n",
    "\n",
    "num_regr   = np.bincount(y_regr.indices, minlength=y_regr.shape[1])\n",
    "\n",
    "assert args.min_samples_auc is None, \"Parameter 'min_samples_auc' is obsolete. Use '--min_samples_class' that specifies how many samples a task needs per FOLD and per CLASS to be aggregated.\"\n",
    "\n",
    "## Aggregation Weights \n",
    "if tasks_class.aggregation_weight is None:\n",
    "    ## using min_samples rule\n",
    "    fold_pos, fold_neg = sc.class_fold_counts(y_class, folding)\n",
    "    n = args.min_samples_class\n",
    "    tasks_class.aggregation_weight = ((fold_pos >= n).all(0) & (fold_neg >= n)).all(0).astype(np.float64)\n",
    "\n",
    "if tasks_regr.aggregation_weight is None:\n",
    "    if y_censor.nnz == 0:\n",
    "        y_regr2 = y_regr.copy()\n",
    "        y_regr2.data[:] = 1\n",
    "    else:\n",
    "        ## only counting uncensored data\n",
    "        y_regr2      = y_censor.copy()\n",
    "        y_regr2.data = (y_regr2.data == 0).astype(np.int32)\n",
    "    fold_regr, _ = sc.class_fold_counts(y_regr2, folding)\n",
    "    del y_regr2\n",
    "    tasks_regr.aggregation_weight = (fold_regr >= args.min_samples_regr).all(0).astype(np.float64)\n",
    "\n",
    "vprint(f\"Input dimension: {ecfp.shape[1]}\")\n",
    "vprint(f\"#samples:        {ecfp.shape[0]}\")\n",
    "vprint(f\"#classification tasks:  {y_class.shape[1]}\")\n",
    "vprint(f\"#regression tasks:      {y_regr.shape[1]}\")\n",
    "vprint(f\"Using {(tasks_class.aggregation_weight > 0).sum()} classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\")\n",
    "vprint(f\"Using {(tasks_regr.aggregation_weight > 0).sum()} regression tasks for calculating metrics (RMSE, Rsquared, correlation).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ecb0275c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:38.039931Z",
     "start_time": "2022-05-01T10:29:37.993508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18704 [3804 3851 3718 3702 3629]\n",
      "[[115  31  17  54   7  18 203   3  55  76  63   1  42   0  75  36   0   1  43   2   7   7   0   3   0  21   1  37 330  11  86   0   0 142  27  25\n",
      "    4   7 111  12   7  79   0  97 129  15  10   9   9  38 272   1   2   0 285  63 185   1   0   4  19  21  13   0  18  12   0   0  93  55   1  73\n",
      "   29  41  18   0  46  37  14   0  40  18   6   8  10 330   6   4   1   0   0   0   8   0   0   0   3   0   1   0]\n",
      " [179   1  13  70   8   8 124   3  57  65  10   3  28   0  62  75   0   5  21   3  11  13   4   0   1  11   0  32 300   8 118   0   0 153  57  25\n",
      "    2   5 111  12   2  59   1  47 110  15  21   1   6  43 276   1   4   4 329   7 185 108   1  11  34  14   7   0  20  19   1   0 101  75   1  68\n",
      "   14  21  29   0  83  61   9   0  50   2   5   6   2 359  24   1   4   0   0   0   5   0   0   6   0   0   1   0]\n",
      " [237   0  10  63  15   6 144   3  59  64  67   2  14   0  48  34   0   4  25   6   3   8  12   4   4   6   1  35 250   3  66   0   0 119 133  24\n",
      "    0   8 117  12  18  31   0  78  78   9  26  12  10  38 296   0   4   3 280  45 172   1   5  14   5  11  20   0  16  24   0   0  85  65   0  73\n",
      "   25  20  16   0  51  42  13   0  58  22  10   8  10 347  20   3   9   0   0   0  23   0   0  12   3   0   0   1]\n",
      " [171   0  12  37  19   6 121   2  77  46 221   1  18   0  58  35   0   0  53   5  12   6   0  27   2  17   0  20 200   4  63   1   0 132  55  28\n",
      "    0   3 101  10   0 125   0  66 138  26  20  14  20  73 268   0  10   2 237  11 188   1  11  16   8  17  20   0  14   2   0   0  91  38   4  61\n",
      "   14  27 125   0  21  45   4  14  35  22   9   9   4 248  12   3   1   0   0   0  45   1   0  10   6   0   3   0]\n",
      " [182  27   7  60   6   5 157   3  44  91  62   6  17   1  38  33   0   1  48  11  13   2   0   9   2  15   5  39 319   9 114   0   0 129  55  40\n",
      "    0   8 112   6   0  31   0  62  80   7  17   0  10  67 254   1   4   0 277  22 241   2  14  10   4  11   3   0  18   1   1   0  95  40   3  42\n",
      "    9  37  11   0  50  47  22   0  47  15   0  10   6 326  12   5   7   0   0   0  21   0   0   4   2   0   5   0]]\n",
      "\n",
      "2445 [505 540 469 467 464]\n",
      "[[ 17   0   0   0   0   1   3   4   2   2   0   0   0   1   2   0   0   0   0   2   0   0  13   0   0   0   0   0   6   0   0  30   0   0   0   3\n",
      "    3   3   2   0   0   1   1   1  18   0   2   0  85   0   0   2  13  47   1  11   0   0   0   2   0   1   1   1   3   0   0   0   0   0  18   0\n",
      "    9   3   0   4   1   0  23  11   6   0   5   0   0  46   4   4  73   2   0   7   1   0   0   0   0   0   4   0]\n",
      " [ 27   0   0   0   0   0   2   2   5   4   0   0   0   3   0   0   0   0   0   2   0   5   0   0   0   0   0   0  11   0   0  34   0   4   0  17\n",
      "    0   3   1   0   0   0   0   0   6   0   0   0  37   2   0   0  11  79   4  28   0   0   0   1   0   2   0   1  13   0   0   0   1   1   2   1\n",
      "    2   2   0   7   0   0  23   4   9   0   4   0   0  35   1   3 115   1   0   2   0   5   0   0   1   0  13   4]\n",
      " [ 18   0   0   0   0   1  15   0   0   2   0   0   0   2   0   0   0   0   0   2   0   2   2   0   0   0   0   0   9   0   0  33   0   2   0  17\n",
      "    1   5   5   0   0   0   0   0  11   0   0   0  51   0   0   0   5  48   3  23   2   0   0   1   0   0   0   0   5   1   0   0   1   0   5   1\n",
      "   16   2   0   6   0   0  22   2   6   0   2   0   0  42   1   4  52   5   0  18   0   5   0   0   0   0   9   4]\n",
      " [  5   0   0   0   0   1   7   1   0   3   0   0   0   1   1   0   0   0   0   3   0   3   1   0   0   0   0   0  16   0   0  19   0   0   0  15\n",
      "    2   3   3   0   0   0   0   0  11   0   3   0  56   0   0   0  16  19   5   6   0   0   0   3   0   0   2   0  18   0   0   1   3   0  15   0\n",
      "   22   4   1   4   0   0  16   1   9   0   3   0   0  61   5   1  86   2   0   0   0   4   0   0   1   0   3   2]\n",
      " [ 16   0   0   0   0   0   2   0   2   0   0   0   0   5   0   0   0   0   0   0   0   3   5   0   0   0   0   0   3   0   0  27   0   3   0   4\n",
      "    3   4   6   0   0   0   0   0  26   0   5   0  51   0   0   0   3  52   4   9   2   0   0   2   0   2   0   0  18   0   0   0   0   1   4   0\n",
      "   15   0   0   3   2   0  17   3   8   0   5   0   1  36   5   1  74  22   0   0   0   3   0   0   0   0   3   4]]\n"
     ]
    }
   ],
   "source": [
    "(tasks_class.aggregation_weight > 0).sum()\n",
    "fold_pos.shape\n",
    "print(fold_pos.sum(), fold_pos.sum(axis=-1))\n",
    "print(fold_pos)\n",
    "print()\n",
    "print(fold_neg.sum(), fold_neg.sum(axis=-1))\n",
    "print(fold_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6da79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T19:58:14.892601Z",
     "start_time": "2022-04-28T19:58:14.854938Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "97e10187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:38.085530Z",
     "start_time": "2022-05-01T10:29:38.043269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(tasks_class.aggregation_weight.sum())\n",
    "print(tasks_class.aggregation_weight)\n",
    "print(tasks_class.training_weight)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f5d2df5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:38.158154Z",
     "start_time": "2022-05-01T10:29:38.090726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension   : 32000\n",
      "Input dimension   : 32000\n",
      "Training dataset  : (14633, 32000)\n",
      "Validation dataset: (3755, 32000)\n",
      "\n",
      "#classification tasks:  100\n",
      "#regression tasks    :      0\n",
      "Using  20 classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\n",
      "Using   0 regression tasks for calculating metrics (RMSE, Rsquared, correlation).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_361/62202794.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pos_rate = num_pos_va/(num_pos_va+num_neg_va)\n"
     ]
    }
   ],
   "source": [
    "## Separation of test data\n",
    "if args.fold_te is not None and args.fold_te >= 0:\n",
    "    ## removing test data\n",
    "    assert args.fold_te != args.fold_va, \"fold_va and fold_te must not be equal.\"\n",
    "    keep    = folding != args.fold_te\n",
    "    ecfp    = ecfp[keep]\n",
    "    y_class = y_class[keep]\n",
    "    y_regr  = y_regr[keep]\n",
    "    y_censor = y_censor[keep]\n",
    "    folding = folding[keep]\n",
    "\n",
    "## Regression Normalization    \n",
    "normalize_inv = None\n",
    "if args.normalize_regression == 1 and args.normalize_regr_va == 1:\n",
    "   y_regr, mean_save, var_save = sc.normalize_regr(y_regr)\n",
    "\n",
    "## Separation of train and Validation data\n",
    "fold_va = args.fold_va\n",
    "idx_tr  = np.where(folding != fold_va)[0]\n",
    "idx_va  = np.where(folding == fold_va)[0]\n",
    "\n",
    "y_class_tr = y_class[idx_tr]\n",
    "y_class_va = y_class[idx_va]\n",
    "y_regr_tr  = y_regr[idx_tr]\n",
    "y_regr_va  = y_regr[idx_va]\n",
    "y_censor_tr = y_censor[idx_tr]\n",
    "y_censor_va = y_censor[idx_va]\n",
    "\n",
    "## REgression normalization\n",
    "if args.normalize_regression == 1 and args.normalize_regr_va == 0:\n",
    "   y_regr_tr, mean_save, var_save = sc.normalize_regr(y_regr_tr) \n",
    "   if args.inverse_normalization == 1:\n",
    "      normalize_inv = {}\n",
    "      normalize_inv[\"mean\"] = mean_save\n",
    "      normalize_inv[\"var\"]  = var_save\n",
    "    \n",
    "num_pos_va  = np.array((y_class_va == +1).sum(0)).flatten()\n",
    "num_neg_va  = np.array((y_class_va == -1).sum(0)).flatten()\n",
    "num_regr_va = np.bincount(y_regr_va.indices, minlength=y_regr.shape[1])\n",
    "pos_rate = num_pos_va/(num_pos_va+num_neg_va)\n",
    "pos_rate_ref = args.pi_zero\n",
    "pos_rate = np.clip(pos_rate, 0, 0.99)\n",
    "cal_fact_aucpr = pos_rate*(1-pos_rate_ref)/(pos_rate_ref*(1-pos_rate))\n",
    "\n",
    "vprint(f\"Input dimension   : {ecfp.shape[1]}\")\n",
    "vprint(f\"Input dimension   : {ecfp.shape[1]}\")\n",
    "vprint(f\"Training dataset  : {ecfp[idx_tr].shape}\")\n",
    "vprint(f\"Validation dataset: {ecfp[idx_va].shape}\")\n",
    "vprint()\n",
    "vprint(f\"#classification tasks:  {y_class.shape[1]}\")\n",
    "vprint(f\"#regression tasks    :      {y_regr.shape[1]}\")\n",
    "vprint(f\"Using {(tasks_class.aggregation_weight > 0).sum():3d} classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\")\n",
    "vprint(f\"Using {(tasks_regr.aggregation_weight > 0).sum():3d} regression tasks for calculating metrics (RMSE, Rsquared, correlation).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31863130",
   "metadata": {},
   "source": [
    "### Batch Size Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0aefd037",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:38.206918Z",
     "start_time": "2022-05-01T10:29:38.161940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig batch size:   128\n",
      "orig num int batches:   1\n",
      "batch size:   128\n",
      "num_int_batches:   1\n"
     ]
    }
   ],
   "source": [
    "num_int_batches = 1\n",
    "if args.batch_size is not None:\n",
    "    batch_size = args.batch_size\n",
    "else:\n",
    "    batch_size = int(np.ceil(args.batch_ratio * idx_tr.shape[0]))\n",
    "\n",
    "print(f\"orig batch size:   {batch_size}\")\n",
    "print(f\"orig num int batches:   {num_int_batches}\")\n",
    "\n",
    "if args.internal_batch_max is not None:\n",
    "    if args.internal_batch_max < batch_size:\n",
    "        num_int_batches = int(np.ceil(batch_size / args.internal_batch_max))\n",
    "        batch_size      = int(np.ceil(batch_size / num_int_batches))\n",
    "print(f\"batch size:   {batch_size}\")\n",
    "print(f\"num_int_batches:   {num_int_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cec6aa84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:38.263066Z",
     "start_time": "2022-05-01T10:29:38.211365Z"
    }
   },
   "outputs": [],
   "source": [
    "# #import ipdb; ipdb.set_trace()\n",
    "# batch_size  = int(np.ceil(args.batch_ratio * idx_tr.shape[0]))\n",
    "# num_int_batches = 1\n",
    "\n",
    "# if args.internal_batch_max is not None:\n",
    "#     if args.internal_batch_max < batch_size:\n",
    "#         num_int_batches = int(np.ceil(batch_size / args.internal_batch_max))\n",
    "#         batch_size      = int(np.ceil(batch_size / num_int_batches))\n",
    "# vprint(f\"#internal batch size:   {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d4ea279f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:38.319372Z",
     "start_time": "2022-05-01T10:29:38.268482Z"
    }
   },
   "outputs": [],
   "source": [
    "tasks_cat_id_list = None\n",
    "select_cat_ids = None\n",
    "if tasks_class.cat_id is not None:\n",
    "    tasks_cat_id_list = [[x,i] for i,x in enumerate(tasks_class.cat_id) if str(x) != 'nan']\n",
    "    tasks_cat_ids = [i for i,x in enumerate(tasks_class.cat_id) if str(x) != 'nan']\n",
    "    select_cat_ids = np.array(tasks_cat_ids)\n",
    "    cat_id_size = len(tasks_cat_id_list)\n",
    "else:\n",
    "    cat_id_size = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22caef4",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5d7561ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:38.373339Z",
     "start_time": "2022-05-01T10:29:38.322899Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_tr = sc.ClassRegrSparseDataset(x=ecfp[idx_tr], y_class=y_class_tr, y_regr=y_regr_tr, y_censor=y_censor_tr, y_cat_columns=select_cat_ids)\n",
    "dataset_va = sc.ClassRegrSparseDataset(x=ecfp[idx_va], y_class=y_class_va, y_regr=y_regr_va, y_censor=y_censor_va, y_cat_columns=select_cat_ids)\n",
    "\n",
    "loader_tr = DataLoader(dataset_tr, batch_size=batch_size, num_workers = 8, pin_memory=True, collate_fn=dataset_tr.collate, shuffle=True)\n",
    "loader_va = DataLoader(dataset_va, batch_size=batch_size, num_workers = 4, pin_memory=True, collate_fn=dataset_va.collate, shuffle=False)\n",
    "\n",
    "args.input_size  = dataset_tr.input_size\n",
    "args.output_size = dataset_tr.output_size\n",
    "\n",
    "args.class_output_size = dataset_tr.class_output_size\n",
    "args.regr_output_size  = dataset_tr.regr_output_size\n",
    "args.cat_id_size = cat_id_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3bd2ad04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:38.409333Z",
     "start_time": "2022-05-01T10:29:38.376604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " dataset_tr.y_class                                 :  (14633, 100) \n",
      " dataset_va.y_class                                 :  (3755, 100) \n",
      "                                 \n",
      " size of training set                               :  14633 \n",
      " size of validation set                             :  3755 \n",
      "                                 \n",
      " Number of batches in training                      :  115 \n",
      " Number of batches in validation dataset            :  30 \n",
      "                                \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\n dataset_tr.y_class                                 :  {dataset_tr.y_class.shape}\",\n",
    "      f\"\\n dataset_va.y_class                                 :  {dataset_va.y_class.shape}\",\n",
    "#       f\"\\n dataset_test.y_class                                 :  {dataset_va.y_class.shape}\",\n",
    "      f\"\\n                                \",\n",
    "      f'\\n size of training set                               :  {len(dataset_tr)}',\n",
    "      f'\\n size of validation set                             :  {len(dataset_va)}',\n",
    "#     #   f'\\n size of test set                                   :  {len(dldrs.testset)}',\n",
    "#     #   f'\\n                               Total                :  {len(dldrs.trainset0)+len(dldrs.trainset1)+len(dldrs.trainset2)+len(dldrs.valset)+ len(dldrs.testset)}',\n",
    "      f\"\\n                                \",\n",
    "      f\"\\n Number of batches in training                      :  {len(loader_tr)}\",\n",
    "      f\"\\n Number of batches in validation dataset            :  {len(loader_va)}\",\n",
    "    #   f\"\\n lenght (# batches) in test dataset                 :  {len(dldrs.test_loader)}\",\n",
    "      f\"\\n                                \")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868699b",
   "metadata": {},
   "source": [
    "###  WandB setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0f275b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:42.143765Z",
     "start_time": "2022-05-01T10:29:38.413423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1inin34j 0501_1229 SparseChem-Mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: cannot run ipynb_drop_output: No such file or directory\n",
      "error: cannot fork to run external filter 'ipynb_drop_output'\n",
      "error: external filter 'ipynb_drop_output' failed\n",
      "error: cannot run ipynb_drop_output: No such file or directory\n",
      "error: cannot fork to run external filter 'ipynb_drop_output'\n",
      "error: external filter 'ipynb_drop_output' failed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kbardool/WSL-projs/SparseChem/wandb/run-20220501_122938-1inin34j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"http://localhost:8080/kbardool/SparseChem-Mini/runs/1inin34j\" target=\"_blank\">0501_1229</a></strong> to <a href=\"http://localhost:8080/kbardool/SparseChem-Mini\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PROJECT NAME: SparseChem-Mini\n",
      " RUN ID      : 1inin34j \n",
      " RUN NAME    : 0501_1229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_metric.Metric at 0x7fe54042f6a0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------------------------------------------------------\n",
    "# ### WandB setup\n",
    "#------------------------------------------------------------------\n",
    "ns = types.SimpleNamespace()\n",
    "ns.current_epoch  = 0\n",
    "ns.current_iter   = 0\n",
    "ns.best_results   = {}\n",
    "ns.best_metrics   = None\n",
    "ns.best_value     = 0 \n",
    "ns.best_iter      = 0\n",
    "ns.best_epoch     = 0\n",
    "ns.p_epoch        = 0\n",
    "ns.num_prints     = 0\n",
    "\n",
    "init_wandb(ns, args)\n",
    "wandb.define_metric(\"best_accuracy\", summary=\"last\")\n",
    "wandb.define_metric(\"best_epoch\", summary=\"last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b834837",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "00ec1303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:42.891075Z",
     "start_time": "2022-05-01T10:29:42.150307Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------\n",
    "# ### Network\n",
    "#------------------------------------------------------------------\n",
    "dev  = torch.device(args.dev)\n",
    "\n",
    "net  = sc.SparseFFN(args).to(dev)\n",
    "loss_class = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "loss_regr  = sc.censored_mse_loss\n",
    "\n",
    "if not args.censored_loss:\n",
    "    loss_regr = functools.partial(loss_regr, censored_enabled=False)\n",
    "\n",
    "tasks_class.training_weight = tasks_class.training_weight.to(dev)\n",
    "tasks_regr.training_weight  = tasks_regr.training_weight.to(dev)\n",
    "tasks_regr.censored_weight  = tasks_regr.censored_weight.to(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0b4f16",
   "metadata": {},
   "source": [
    "###  Optimizer, Scheduler, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ebcc9050",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:43.013145Z",
     "start_time": "2022-05-01T10:29:42.898294Z"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------\n",
    "# ###  Optimizer, Scheduler, GradScaler\n",
    "#------------------------------------------------------------------\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "scheduler = MultiStepLR(optimizer, milestones=args.lr_steps, gamma=args.lr_alpha)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "wandb.watch(net, log='all', log_freq= 10)     ###  Weights and Biases Initialization \n",
    "reporter = None\n",
    "h = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080e975d",
   "metadata": {},
   "source": [
    "### setup memory profiling reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5f357697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:43.089424Z",
     "start_time": "2022-05-01T10:29:43.018676Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.profile == 1:\n",
    "   torch_gpu_id = torch.cuda.current_device()\n",
    "   if \"CUDA_VISIBLE_DEVICES\" in os.environ:\n",
    "      ids = list(map(int, os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"\").split(\",\")))\n",
    "      nvml_gpu_id = ids[torch_gpu_id] # remap\n",
    "   else:\n",
    "      nvml_gpu_id = torch_gpu_id\n",
    "   h = nvmlDeviceGetHandleByIndex(nvml_gpu_id)\n",
    "\n",
    "if args.profile == 1:\n",
    "   #####   output saving   #####\n",
    "   if not os.path.exists(args.output_dir):\n",
    "       os.makedirs(args.output_dir)\n",
    "\n",
    "   reporter = MemReporter(net)\n",
    "\n",
    "   with open(f\"{args.output_dir}/memprofile.txt\", \"w+\") as profile_file:\n",
    "        with redirect_stdout(profile_file):\n",
    "             profile_file.write(f\"\\nInitial model detailed report:\\n\\n\")\n",
    "             reporter.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "810b495f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:43.171229Z",
     "start_time": "2022-05-01T10:29:43.094268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:\n",
      "SparseFFN(\n",
      "  (net): Sequential(\n",
      "    (0): SparseInputNet(\n",
      "      (net_freq): SparseLinear(in_features=32000, out_features=1000, bias=True)\n",
      "    )\n",
      "    (1): MiddleNet(\n",
      "      (net): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (classLast): LastNet(\n",
      "    (net): Sequential(\n",
      "      (initial_layer): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): Dropout(p=0.45, inplace=False)\n",
      "        (2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (regrLast): Sequential(\n",
      "    (0): LastNet(\n",
      "      (net): Sequential(\n",
      "        (initial_layer): Sequential(\n",
      "          (0): Tanh()\n",
      "          (1): Dropout(p=0.45, inplace=False)\n",
      "          (2): Linear(in_features=1000, out_features=0, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "dev                  :    cpu\n",
      "args.lr              :    0.001\n",
      "args.weight_decay    :    0.0001\n",
      "args.lr_steps        :    [10]\n",
      "args.lr_steps        :    [10]\n",
      "num_int_batches      :    1\n",
      "batch_size           :    128\n",
      "current epoch        :    0\n",
      "epochs               :    100\n",
      "scaler               :    <torch.cuda.amp.grad_scaler.GradScaler object at 0x7fe5600c77f0>\n",
      "args.normalize_loss  :    None\n",
      "loss_class           :    BCEWithLogitsLoss()\n",
      "mixed precision      :    0\n",
      "args.eval_train      :    0\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------\n",
    "# ### Display network and other values\n",
    "#------------------------------------------------------------------\n",
    "print(\"Network:\")\n",
    "print(net)\n",
    "print(optimizer)\n",
    "print(f\"dev                  :    {dev}\")\n",
    "print(f\"args.lr              :    {args.lr}\")\n",
    "print(f\"args.weight_decay    :    {args.weight_decay}\")\n",
    "print(f\"args.lr_steps        :    {args.lr_steps}\")\n",
    "print(f\"args.lr_steps        :    {args.lr_steps}\")\n",
    "print(f\"num_int_batches      :    {num_int_batches}\")\n",
    "print(f\"batch_size           :    {batch_size}\")\n",
    "print(f\"current epoch        :    {ns.current_epoch}\")\n",
    "print(f\"epochs               :    {args.epochs}\")\n",
    "print(f\"scaler               :    {scaler}\")\n",
    "print(f\"args.normalize_loss  :    {args.normalize_loss}\")\n",
    "print(f\"loss_class           :    {loss_class}\")\n",
    "print(f\"mixed precision      :    {args.mixed_precision}\")\n",
    "print(f\"args.eval_train      :    {args.eval_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64267731",
   "metadata": {},
   "source": [
    "##  Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "628e976d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T11:00:50.073723Z",
     "start_time": "2022-05-01T11:00:49.997989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Last Epoch: 10   # of epochs to do:  10 - Run epochs 11 to 20\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "# from torch.serialization import SourceChangeWarning \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)    \n",
    "args.epochs = 10\n",
    "ns.end_epoch = ns.current_epoch + args.epochs\n",
    "print(f\" Last Epoch: {ns.current_epoch}   # of epochs to do:  {args.epochs} - Run epochs {ns.current_epoch+1} to {ns.end_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9f8fa8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T11:07:25.545996Z",
     "start_time": "2022-05-01T11:00:53.027746Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11     |   0.08261   0.27209   0.92063   0.91466   0.90616   0.82609   0.92429 |       nan       nan       nan |   38.9 \n",
      "12     |   0.08190   0.27442   0.94367   0.90650   0.94113   0.83497   0.94169 |       nan       nan       nan |   36.7 \n",
      "13     |   0.08002   0.26982   0.94675   0.91042   0.94408   0.84154   0.94389 |       nan       nan       nan |   38.2 \n",
      "Previous best_epoch:     4   best iter:     0,   best_value: 0.94500\n",
      "New      best_epoch:    13   best iter:     0,   best_value: 0.94675\n",
      "14     |   0.08097   0.26868   0.94817   0.91089   0.94624   0.84922   0.94246 |       nan       nan       nan |   37.9 \n",
      "Previous best_epoch:    13   best iter:     0,   best_value: 0.94675\n",
      "New      best_epoch:    14   best iter:     0,   best_value: 0.94817\n",
      "15     |   0.08155   0.26583   0.94457   0.90013   0.94198   0.82955   0.94341 |       nan       nan       nan |   36.5 \n",
      "16     |   0.08284   0.27334   0.94220   0.90332   0.93976   0.83490   0.94049 |       nan       nan       nan |   36.1 \n",
      "17     |   0.08261   0.26192   0.94765   0.91058   0.94567   0.85621   0.94254 |       nan       nan       nan |   37.5 \n",
      "18     |   0.08135   0.27262   0.94647   0.90969   0.94501   0.85281   0.94103 |       nan       nan       nan |   36.7 \n",
      "19     |   0.08019   0.26036   0.92219   0.90265   0.90782   0.81731   0.92603 |       nan       nan       nan |   35.5 \n",
      "20     |   0.08245   0.26110   0.95176   0.91104   0.95053   0.86232   0.94368 |       nan       nan       nan |   35.4 \n",
      "Previous best_epoch:    14   best iter:     0,   best_value: 0.94817\n",
      "New      best_epoch:    20   best iter:     0,   best_value: 0.95176\n",
      "Best Epoch :       20\n",
      "Best Iteration :   0 \n",
      "Best Precision :   0.95176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ns.end_epoch = ns.current_epoch + args.epochs\n",
    "\n",
    "for ns.current_epoch in range(ns.current_epoch+1, ns.end_epoch+1, 1):\n",
    "    t0 = time.time()\n",
    "    sc.train_class_regr(\n",
    "        net, optimizer,\n",
    "        loader          = loader_tr,\n",
    "        loss_class      = loss_class,\n",
    "        loss_regr       = loss_regr,\n",
    "        dev             = dev,\n",
    "        weights_class   = tasks_class.training_weight * (1-args.regression_weight) * 2,\n",
    "        weights_regr    = tasks_regr.training_weight * args.regression_weight * 2,\n",
    "        censored_weight = tasks_regr.censored_weight,\n",
    "        normalize_loss  = args.normalize_loss,\n",
    "        num_int_batches = num_int_batches,\n",
    "        progress        = False,\n",
    "        writer          = writer,\n",
    "        epoch           = ns.current_epoch,\n",
    "        args            = args,\n",
    "        scaler          = scaler,\n",
    "        nvml_handle     = h)\n",
    "\n",
    "    if args.profile == 1:\n",
    "       with open(f\"{args.output_dir}/memprofile.txt\", \"a+\") as profile_file:\n",
    "            profile_file.write(f\"\\nAfter epoch {epoch} model detailed report:\\n\\n\")\n",
    "            with redirect_stdout(profile_file):\n",
    "                 reporter.report()\n",
    "\n",
    "    t1 = time.time()\n",
    "    eval_round = (args.eval_frequency > 0) and ((ns.current_epoch + 1) % args.eval_frequency == 0)\n",
    "    last_round = ns.current_epoch == args.epochs - 1\n",
    "\n",
    "    if eval_round or last_round:\n",
    "\n",
    "        results_va = sc.evaluate_class_regr(net, loader_va, loss_class, loss_regr, \n",
    "                                            tasks_class= tasks_class, \n",
    "                                            tasks_regr = tasks_regr, \n",
    "                                            dev        = dev, \n",
    "                                            progress   = False, \n",
    "                                            normalize_inv=normalize_inv, \n",
    "                                            cal_fact_aucpr=cal_fact_aucpr)\n",
    "        \n",
    "        for key, val in results_va[\"classification_agg\"].items():\n",
    "            writer.add_scalar(\"val_metrics:aggregated/\"+key, val, ns.current_epoch * batch_size)\n",
    "\n",
    "\n",
    "        if args.eval_train:\n",
    "            results_tr = sc.evaluate_class_regr(net, loader_tr, loss_class, loss_regr, \n",
    "                                                tasks_class = tasks_class, \n",
    "                                                tasks_regr  = tasks_regr, \n",
    "                                                dev         = dev, \n",
    "                                                progress    = args.verbose >= 2)\n",
    "            for key, val in results_tr[\"classification_agg\"].items():\n",
    "                writer.add_scalar(\"trn_metrics:aggregated/\"+key, val, ns.current_epoch * batch_size)\n",
    "\n",
    "        else:\n",
    "            results_tr = None\n",
    "\n",
    "        if args.verbose:\n",
    "            ## printing a new header every 20 lines\n",
    "            header = ns.num_prints % 20 == 0\n",
    "            ns.num_prints += 1\n",
    "            sc.print_metrics_cr(ns.current_epoch, t1 - t0, results_tr, results_va, header)\n",
    "            \n",
    "        wandb.log(results_va[\"classification_agg\"].to_dict())\n",
    "\n",
    "        check_for_improvement(ns, results_va)\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best Precision :   {ns.best_value:.5f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3da4a4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T13:58:55.449841Z",
     "start_time": "2022-04-14T13:58:55.364304Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "49c2d58b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T11:07:25.664837Z",
     "start_time": "2022-05-01T11:07:25.551514Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch :       20\n",
      "Best Iteration :   0 \n",
      "Best Precision :   0.95176\n",
      "\n",
      "\n",
      " roc_auc_score         0.9110\n",
      " auc_pr                0.9505\n",
      " avg_prec_score        0.9518\n",
      " f1_max                0.9437\n",
      " p_f1_max              0.7107\n",
      " kappa                 0.5863\n",
      " kappa_max             0.8259\n",
      " p_kappa_max           0.7771\n",
      " bceloss               0.2611\n",
      " auc_pr_cal            0.8623\n",
      " logloss               0.0824\n",
      " num_tasks_total       100.0000\n",
      " num_tasks_agg         20.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Epoch :       {ns.best_epoch}\\n\"\n",
    "      f\"Best Iteration :   {ns.best_iter} \\n\"\n",
    "      f\"Best Precision :   {ns.best_value:.5f}\\n\")\n",
    "print()\n",
    "for k in results_va['classification_agg'].keys():\n",
    "    print(f\" {k:20s}  {results_va['classification_agg'][k]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7369b24f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T11:07:25.764025Z",
     "start_time": "2022-05-01T11:07:25.668359Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss  auc_pr_cal\n",
      "task                                                                                                                     \n",
      "0          0.990537  0.998636        0.998606  0.982301  0.967705  0.786753   0.877266     0.967705  0.095932    0.975334\n",
      "5          0.944444  0.996995        0.997076  0.972973  0.545588  0.000000   0.641509     0.989483  0.126865    0.949860\n",
      "6          0.998358  0.999976        0.999976  0.997543  0.964145  0.797642   0.854725     0.988052  0.019560    0.996303\n",
      "7          0.666667  0.461111        0.588889  0.750000  0.789993  0.000000   0.461538     0.789993  1.212351    0.132914\n",
      "8          1.000000  1.000000        1.000000  1.000000  0.979238  0.000000   1.000000     0.979238  0.097476    1.000000\n",
      "9          1.000000  1.000000        1.000000  1.000000  0.998983  0.660870   1.000000     0.998983  0.019154    1.000000\n",
      "14         0.993333  0.999823        0.999825  0.993377  0.948644  0.000000   0.793566     0.994204  0.066407    0.989078\n",
      "19         1.000000  1.000000        1.000000  1.000000  0.972359  0.000000   1.000000     0.972359  1.242245    1.000000\n",
      "28         0.923232  0.998182        0.998186  0.996979  0.888528  0.662651   0.797101     0.888528  0.045760    0.705138\n",
      "35         1.000000  1.000000        1.000000  1.000000  0.984799  1.000000   1.000000     0.984799  0.014051    1.000000\n",
      "36         0.833333  0.870833        0.887500  0.888889  0.165857  0.222222   0.695652     0.165857  0.806236    0.599107\n",
      "37         0.714286  0.904167        0.909524  0.833333  0.847535 -0.315789   0.600000     0.847535  0.632602    0.739103\n",
      "38         0.405405  0.980586        0.980792  0.991071  0.000071 -0.011940   0.013206     0.998808  0.224081    0.239608\n",
      "41         1.000000  1.000000        1.000000  1.000000  0.999006  0.000000   1.000000     0.999006  0.064160    1.000000\n",
      "43         0.474227  0.992424        0.992485  0.994872  0.994877  0.000000   0.018075     0.999824  0.088572    0.513910\n",
      "44         0.994401  0.999218        0.999221  0.988417  0.781578  0.829506   0.907256     0.833618  0.064970    0.974642\n",
      "46         0.650000  0.898391        0.906346  0.952381  0.973674  0.000000   0.625000     0.973674  0.612343    0.387366\n",
      "48         0.890196  0.743982        0.731410  0.750000  0.576638  0.727141   0.727141     0.576638  0.212091    0.748614\n",
      "51         0.000000  0.166667        0.333333  0.500000  0.978660  0.000000   0.000000     0.995890  2.873904    0.050000\n",
      "52         0.730769  0.586806        0.611111  0.666667  0.529623  0.634146   0.634146     0.529623  0.400255    0.566144\n",
      "54         1.000000  1.000000        1.000000  1.000000  0.989425  0.000000   1.000000     0.989425  0.008603    1.000000\n",
      "55         1.000000  1.000000        1.000000  1.000000  0.131548  0.948540   1.000000     0.131548  0.061650    1.000000\n",
      "59         0.750000  0.908333        0.916667  0.857143  0.991117  0.000000   0.666667     0.991117  1.414751    0.772115\n",
      "61         1.000000  1.000000        1.000000  1.000000  0.973038  0.000000   1.000000     0.973038  0.040258    1.000000\n",
      "62         0.923077  0.994294        0.994505  0.962963  0.946888  0.000000   0.631579     0.994635  0.240211    0.930501\n",
      "64         1.000000  1.000000        1.000000  1.000000  0.286185  0.695652   1.000000     0.286185  0.155471    1.000000\n",
      "70         1.000000  1.000000        1.000000  1.000000  0.118752  0.000000   1.000000     0.118752  0.127267    1.000000\n",
      "72         1.000000  1.000000        1.000000  1.000000  0.960381  1.000000   1.000000     0.960381  0.014087    1.000000\n",
      "73         0.934959  0.995240        0.995299  0.964706  0.022978  0.365385   0.535211     0.566768  0.203779    0.900929\n",
      "76         0.586957  0.988739        0.988907  0.989247  0.992417  0.000000   0.057022     0.998012  0.134393    0.620365\n",
      "78         0.889752  0.901402        0.900295  0.846154  0.993644  0.575931   0.763578     0.993644  1.163991    0.797599\n",
      "80         0.995833  0.999383        0.999390  0.987654  0.588340  0.896861   0.910506     0.840990  0.072403    0.984924\n",
      "82         0.800000  0.817659        0.835714  0.857143  0.194603  0.290323   0.620690     0.194603  0.635695    0.467574\n",
      "85         0.938011  0.989917        0.989936  0.976331  0.577051  0.749648   0.766966     0.577051  0.202836    0.746897\n",
      "86         1.000000  1.000000        1.000000  1.000000  0.942057  1.000000   1.000000     0.942057  0.019415    1.000000\n",
      "87         1.000000  1.000000        1.000000  1.000000  0.718080  0.750000   1.000000     0.718080  0.378440    1.000000\n",
      "88         1.000000  1.000000        1.000000  1.000000  0.496525  0.000000   1.000000     0.496525  0.021023    1.000000\n",
      "92         1.000000  1.000000        1.000000  1.000000  0.997766  0.000000   1.000000     0.997766  0.413694    1.000000\n",
      "98         1.000000  1.000000        1.000000  1.000000  0.947727  1.000000   1.000000     0.947727  0.165614    1.000000\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.width = 150\n",
    "df = results_va['classification']\n",
    "print(df[pd.notna(df.roc_auc_score)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a36fa",
   "metadata": {},
   "source": [
    "## Post Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f24a0d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:27.551938Z",
     "start_time": "2022-05-01T10:29:27.245670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving performance metrics (AUCs) and model.\n",
      "Saved model weights into '../experiments/mini-SparseChem/1000x0_0501_1209_lr0.001_do0.45/sc_1000_lr0.001_do0.45.pt'.\n",
      "Saved config and results into '../experiments/mini-SparseChem/1000x0_0501_1209_lr0.001_do0.45/sc_1000_lr0.001_do0.45.json'.\n",
      "You can load the results by:\n",
      "  import sparsechem as sc\n",
      "  res = sc.load_results('../experiments/mini-SparseChem/1000x0_0501_1209_lr0.001_do0.45/sc_1000_lr0.001_do0.45.json')\n"
     ]
    }
   ],
   "source": [
    "#print(\"DEBUG data for hidden spliting\")\n",
    "#print (f\"Classification mask: Sum = {net.classmask.sum()}\\t Uniques: {np.unique(net.classmask)}\")\n",
    "#print (f\"Regression mask:     Sum = {net.regmask.sum()}\\t Uniques: {np.unique(net.regmask)}\")\n",
    "#print (f\"overlap: {(net.regmask * net.classmask).sum()}\")\n",
    "\n",
    "writer.close()\n",
    "vprint()\n",
    "if args.profile == 1:\n",
    "   multiplexer = sc.create_multiplexer(tb_name)\n",
    "#   sc.export_scalars(multiplexer, '.', \"GPUmem\", \"testcsv.csv\")\n",
    "   data = sc.extract_scalars(multiplexer, '.', \"GPUmem\")\n",
    "   vprint(f\"Peak GPU memory used: {sc.return_max_val(data)}MB\")\n",
    "vprint(\"Saving performance metrics (AUCs) and model.\")\n",
    "\n",
    "#####   model saving   #####\n",
    "if not os.path.exists(args.output_dir):\n",
    "   os.makedirs(args.output_dir)\n",
    "\n",
    "model_file = f\"{args.output_dir}/{args.name}.pt\"\n",
    "out_file   = f\"{args.output_dir}/{args.name}.json\"\n",
    "\n",
    "if args.save_model:\n",
    "   torch.save(net.state_dict(), model_file)\n",
    "   vprint(f\"Saved model weights into '{model_file}'.\")\n",
    "\n",
    "results_va[\"classification\"][\"num_pos\"] = num_pos_va\n",
    "results_va[\"classification\"][\"num_neg\"] = num_neg_va\n",
    "results_va[\"regression\"][\"num_samples\"] = num_regr_va\n",
    "\n",
    "if results_tr is not None:\n",
    "    results_tr[\"classification\"][\"num_pos\"] = num_pos - num_pos_va\n",
    "    results_tr[\"classification\"][\"num_neg\"] = num_neg - num_neg_va\n",
    "    results_tr[\"regression\"][\"num_samples\"] = num_regr - num_regr_va\n",
    "\n",
    "stats=None\n",
    "if args.normalize_regression == 1 :\n",
    "   stats={}\n",
    "   stats[\"mean\"] = mean_save\n",
    "   stats[\"var\"]  = np.array(var_save)[0]\n",
    "sc.save_results(out_file, args, validation=results_va, training=results_tr, stats=stats)\n",
    "\n",
    "vprint(f\"Saved config and results into '{out_file}'.\\nYou can load the results by:\\n  import sparsechem as sc\\n  res = sc.load_results('{out_file}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4bbb2748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:27.640861Z",
     "start_time": "2022-05-01T10:29:27.557942Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  kappa_max  p_kappa_max   bceloss  auc_pr_cal  num_pos  num_neg\n",
      "task                                                                                                                                       \n",
      "0          0.994118  0.999152        0.999121  0.986900  0.750772  0.786753   0.901198     0.750772  0.079684    0.981474      115       17\n",
      "1               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN         NaN       31        0\n",
      "2               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN         NaN       17        0\n",
      "3               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN         NaN       54        0\n",
      "4               NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN         NaN        7        0\n",
      "5          0.944444  0.996995        0.997076  0.972973  0.440171 -0.055556   0.641509     0.981012  0.139522    0.949860       18        1\n",
      "6          0.998358  0.999976        0.999976  0.997543  0.957550  0.797642   0.854725     0.992787  0.023867    0.996303      203        3\n",
      "7          0.666667  0.461111        0.588889  0.750000  0.890399  0.000000   0.461538     0.890399  1.565884    0.132914        3        4\n",
      "8          1.000000  1.000000        1.000000  1.000000  0.973054  0.000000   1.000000     0.973054  0.077889    1.000000       55        2\n",
      "9          1.000000  1.000000        1.000000  1.000000  0.998858  0.660870   1.000000     0.998858  0.016115    1.000000       76        2\n",
      "10              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN         NaN       63        0\n",
      "11              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN         NaN        1        0\n",
      "12              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN         NaN       42        0\n",
      "13              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN         NaN        0        1\n",
      "14         0.993333  0.999823        0.999825  0.993377  0.983867  0.000000   0.793566     0.997540  0.095622    0.989078       75        2\n",
      "15              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN         NaN       36        0\n",
      "16              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN         NaN        0        0\n",
      "17              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN         NaN        1        0\n",
      "18              NaN       NaN             NaN       NaN       NaN       NaN        NaN          NaN       NaN         NaN       43        0\n",
      "19         1.000000  1.000000        1.000000  1.000000  0.928687  0.000000   1.000000     0.928687  0.636593    1.000000        2        2\n",
      "\n",
      "dict_keys(['classification', 'classification_agg', 'regression', 'regression_agg'])\n",
      "roc_auc_score        0.876634\n",
      "auc_pr               0.887863\n",
      "avg_prec_score       0.891956\n",
      "f1_max               0.890680\n",
      "p_f1_max             0.680603\n",
      "kappa                0.575100\n",
      "kappa_max            0.755458\n",
      "p_kappa_max          0.777735\n",
      "bceloss              0.294061\n",
      "auc_pr_cal           0.778992\n",
      "logloss              0.084267\n",
      "num_tasks_total    100.000000\n",
      "num_tasks_agg       20.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(results_va['classification'][0:20])\n",
    "print()\n",
    "print(results_va.keys())\n",
    "pp.pprint(results_va['classification_agg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "def44851",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T10:29:31.702526Z",
     "start_time": "2022-05-01T10:29:28.582847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05249aa549774e52a2e3eaaa0a60d272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.809 MB of 0.809 MB uploaded (0.096 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 10.5%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auc_pr</td><td>▇██▄▁▅▃▄▂</td></tr><tr><td>auc_pr_cal</td><td>█▇█▆▁▅▄▅▄</td></tr><tr><td>avg_prec_score</td><td>▇██▅▁▅▄▅▁</td></tr><tr><td>bceloss</td><td>▃▂▂▁▆▅▃█▄</td></tr><tr><td>best_accuracy</td><td>▁▇█</td></tr><tr><td>best_epoch</td><td>▁▅█</td></tr><tr><td>f1_max</td><td>▇█▇▆▂▅▄▅▁</td></tr><tr><td>kappa</td><td>▂█▂▆▁▅▂▃▄</td></tr><tr><td>kappa_max</td><td>▆█▇▇▁▅▃▆▂</td></tr><tr><td>logloss</td><td>▂▁▂▁▇▅▄█▄</td></tr><tr><td>num_tasks_agg</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_tasks_total</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>p_f1_max</td><td>▂▅▂▃▁▁▅█▅</td></tr><tr><td>p_kappa_max</td><td>▁▄▂▃▃▂▆█▅</td></tr><tr><td>roc_auc_score</td><td>▁█▆█▁▅▄▇▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auc_pr</td><td>0.88786</td></tr><tr><td>auc_pr_cal</td><td>0.77899</td></tr><tr><td>avg_prec_score</td><td>0.89196</td></tr><tr><td>bceloss</td><td>0.29406</td></tr><tr><td>f1_max</td><td>0.89068</td></tr><tr><td>kappa</td><td>0.5751</td></tr><tr><td>kappa_max</td><td>0.75546</td></tr><tr><td>logloss</td><td>0.08427</td></tr><tr><td>num_tasks_agg</td><td>20.0</td></tr><tr><td>num_tasks_total</td><td>100.0</td></tr><tr><td>p_f1_max</td><td>0.6806</td></tr><tr><td>p_kappa_max</td><td>0.77773</td></tr><tr><td>roc_auc_score</td><td>0.87663</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0501_1209</strong>: <a href=\"http://localhost:8080/kbardool/SparseChem-Mini/runs/13myaskn\" target=\"_blank\">http://localhost:8080/kbardool/SparseChem-Mini/runs/13myaskn</a><br/>Synced 7 W&B file(s), 0 media file(s), 8 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220501_120954-13myaskn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ns.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de95601",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a95fe27d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T15:17:56.503884Z",
     "start_time": "2022-04-28T15:17:56.464295Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      roc_auc_score    auc_pr  avg_prec_score    f1_max  p_f1_max     kappa  \\\n",
      "task                                                                          \n",
      "0          0.991560  0.998782        0.998752  0.982301  0.980404  0.786753   \n",
      "1               NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "2               NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "3               NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "4               NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "5          0.944444  0.996995        0.997076  0.972973  0.562853  0.000000   \n",
      "6          1.000000  1.000000        1.000000  1.000000  0.973055  0.797642   \n",
      "7          0.666667  0.461111        0.588889  0.750000  0.763078  0.000000   \n",
      "8          1.000000  1.000000        1.000000  1.000000  0.987239  0.000000   \n",
      "9          1.000000  1.000000        1.000000  1.000000  0.998716  0.660870   \n",
      "10              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "11              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "12              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "13              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "14         0.993333  0.999823        0.999825  0.993377  0.959745  0.000000   \n",
      "15              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "16              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "17              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "18              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "19         1.000000  1.000000        1.000000  1.000000  0.957944  0.000000   \n",
      "20              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "21              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "22              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "23              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "24              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "25              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "26              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "27              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "28         0.915152  0.997941        0.997946  0.996979  0.875137  0.797101   \n",
      "29              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "30              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "31              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "32              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "33              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "34              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "35         1.000000  1.000000        1.000000  1.000000  0.979840  1.000000   \n",
      "36         0.750000  0.766667        0.804167  0.888889  0.083961  0.222222   \n",
      "37         0.619048  0.845833        0.857143  0.823529  0.287464  0.347826   \n",
      "38         0.378378  0.978327        0.978592  0.991071  0.000882 -0.011940   \n",
      "39              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "40              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "41         1.000000  1.000000        1.000000  1.000000  0.998889  0.000000   \n",
      "42              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "43         0.474227  0.992424        0.992485  0.994872  0.995585  0.000000   \n",
      "44         0.993971  0.999149        0.999152  0.992248  0.818924  0.829506   \n",
      "45              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "46         0.750000  0.939224        0.943012  0.952381  0.985955  0.000000   \n",
      "47              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "48         0.888889  0.741100        0.728505  0.750000  0.582740  0.727141   \n",
      "49              NaN       NaN             NaN       NaN       NaN       NaN   \n",
      "\n",
      "      kappa_max  p_kappa_max   bceloss  auc_pr_cal  num_pos  num_neg  \n",
      "task                                                                  \n",
      "0      0.877266     0.980404  0.099664    0.976466      115       17  \n",
      "1           NaN          NaN       NaN         NaN       31        0  \n",
      "2           NaN          NaN       NaN         NaN       17        0  \n",
      "3           NaN          NaN       NaN         NaN       54        0  \n",
      "4           NaN          NaN       NaN         NaN        7        0  \n",
      "5      0.641509     0.986980  0.111792    0.949860       18        1  \n",
      "6      1.000000     0.973055  0.016514    1.000000      203        3  \n",
      "7      0.461538     0.763078  1.387727    0.132914        3        4  \n",
      "8      1.000000     0.987239  0.094224    1.000000       55        2  \n",
      "9      1.000000     0.998716  0.016673    1.000000       76        2  \n",
      "10          NaN          NaN       NaN         NaN       63        0  \n",
      "11          NaN          NaN       NaN         NaN        1        0  \n",
      "12          NaN          NaN       NaN         NaN       42        0  \n",
      "13          NaN          NaN       NaN         NaN        0        1  \n",
      "14     0.793566     0.995055  0.069398    0.989078       75        2  \n",
      "15          NaN          NaN       NaN         NaN       36        0  \n",
      "16          NaN          NaN       NaN         NaN        0        0  \n",
      "17          NaN          NaN       NaN         NaN        1        0  \n",
      "18          NaN          NaN       NaN         NaN       43        0  \n",
      "19     1.000000     0.957944  1.159957    1.000000        2        2  \n",
      "20          NaN          NaN       NaN         NaN        7        0  \n",
      "21          NaN          NaN       NaN         NaN        7        0  \n",
      "22          NaN          NaN       NaN         NaN        0       13  \n",
      "23          NaN          NaN       NaN         NaN        3        0  \n",
      "24          NaN          NaN       NaN         NaN        0        0  \n",
      "25          NaN          NaN       NaN         NaN       21        0  \n",
      "26          NaN          NaN       NaN         NaN        1        0  \n",
      "27          NaN          NaN       NaN         NaN       37        0  \n",
      "28     0.797101     0.875137  0.042430    0.676589      330        6  \n",
      "29          NaN          NaN       NaN         NaN       11        0  \n",
      "30          NaN          NaN       NaN         NaN       86        0  \n",
      "31          NaN          NaN       NaN         NaN        0       30  \n",
      "32          NaN          NaN       NaN         NaN        0        0  \n",
      "33          NaN          NaN       NaN         NaN      142        0  \n",
      "34          NaN          NaN       NaN         NaN       27        0  \n",
      "35     1.000000     0.979840  0.006316    1.000000       25        3  \n",
      "36     0.695652     0.083961  1.078320    0.376580        4        3  \n",
      "37     0.347826     0.812577  0.621829    0.498911        7        3  \n",
      "38     0.010991     0.999271  0.210472    0.203723      111        2  \n",
      "39          NaN          NaN       NaN         NaN       12        0  \n",
      "40          NaN          NaN       NaN         NaN        7        0  \n",
      "41     1.000000     0.998889  0.063473    1.000000       79        1  \n",
      "42          NaN          NaN       NaN         NaN        0        1  \n",
      "43     0.018075     0.999811  0.087830    0.513910       97        1  \n",
      "44     0.936693     0.818924  0.067191    0.970516      129       18  \n",
      "45          NaN          NaN       NaN         NaN       15        0  \n",
      "46     0.625000     0.985955  0.576575    0.571078       10        2  \n",
      "47          NaN          NaN       NaN         NaN        9        0  \n",
      "48     0.727141     0.582740  0.222837    0.745717        9       85  \n",
      "49          NaN          NaN       NaN         NaN       38        0  \n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(results_va['classification'][0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "deca5b86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T16:20:53.027104Z",
     "start_time": "2022-04-28T16:20:52.995717Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2445\n",
      "18704\n",
      "505\n",
      "3804\n"
     ]
    }
   ],
   "source": [
    "print( num_neg.sum())\n",
    "print( num_pos.sum())\n",
    "print( num_neg_va.sum())\n",
    "print( num_pos_va.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545b94be",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in zip(dldrs.valset.num_pos, dldrs.valset.num_neg):\n",
    "    print(f\" {i[0]:4d}  {i[1]:4d}\")\n",
    "for i in zip(dldrs.valset.num_pos, dldrs.valset.num_neg):\n",
    "    print(f\" {i[0]:4d}  {i[1]:4d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fa5e170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T15:18:02.976078Z",
     "start_time": "2022-04-28T15:18:02.936187Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "roc_auc_score        0.900757\n",
      "auc_pr               0.943594\n",
      "avg_prec_score       0.945930\n",
      "f1_max               0.938011\n",
      "p_f1_max             0.723872\n",
      "kappa                0.611823\n",
      "kappa_max            0.803714\n",
      "p_kappa_max          0.826011\n",
      "bceloss              0.296447\n",
      "auc_pr_cal           0.827893\n",
      "logloss              0.087415\n",
      "num_tasks_total    100.000000\n",
      "num_tasks_agg       20.000000\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pp.pprint(results_va)\n",
    "print()\n",
    "\n",
    "pp.pprint(results_va['classification_agg'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00b24bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T16:12:52.731012Z",
     "start_time": "2022-04-28T16:12:52.668446Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115  31  17  54   7  18 203   3  55  76  63   1  42   0  75  36   0   1  43   2   7   7   0   3   0  21   1  37 330  11  86   0   0 142  27  25   4\n",
      "   7 111  12   7  79   0  97 129  15  10   9   9  38 272   1   2   0 285  63 185   1   0   4  19  21  13   0  18  12   0   0  93  55   1  73  29  41\n",
      "  18   0  46  37  14   0  40  18   6   8  10 330   6   4   1   0   0   0   8   0   0   0   3   0   1   0]\n",
      "[17  0  0  0  0  1  3  4  2  2  0  0  0  1  2  0  0  0  0  2  0  0 13  0  0  0  0  0  6  0  0 30  0  0  0  3  3  3  2  0  0  1  1  1 18  0  2  0 85\n",
      "  0  0  2 13 47  1 11  0  0  0  2  0  1  1  1  3  0  0  0  0  0 18  0  9  3  0  4  1  0 23 11  6  0  5  0  0 46  4  4 73  2  0  7  1  0  0  0  0  0\n",
      "  4  0]\n",
      "[]\n",
      "  115    17    trianing:  884     83\n",
      "   31     0    trianing:   59      0\n",
      "   17     0    trianing:   59      0\n",
      "   54     0    trianing:  284      0\n",
      "    7     0    trianing:   55      0\n",
      "   18     1    trianing:   43      3\n",
      "  203     3    trianing:  749     29\n",
      "    3     4    trianing:   14      7\n",
      "   55     2    trianing:  292      9\n",
      "   76     2    trianing:  342     11\n",
      "   63     0    trianing:  423      0\n",
      "    1     0    trianing:   13      0\n",
      "   42     0    trianing:  119      0\n",
      "    0     1    trianing:    1     12\n",
      "   75     2    trianing:  281      3\n",
      "   36     0    trianing:  213      0\n",
      "    0     0    trianing:    0      0\n",
      "    1     0    trianing:   11      0\n",
      "   43     0    trianing:  190      0\n",
      "    2     2    trianing:   27      9\n",
      "    7     0    trianing:   46      0\n",
      "    7     0    trianing:   36     13\n",
      "    0    13    trianing:   16     21\n",
      "    3     0    trianing:   43      0\n",
      "    0     0    trianing:    9      0\n",
      "   21     0    trianing:   70      0\n",
      "    1     0    trianing:    7      0\n",
      "   37     0    trianing:  163      0\n",
      "  330     6    trianing: 1399     45\n",
      "   11     0    trianing:   35      0\n",
      "   86     0    trianing:  447      0\n",
      "    0    30    trianing:    1    143\n",
      "    0     0    trianing:    0      0\n",
      "  142     0    trianing:  675      9\n",
      "   27     0    trianing:  327      0\n",
      "   25     3    trianing:  142     56\n",
      "    4     3    trianing:    6      9\n",
      "    7     3    trianing:   31     18\n",
      "  111     2    trianing:  552     17\n",
      "   12     0    trianing:   52      0\n",
      "    7     0    trianing:   27      0\n",
      "   79     1    trianing:  325      1\n",
      "    0     1    trianing:    1      1\n",
      "   97     1    trianing:  350      1\n",
      "  129    18    trianing:  535     72\n",
      "   15     0    trianing:   72      0\n",
      "   10     2    trianing:   94     10\n",
      "    9     0    trianing:   36      0\n",
      "    9    85    trianing:   55    280\n",
      "   38     0    trianing:  259      2\n",
      "  272     0    trianing: 1366      0\n",
      "    1     2    trianing:    3      2\n",
      "    2    13    trianing:   24     48\n",
      "    0    47    trianing:    9    245\n",
      "  285     1    trianing: 1408     17\n",
      "   63    11    trianing:  148     77\n",
      "  185     0    trianing:  971      4\n",
      "    1     0    trianing:  113      0\n",
      "    0     0    trianing:   31      0\n",
      "    4     2    trianing:   55      9\n",
      "   19     0    trianing:   70      0\n",
      "   21     1    trianing:   74      5\n",
      "   13     1    trianing:   63      3\n",
      "    0     1    trianing:    0      2\n",
      "   18     3    trianing:   86     57\n",
      "   12     0    trianing:   58      1\n",
      "    0     0    trianing:    2      0\n",
      "    0     0    trianing:    0      1\n",
      "   93     0    trianing:  465      5\n",
      "   55     0    trianing:  273      2\n",
      "    1    18    trianing:    9     44\n",
      "   73     0    trianing:  317      2\n",
      "   29     9    trianing:   91     64\n",
      "   41     3    trianing:  146     11\n",
      "   18     0    trianing:  199      1\n",
      "    0     4    trianing:    0     24\n",
      "   46     1    trianing:  251      3\n",
      "   37     0    trianing:  232      0\n",
      "   14    23    trianing:   62    101\n",
      "    0    11    trianing:   14     21\n",
      "   40     6    trianing:  230     38\n",
      "   18     0    trianing:   79      0\n",
      "    6     5    trianing:   30     19\n",
      "    8     0    trianing:   41      0\n",
      "   10     0    trianing:   32      1\n",
      "  330    46    trianing: 1610    220\n",
      "    6     4    trianing:   74     16\n",
      "    4     4    trianing:   16     13\n",
      "    1    73    trianing:   22    400\n",
      "    0     2    trianing:    0     32\n",
      "    0     0    trianing:    0      0\n",
      "    0     7    trianing:    0     27\n",
      "    8     1    trianing:  102      1\n",
      "    0     0    trianing:    1     17\n",
      "    0     0    trianing:    0      0\n",
      "    0     0    trianing:   32      0\n",
      "    3     0    trianing:   14      2\n",
      "    0     0    trianing:    0      0\n",
      "    1     4    trianing:   10     32\n",
      "    0     0    trianing:    1     14\n"
     ]
    }
   ],
   "source": [
    "print(num_pos_va)\n",
    "print(num_neg_va)\n",
    "print(num_regr_va)\n",
    "for i in zip(num_pos_va, num_neg_va, num_pos, num_neg):\n",
    "    print(f\" {i[0]:4d}  {i[1]:4d}    trianing: {i[2]:4d}   {i[3]:4d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40b7bd71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T15:22:06.177783Z",
     "start_time": "2022-04-28T15:22:06.127520Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "roc_auc_score      0.874262\n",
       "auc_pr             0.922464\n",
       "avg_prec_score     0.932781\n",
       "f1_max             0.938123\n",
       "p_f1_max           0.746278\n",
       "kappa              0.400306\n",
       "kappa_max          0.754262\n",
       "p_kappa_max        0.830485\n",
       "bceloss            0.385833\n",
       "auc_pr_cal         0.803581\n",
       "num_pos           58.512821\n",
       "num_neg            9.948718\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[pd.notna(df.roc_auc_score)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b482ac5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T15:22:26.189727Z",
     "start_time": "2022-04-28T15:22:26.149010Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa96df3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff228568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T07:37:52.305993Z",
     "start_time": "2022-04-13T07:37:52.296939Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "def restart_wandb(exp_id, exp_name, project_name, resume = \"allow\" ):\n",
    "    print(exp_id, exp_name, project_name) \n",
    "    wandb_run = wandb.init(project = project_name, \n",
    "                                     entity  = \"kbardool\", \n",
    "                                     id      = exp_id, \n",
    "                                     name    = exp_name,\n",
    "                                     resume=resume )\n",
    "    \n",
    "    print(f\" PROJECT NAME: {wandb_run.project}\\n\"\n",
    "          f\" RUN ID      : {wandb_run.id} \\n\"\n",
    "          f\" RUN NAME    : {wandb_run.name}\")     \n",
    " \n",
    "    return wandb_run \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51adf2f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T07:37:58.779180Z",
     "start_time": "2022-04-13T07:37:53.070725Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d2rw3bdq 0413_0509 SparseChem-Mini\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:d2rw3bdq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8471011283e94d06a59a2d75df43c046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "WARNING:\n",
      "\n",
      "You should always run with libnvidia-ml.so that is installed with your\n",
      "NVIDIA Display Driver. By default it's installed in /usr/lib and /usr/lib64.\n",
      "libnvidia-ml.so in GDK package is a stub library that is attached only for\n",
      "build purposes (e.g. machine that you build your application doesn't have\n",
      "to have Display Driver installed).\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Linked to libnvidia-ml library at wrong path : /usr/lib64/libnvidia-ml.so.1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0413_0509</strong>: <a href=\"https://wandb.ai/kbardool/SparseChem-Mini/runs/d2rw3bdq\" target=\"_blank\">https://wandb.ai/kbardool/SparseChem-Mini/runs/d2rw3bdq</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220413_093712-d2rw3bdq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:d2rw3bdq). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.14 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/vsc-hard-mounts/leuven-data/326/vsc32647/projs/SparseChem/wandb/run-20220413_093753-d2rw3bdq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/kbardool/SparseChem-Mini/runs/d2rw3bdq\" target=\"_blank\">0413_0509</a></strong> to <a href=\"https://wandb.ai/kbardool/SparseChem-Mini\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PROJECT NAME: SparseChem-Mini\n",
      " RUN ID      : d2rw3bdq \n",
      " RUN NAME    : 0413_0509\n"
     ]
    }
   ],
   "source": [
    "run = restart_wandb(\"d2rw3bdq\",\"0413_0509\",\"SparseChem-Mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcc605ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T07:49:06.657692Z",
     "start_time": "2022-04-13T07:49:06.645775Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/a5e50704be/ipykernel_31013/1322073845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "271944b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T07:48:13.315835Z",
     "start_time": "2022-04-13T07:48:13.311428Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b561a453",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T07:49:03.347430Z",
     "start_time": "2022-04-13T07:49:03.342915Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ffe3f20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T18:02:22.065859Z",
     "start_time": "2022-04-10T18:02:21.337434Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# cmd = (\n",
    "#   f\" --x       /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic/chembl_23mini_x.npy \" +\n",
    "#   f\" --y_class /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic/chembl_23mini_adashare_y_all_bin_sparse.npy \" +\n",
    "#   f\" --folding /home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic/chembl_23mini_folds.npy \" +\n",
    "#   f\" --output_dir {output_dir}\" +    \n",
    "#   f\" --fold_va           0 \" +\n",
    "#   f\" --batch_ratio    0.02 \" +\n",
    "#   f\" --hidden_sizes   25 25 25 25 25 25 \" +\n",
    "#   f\" --dropouts_trunk  0  0  0  0  0  0 \" +\n",
    "#   f\" --weight_decay   1e-4 \" \n",
    "#   f\" --epochs           40 \" +\n",
    "#   f\" --lr             1e-3 \" +\n",
    "#   f\" --lr_steps         10 \" +\n",
    "#   f\" --lr_alpha        0.3\" \n",
    "# )\n",
    "\n",
    "# cmd = (\n",
    "#   f\" --x       {data_dir}/chembl_23mini_x.npy \" +\n",
    "#   f\" --y_class {data_dir}/chembl_23mini_adashare_y_all_bin_sparse.npy \" +\n",
    "#   f\" --folding {data_dir}/chembl_23mini_folds.npy \" +\n",
    "#   f\" --output_dir {output_dir}\" +    \n",
    "#   f\" --fold_va            0 \" +\n",
    "#   f\" --batch_ratio     0.02 \" +\n",
    "#   f\" --hidden_sizes   40 40 \" +\n",
    "#   f\" --dropouts_trunk  0  0 \" +\n",
    "#   f\" --weight_decay   1e-4 \" +\n",
    "#   f\" --epochs           20 \" +\n",
    "#   f\" --lr             1e-3 \" +\n",
    "#   f\" --lr_steps         10 \" +\n",
    "#   f\" --lr_alpha        0.3 \" \n",
    "# )\n",
    "\n",
    "#   f\" --hidden_sizes   400 400 \" +\n",
    "#   f\" --last_dropout   0.2 \" +\n",
    "#   f\" --middle_dropout 0.2 \" +\n",
    "#   f\" --x       ./{data_dir}/chembl_23_x.mtx \" +\n",
    "#   f\" --y_class ./{data_dir}/chembl_23_y.mtx \" +\n",
    "#   f\" --folding ./{data_dir}/folding_hier_0.6.npy \" +\n",
    "\n",
    "#### copied from SparseChemDev \n",
    "\n",
    "# cmd = (\n",
    "#         f\" --x       ./{data_dir}/chembl_23mini_x.npy\" +\n",
    "#         f\" --y_class ./{data_dir}/chembl_23mini_y.npy\" +\n",
    "#         f\" --folding ./{data_dir}/chembl_23mini_folds.npy\" +\n",
    "#         f\" --hidden_sizes 20 30 40 \" +  \n",
    "#         f\" --output_dir {output_dir}\" +\n",
    "#         f\" --batch_ratio 0.1\" +\n",
    "#         f\" --epochs 2\" +\n",
    "#         f\" --lr 1e-3\" +\n",
    "#         f\" --lr_steps 1\" +\n",
    "#         f\" --dev {dev}\" +\n",
    "#         f\" --verbose 1\")\n",
    "#         f\" --input_size_freq  40\"\n",
    "#         f\" --tail_hidden_size  10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c68af3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data_dir=\"chembl23_data\"\n",
    "# data_dir=\"chembl23_run_01152022\"\n",
    "# rstr = \"synthetic_data_model\" ##random_str(12)\n",
    "# rstr = \"synthetic_data_model_03042022\" ##random_str(12)\n",
    "# output_dir = f\"./models-{rstr}/\"\n",
    "# output_dir = f\"./{data_dir}/models-{rstr}/\"\n",
    "# output dir kbardool/kusanagi/experiments/SparseChem/0116_0843\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd7fea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T17:59:54.268012Z",
     "start_time": "2022-04-10T17:59:54.197660Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dev = \"gpu\" \n",
    "# data_dir=\"chembl23_data\"\n",
    "# data_dir=\"chembl23_run_01152022\"\n",
    "# data_dir = \"/home/kbardool/kusanagi/MLDatasets/chembl_23mini_synthetic\"\n",
    "\n",
    "# rm_output=False\n",
    "\n",
    "# rstr = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "# rstr = \"synthetic_data_model\" ##random_str(12)\n",
    "# rstr = \"synthetic_data_model_03042022\" ##random_str(12)\n",
    "\n",
    "# output_dir = f\"./models-{rstr}/\"\n",
    "# output_dir = f\"./{data_dir}/models-{rstr}/\"\n",
    "\n",
    "# output dir kbardool/kusanagi/experiments/SparseChem/0116_0843\n",
    "# output_dir = f\"/home/kbardool/kusanagi/experiments/SparseChem/{rstr}\"\n",
    "# print(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt-gpu",
   "language": "python",
   "name": "pyt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
