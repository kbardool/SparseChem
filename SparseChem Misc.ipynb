{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d685f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:32:56.731374Z",
     "start_time": "2021-12-12T17:32:56.700553Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04e62c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:01.128502Z",
     "start_time": "2021-12-12T17:32:59.022513Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from GPUtil import showUtilization as gpu_usage\n",
    "gpu_usage()                             \n",
    "\n",
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "# from numba import cuda\n",
    "\n",
    "print(' Allocated : ', torch.cuda.memory_allocated(\"cuda:2\") ) #returns you the current GPU memory usage by tensors in bytes for a given device\n",
    "print(' Reserved  : ', torch.cuda.memory_reserved(\"cuda:2\") )#returns you the current GPU memory managed by caching allocator in bytes for a given device, in previous PyTorch versions the command was torch.cuda.memory_cached\n",
    " \n",
    "\n",
    "# cuda_device = 0 \n",
    "\n",
    "# def free_gpu_cache(cuda_device):\n",
    "#     print(\"Initial GPU Usage\")    \n",
    "#     gpu_usage()                             \n",
    "\n",
    "#     print(\"GPU Usage after emptying the cache\")\n",
    "#     gpu_usage()\n",
    "    \n",
    "#     print(\"CUDA empty cache\")\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "#     print(\"Close and reopen device\")\n",
    "#     cuda.select_device(cuda_device)\n",
    "#     print(\"Close device\")    \n",
    "#     cuda.close()\n",
    "#     print(\"Reopen device\")    \n",
    "#     cuda.select_device(cuda_device)\n",
    "\n",
    "#     print(\"GPU Usage after closing and reopening\")\n",
    "#     gpu_usage()\n",
    "\n",
    "# # gpu_usage()                       \n",
    "# free_gpu_cache(1)\n",
    "# # gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a64ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:01.893520Z",
     "start_time": "2021-12-12T17:33:01.132439Z"
    }
   },
   "outputs": [],
   "source": [
    "print( torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace61eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:02.201080Z",
     "start_time": "2021-12-12T17:33:02.184377Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if ('../..' not in sys.path):\n",
    "    sys.path.append('../..')\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2d1de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:04.436687Z",
     "start_time": "2021-12-12T17:33:03.814750Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sparsechem as sc\n",
    "import numpy as np\n",
    "import string\n",
    "import glob\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "from urllib.request import urlretrieve\n",
    "from examples.chembl.test_train import random_str\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pprint\n",
    "import time\n",
    "from sparsechem.utils import training_arguments, load_task_weights\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b7148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:07.935967Z",
     "start_time": "2021-12-12T17:33:07.915738Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_input_parms(args):\n",
    "    \"\"\"Display Configuration values.\"\"\"\n",
    "    print(\"\\n   Arguments passed :\")\n",
    "    print(\"   --------------------\")\n",
    "    for a in dir(args):\n",
    "        if not a.startswith(\"__\") and not callable(getattr(args, a)):\n",
    "            print(\"   {:30} {}\".format(a, getattr(args, a)))\n",
    "    print(\"\\n\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ea879",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:14.198364Z",
     "start_time": "2021-12-12T17:33:14.174452Z"
    }
   },
   "outputs": [],
   "source": [
    "dev = \"cuda:0\"\n",
    "data_dir=\"test_chembl23\"\n",
    "rstr = random_str(12)\n",
    "output_dir = f\"./{data_dir}/models-{rstr}/\"\n",
    "print(f\"Call test_classification with dev: {dev} , data_dir: {data_dir} \\n\")  \n",
    "print(f\"Output dir : {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c2451d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:16.924358Z",
     "start_time": "2021-12-12T17:33:16.904539Z"
    }
   },
   "outputs": [],
   "source": [
    "def vprint(s=\"\"):\n",
    "    if args.verbose:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737ba282",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc782f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:19.843028Z",
     "start_time": "2021-12-12T17:33:19.816659Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = training_arguments()\n",
    "\n",
    "dev = \"cuda:0\" \n",
    "data_dir=\"test_chembl23\"\n",
    "rm_output=False\n",
    "rstr = random_str(12)\n",
    "output_dir = f\"./{data_dir}/models-{rstr}/\"\n",
    "cmd = (\n",
    "        f\" --x ./{data_dir}/chembl_23mini_x.npy\" +\n",
    "        f\" --y_class ./{data_dir}/chembl_23mini_y.npy\" +\n",
    "        f\" --folding ./{data_dir}/chembl_23mini_folds.npy\" +\n",
    "        f\" --batch_ratio 0.001\" +\n",
    "        f\" --output_dir {output_dir}\" +\n",
    "        f\" --hidden_sizes 20 20 \" +\n",
    "        f\" --epochs 2\" +\n",
    "        f\" --lr 1e-3\" +\n",
    "        f\" --lr_steps 1\" +\n",
    "        f\" --dev {dev}\" +\n",
    "        f\" --verbose 1\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args(cmd.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5b0db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T00:03:57.401130Z",
     "start_time": "2021-12-11T00:03:57.363067Z"
    }
   },
   "outputs": [],
   "source": [
    "display_input_parms(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1481d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:25.442773Z",
     "start_time": "2021-12-12T17:33:25.407051Z"
    }
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Generate runname if one wasn't provided in input args \n",
    "##\n",
    "if args.run_name is not None:\n",
    "    name = args.run_name\n",
    "else:\n",
    "    name  = f\"sc_{args.prefix}_h{'.'.join([str(h) for h in args.hidden_sizes])}_ldo{args.last_dropout:.1f}_wd{args.weight_decay}\"\n",
    "    name += f\"_lr{args.lr}_lrsteps{'.'.join([str(s) for s in args.lr_steps])}_ep{args.epochs}\"\n",
    "    name += f\"_fva{args.fold_va}_fte{args.fold_te}\"\n",
    "vprint(f\"\\nRun name is '{name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405031e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:26.214654Z",
     "start_time": "2021-12-12T17:33:26.190230Z"
    }
   },
   "outputs": [],
   "source": [
    "##\n",
    "## if args.save_board, Setup tensorboard writer\n",
    "##\n",
    "if args.save_board:\n",
    "    tb_name = os.path.join(args.output_dir, \"boards\", name)\n",
    "    vprint(f\"\\nargs.save_board is '{args.save_board}' - will be written to {tb_name}.\")\n",
    "    writer  = SummaryWriter(tb_name)\n",
    "else:\n",
    "    writer = Nothing()\n",
    "\n",
    "assert args.input_size_freq is None, \"Using tail compression not yet supported.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2c408e",
   "metadata": {},
   "source": [
    "### Load X (ecfp) and Y datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc0d12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:29.372862Z",
     "start_time": "2021-12-12T17:33:29.311522Z"
    }
   },
   "outputs": [],
   "source": [
    "## Verify presence of Y label data\n",
    "if (args.y_class is None) and (args.y_regr is None):\n",
    "    raise ValueError(\"No label data specified, please add --y_class and/or --y_regr.\")\n",
    "\n",
    "##\n",
    "\n",
    "\n",
    "\n",
    "ecfp     = sc.load_sparse(args.x)\n",
    "y_class  = sc.load_sparse(args.y_class)\n",
    "y_regr   = sc.load_sparse(args.y_regr)\n",
    "y_censor = sc.load_sparse(args.y_censor)\n",
    " \n",
    "vprint(f\"ecfp shape                   : {ecfp.shape}\")\n",
    "vprint(f\"y_class shape                : {y_class.shape}\")\n",
    "\n",
    "if (y_regr is not None):\n",
    "    vprint(f\"y_regr shape         : {y_regr.shape}\")\n",
    "\n",
    "if (y_censor is not None):\n",
    "    vprint(f\"y_censor shape       : {y_censor.shape}\")\n",
    "\n",
    "if (y_regr is None) and (y_censor is not None):\n",
    "    raise ValueError(\"y_censor provided please also provide --y_regr.\")\n",
    "\n",
    "if y_class is None:\n",
    "    y_class = scipy.sparse.csr_matrix((ecfp.shape[0], 0))\n",
    "    vprint(f\"Created y_class shape        : {y_class.shape}\")\n",
    "\n",
    "if y_regr is None:\n",
    "    y_regr  = scipy.sparse.csr_matrix((ecfp.shape[0], 0))\n",
    "    vprint(f\"Created y_regr shape         : {y_regr.shape}\")\n",
    "\n",
    "if y_censor is None:\n",
    "    y_censor = scipy.sparse.csr_matrix(y_regr.shape)\n",
    "    vprint(f\"Created y_censor shape       : {y_censor.shape}\")\n",
    "    \n",
    "folding = np.load(args.folding)\n",
    "assert ecfp.shape[0] == folding.shape[0], \"x and folding must have same number of rows\"\n",
    "vprint(f\"folding shape                : {folding.shape}\")\n",
    "\n",
    "\n",
    "vprint() \n",
    "vprint(f\"x shape              : {ecfp.shape}\")\n",
    "vprint(f\"y_class shape        : {y_class.shape}\")\n",
    "vprint(f\"y_regr shape         : {y_regr.shape}\")\n",
    "vprint(f\"y_censor shape       : {y_censor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c44317",
   "metadata": {},
   "source": [
    "### Loading task weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6830c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:33.044092Z",
     "start_time": "2021-12-12T17:33:33.023281Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(args.weights_class, args.weights_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cfbb29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:34.689845Z",
     "start_time": "2021-12-12T17:33:34.656736Z"
    }
   },
   "outputs": [],
   "source": [
    "## Loading task weights\n",
    "tasks_class = sc.load_task_weights(args.weights_class, y=y_class, label=\"y_class\")\n",
    "tasks_regr  = sc.load_task_weights(args.weights_regr, y=y_regr, label=\"y_regr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3d085e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:36.438857Z",
     "start_time": "2021-12-12T17:33:36.405725Z"
    }
   },
   "outputs": [],
   "source": [
    "if tasks_class.aggregation_weight is None:\n",
    "    '''\n",
    "    fold classes \n",
    "    '''\n",
    "    ## using min_samples rule\n",
    "    fold_pos, fold_neg = sc.class_fold_counts(y_class, folding)\n",
    "    n = args.min_samples_class\n",
    "    tasks_class.aggregation_weight = ((fold_pos >= n).all(0) & (fold_neg >= n)).all(0).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd910eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:37.939502Z",
     "start_time": "2021-12-12T17:33:37.918870Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tasks_class = sc.load_task_weights(args.weights_class, y=y_class, label=\"y_class\")\n",
    "# tasks_regr  = sc.load_task_weights(args.weights_regr , y=y_regr, label=\"y_regr\")\n",
    "\n",
    "# print(\"\\n\")\n",
    "# if tasks_class.aggregation_weight is None:\n",
    "#     '''\n",
    "#     fold classes \n",
    "#     '''\n",
    "#     ## using min_samples rule\n",
    "#     fold_pos, fold_neg = sc.class_fold_counts(y_class, folding)\n",
    "#     n = args.min_samples_class\n",
    "#     tasks_class.aggregation_weight = ((fold_pos >= n).all(0) & (fold_neg >= n)).all(0).astype(np.float64)    \n",
    "    \n",
    "    \n",
    "#     print(f\" fold_pos shape: {fold_pos.shape}\")\n",
    "#     print(fold_pos[4])\n",
    "#     print(f\"\\n fold_neg.shape  {fold_neg.shape}\")\n",
    "#     print(fold_neg[4])\n",
    "\n",
    "#     print(f\"\\n min_smaples_class: {args.min_samples_class}\")\n",
    "    \n",
    "#     print(f\"\\n (fold_pos >= n) {(fold_pos >=n).shape}\")\n",
    "#     print((fold_pos >= n)[4])\n",
    "#     print(f\"\\n (fold_neg >= n)  {(fold_neg >=n).shape}\")\n",
    "#     print((fold_neg >= n)[4])\n",
    "#     print()\n",
    "#     print(f\"\\n (fold_pos >= n).all(0) shape:   {(fold_pos >= n).all(0).shape}\")\n",
    "#     print(f\"\\n  {(fold_pos >= n).all(0)}\")\n",
    "#     print()\n",
    "#     print(f\"\\n (fold_neg >= n).all(0) shape:  {(fold_neg >= n).all(0).shape}\")\n",
    "#     print(f\"\\n  {(fold_neg >= n).all(0)}\")    \n",
    "\n",
    "#     a1 =( (fold_pos >= n).all(0) & (fold_neg >= n) ).all(0)\n",
    "#     a2 =( (fold_pos >= n).all(0) & (fold_neg >= n).all(0))\n",
    "#     a3 =( (fold_pos >= n) & (fold_neg >= n) ).all(0)\n",
    "    \n",
    "#     vprint(f\"\\n\\n ( (fold_pos >= n).all(0) & (fold_neg >= n)).all(0): {a1.shape}  \")\n",
    "#     vprint(f\"{a1}\" )\n",
    "    \n",
    "#     vprint(f\"\\n\\n ( (fold_pos >= n).all(0) & (fold_neg >= n).all(0) ) : {a2.shape}  \\n\")\n",
    "#     vprint(f\"{a2}  \\n\")\n",
    "\n",
    "    \n",
    "#     vprint(f\"\\n\\n [(fold_pos >= n) & (fold_neg >= n )].all(0): {a3.shape}  \")\n",
    "#     vprint(f\"{a3}\" )\n",
    "    \n",
    "    \n",
    "#     print((a1==a2).all(),  (a1==a3).all())\n",
    "#     vprint(f\"tasks_class.aggregation_weight : \\n{tasks_class.aggregation_weight}  \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791035b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:38.639978Z",
     "start_time": "2021-12-12T17:33:38.601165Z"
    }
   },
   "outputs": [],
   "source": [
    "if tasks_regr.aggregation_weight is None:\n",
    "    print(\"proceed\")\n",
    "    if y_censor.nnz == 0:\n",
    "        y_regr2 = y_regr.copy()\n",
    "        y_regr2.data[:] = 1\n",
    "    else:\n",
    "        ## only counting uncensored data\n",
    "        y_regr2      = y_censor.copy()\n",
    "        y_regr2.data = (y_regr2.data == 0).astype(np.int32)\n",
    "  \n",
    "    fold_regr, _ = sc.class_fold_counts(y_regr2, folding)\n",
    "    print(' fold_regr:', fold_regr)\n",
    "    del y_regr2\n",
    "    tasks_regr.aggregation_weight = (fold_regr >= args.min_samples_regr).all(0).astype(np.float64)\n",
    "    print(tasks_regr.aggregation_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6690883b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:39.259752Z",
     "start_time": "2021-12-12T17:33:39.199536Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vprint(f\"tasks_class.training_weight: \\n{tasks_class.training_weight} \\n\")\n",
    "vprint(f\"tasks_class.aggregation_weight : \\n{tasks_class.aggregation_weight}  \\n\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce715e",
   "metadata": {},
   "source": [
    "#### load_task_weights() : step by step:\n",
    "\n",
    "Executed when a filename is passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66216cd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:42.175513Z",
     "start_time": "2021-12-12T17:33:42.156120Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/home/kevin/MLDatasets/chembl_23_mini/chembl_23mini_class_weights.csv')\n",
    "# df.rename(columns={\"weight\": \"training_weight\"}, inplace=True)\n",
    "# df.rename(columns={c + \"s\": c for c in [\"task_id\", \"training_weight\", \"aggregation_weight\", \"task_type\", \"censored_weight\"]}, inplace=True)\n",
    "# assert \"task_id\" in df.columns, \"task_id is missing in task info CVS file\"\n",
    "# assert \"training_weight\" in df.columns, \"training_weight is missing in task info CSV file\"\n",
    "# df.sort_values(\"task_id\", inplace=True)\n",
    "# df\n",
    "\n",
    "# cols = [\"\", \"task_id\", \"training_weight\", \"aggregation_weight\", \"task_type\", \"censored_weight\"]\n",
    "# for col in df.columns:\n",
    "#     print(' col: ',col)\n",
    "#     assert col in cols, f\"Unsupported colum '{col}' in task weight file. Supported columns: {cols}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb08638e",
   "metadata": {},
   "source": [
    "### Input folding & transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5bc41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:33:43.065001Z",
     "start_time": "2021-12-12T17:33:43.021189Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"args.fold_inputs : {args.fold_inputs} \\t\\t  transform: {args.input_transform}\\n\")\n",
    "print(repr(ecfp))\n",
    "ecfp = sc.fold_transform_inputs(ecfp, folding_size=args.fold_inputs, transform=args.input_transform)##\n",
    "print(repr(ecfp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086041f2",
   "metadata": {},
   "source": [
    "### Get number of positive / neg and total for each classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8aa275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:34:01.556380Z",
     "start_time": "2021-12-12T17:34:01.524404Z"
    }
   },
   "outputs": [],
   "source": [
    "num_pos    = np.array((y_class == +1).sum(0)).flatten()\n",
    "num_neg    = np.array((y_class == -1).sum(0)).flatten()\n",
    "num_class  = np.array((y_class != 0).sum(0)).flatten()\n",
    "\n",
    "if (num_class != num_pos + num_neg).any():\n",
    "    raise ValueError(\"For classification all y values (--y_class/--y) must be 1 or -1.\")\n",
    "\n",
    "num_regr   = np.bincount(y_regr.indices, minlength=y_regr.shape[1])\n",
    "\n",
    "print(' num_regr          : ', num_regr)\n",
    "print(' folding file      : ', folding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ff166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:34:03.626186Z",
     "start_time": "2021-12-12T17:34:03.602344Z"
    }
   },
   "outputs": [],
   "source": [
    "vprint(f\"Input dimension      : {ecfp.shape[1]}\")\n",
    "vprint(f\"#samples             : {ecfp.shape[0]}\")\n",
    "vprint(f\"#classification tasks: {y_class.shape[1]}\")\n",
    "vprint(f\"#regression tasks    : {y_regr.shape[1]}\")\n",
    "vprint(f\"Using {(tasks_class.aggregation_weight > 0).sum()} classification tasks for calculating aggregated metrics (AUCROC, F1_max, etc).\")\n",
    "vprint(f\"Using {(tasks_regr.aggregation_weight > 0).sum()} regression tasks for calculating metrics (RMSE, Rsquared, correlation).\")\n",
    "vprint(f\"args.fold_te         : {args.fold_te}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a60dcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:34:05.263319Z",
     "start_time": "2021-12-12T17:34:05.241796Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.fold_te is not None and args.fold_te >= 0:\n",
    "    ## removing test data\n",
    "    assert args.fold_te != args.fold_va, \"fold_va and fold_te must not be equal.\"\n",
    "    keep    = folding != args.fold_te\n",
    "    ecfp    = ecfp[keep]\n",
    "    y_class = y_class[keep]\n",
    "    y_regr  = y_regr[keep]\n",
    "    y_censor= y_censor[keep]\n",
    "    folding = folding[keep]\n",
    "else:\n",
    "    print(\"args.fold_te is None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12d1e1f",
   "metadata": {},
   "source": [
    "### Identify training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6135b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:34:07.455776Z",
     "start_time": "2021-12-12T17:34:07.430907Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_va = args.fold_va\n",
    "\n",
    "idx_tr  = np.where(folding != fold_va)[0]\n",
    "idx_va  = np.where(folding == fold_va)[0]\n",
    "\n",
    "vprint(f\"fold_va        : {fold_va}\")\n",
    "vprint(f\"idx_va         : {idx_tr}    Length: {len(idx_tr)}\")\n",
    "vprint(f\"idx_va         : {idx_va}    Length: {len(idx_va)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41412c62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:34:08.233212Z",
     "start_time": "2021-12-12T17:34:08.193939Z"
    }
   },
   "outputs": [],
   "source": [
    "y_class_tr = y_class[idx_tr]\n",
    "y_class_va = y_class[idx_va]\n",
    "y_regr_tr  = y_regr[idx_tr]\n",
    "y_regr_va  = y_regr[idx_va]\n",
    "y_censor_tr = y_censor[idx_tr]\n",
    "y_censor_va = y_censor[idx_va]\n",
    "\n",
    "print('y_class_tr : ', repr(y_class_tr))\n",
    "print('y_regr_tr  : ', repr(y_regr_tr))\n",
    "print('y_censor_tr: ', repr(y_censor_tr))\n",
    "print()\n",
    "print('y_class_tr : ', repr(y_class_va))\n",
    "print('y_regr_tr  : ', repr(y_regr_va))\n",
    "print('y_censor_tr: ', repr(y_censor_va))      \n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53beb9ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:34:08.989914Z",
     "start_time": "2021-12-12T17:34:08.960298Z"
    }
   },
   "outputs": [],
   "source": [
    "num_pos_va  = np.array((y_class_va == +1).sum(0)).flatten()\n",
    "num_neg_va  = np.array((y_class_va == -1).sum(0)).flatten()\n",
    "num_regr_va = np.bincount(y_regr_va.indices, minlength=y_regr.shape[1])\n",
    "\n",
    "print(f' num pos va : {num_pos_va[:100]}  sum: {num_pos_va.sum()}')\n",
    "print(f' num neg va : {num_neg_va[:100]}  sum: {num_neg_va.sum()}')\n",
    "print(f' num regr va: {num_regr_va}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b04aa",
   "metadata": {},
   "source": [
    "### Determine Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e7d5f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:53:26.703093Z",
     "start_time": "2021-12-12T17:53:26.681383Z"
    }
   },
   "outputs": [],
   "source": [
    "args.internal_batch_max = None\n",
    "batch_size  = int(np.ceil(args.batch_ratio * idx_tr.shape[0]))\n",
    "num_int_batches = 1\n",
    "\n",
    "print(f\" internal_batch_max: {args.internal_batch_max}\")\n",
    "print(f\" batch ratio:  {args.batch_ratio}\") \n",
    "print(f\" training file size (idx_tr.shape): {idx_tr.shape}\")\n",
    "print(f\" batch size:  batch ratio * idx_tr.shape[0] : {args.batch_ratio * idx_tr.shape[0]}  -> {batch_size}\")\n",
    "\n",
    "\n",
    "args.internal_batch_max = None\n",
    "\n",
    "\n",
    "if args.internal_batch_max is not None:\n",
    "    if args.internal_batch_max < batch_size:\n",
    "        print(f\" batch size is ({batch_size}) larger than internal batch maximum size ({args.internal_batch_max})\")\n",
    "        print(f\" batch_size / args.internal_batch_max : {batch_size / args.internal_batch_max}\")\n",
    "        print(f\" num int_batches: {int(np.ceil(batch_size / args.internal_batch_max))}\")\n",
    "\n",
    "        num_int_batches = int(np.ceil(batch_size / args.internal_batch_max)) \n",
    "        \n",
    "        print(f\" batch_size / num_int_batches : {batch_size / num_int_batches}\")\n",
    "        print(f\" batch_size: {int(np.ceil(batch_size / num_int_batches))}\")\n",
    "        \n",
    "        batch_size      = int(np.ceil(batch_size / num_int_batches))\n",
    "        \n",
    "\n",
    "vprint(f\" batch size:            {batch_size}\")\n",
    "vprint(f\" internal batch size:   {num_int_batches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141050a8",
   "metadata": {},
   "source": [
    "\n",
    "### Instantiate Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427767e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:24.299479Z",
     "start_time": "2021-12-12T17:54:24.277465Z"
    }
   },
   "outputs": [],
   "source": [
    "ecfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cfccde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:24.533790Z",
     "start_time": "2021-12-12T17:54:24.488643Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_tr = sc.ClassRegrSparseDataset(x=ecfp[idx_tr], y_class=y_class_tr, y_regr=y_regr_tr, y_censor=y_censor_tr)\n",
    "dataset_va = sc.ClassRegrSparseDataset(x=ecfp[idx_va], y_class=y_class_va, y_regr=y_regr_va, y_censor=y_censor_va)\n",
    "\n",
    "print(dataset_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865b6c75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:31.432995Z",
     "start_time": "2021-12-12T17:54:31.410117Z"
    }
   },
   "outputs": [],
   "source": [
    "loader_tr = DataLoader(dataset_tr, batch_size=batch_size, num_workers = 1, pin_memory=True, collate_fn=dataset_tr.collate, shuffle=True)\n",
    "loader_va = DataLoader(dataset_va, batch_size=batch_size, num_workers = 1, pin_memory=True, collate_fn=dataset_va.collate, shuffle=False)\n",
    "\n",
    "args.input_size  = dataset_tr.input_size\n",
    "args.output_size = dataset_tr.output_size\n",
    "\n",
    "args.class_output_size = dataset_tr.class_output_size\n",
    "args.regr_output_size  = dataset_tr.regr_output_size\n",
    "\n",
    "print(f\" input size        : {dataset_tr.input_size}     output size: {dataset_tr.output_size}\")\n",
    "print(f\" class output size : {dataset_tr.class_output_size}     regr_output_size : {dataset_tr.regr_output_size}\")\n",
    "print(f\" Batch size        : {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409575e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:25.005063Z",
     "start_time": "2021-12-12T17:54:24.985644Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# batch_enumerator  = enumerate(loader_tr)\n",
    "\n",
    "#  a1 = [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  8,  9, 10, 11, 12, 13, 14]\n",
    "#  a2 = [ 4, 41, 74, 33, 50,  0, 33, 38, 43, 48,  0, 28, 14, 54, 10, 85]\n",
    "\n",
    "# b1 = np.array(a1)\n",
    "# print(b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a812d8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f9d15",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Display Input Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd8154a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:38.051383Z",
     "start_time": "2021-12-12T17:54:38.032891Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# display_input_parms(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c7a61",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6fd91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:48:56.071768Z",
     "start_time": "2021-12-12T17:48:56.050761Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d478fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:40.044024Z",
     "start_time": "2021-12-12T17:54:39.992045Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dev  = torch.device(args.dev)\n",
    "print(f\" dev: {dev}\")\n",
    "\n",
    "net  = sc.SparseFFN(args)\n",
    "# net  = sc.SparseFFN(args).to(dev)\n",
    "print(f\" Net: \\n {net}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b04f0b6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Summarize the defined model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2272407",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    Summarize the given PyTorch model. Summarized information includes:\n",
    "        1) Layer names,\n",
    "        2) input/output shapes,\n",
    "        3) kernel shape,\n",
    "        4) # of parameters,\n",
    "        5) # of operations (Mult-Adds)\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module):\n",
    "                PyTorch model to summarize. The model should be fully in either train()\n",
    "                or eval() mode. If layers are not all in the same mode, running summary\n",
    "                may have side effects on batchnorm or dropout statistics. If you\n",
    "                encounter an issue with this, please open a GitHub issue.\n",
    "\n",
    "    input_data (Sequence of Sizes or Tensors):\n",
    "            Example input tensor of the model (dtypes inferred from model input).\n",
    "            - OR -\n",
    "            Shape of input data as a List/Tuple/torch.Size\n",
    "            (dtypes must match model input, default is FloatTensors).\n",
    "            You should NOT include batch size in the tuple.\n",
    "            - OR -\n",
    "            If input_data is not provided, no forward pass through the network is\n",
    "            performed, and the provided model information is limited to layer names.\n",
    "            Default: None\n",
    "\n",
    "    batch_dim (int):\n",
    "            Batch_dimension of input data. If batch_dim is None, the input data\n",
    "            is assumed to contain the batch dimension.\n",
    "            WARNING: in a future version, the default will change to None.\n",
    "            Default: 0\n",
    "\n",
    "    branching (bool):\n",
    "            Whether to use the branching layout for the printed output.\n",
    "            Default: True\n",
    "\n",
    "    col_names (Iterable[str]):\n",
    "            Specify which columns to show in the output. Currently supported:\n",
    "            (\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\")\n",
    "            If input_data is not provided, only \"num_params\" is used.\n",
    "            Default: (\"output_size\", \"num_params\")\n",
    "\n",
    "    col_width (int):\n",
    "            Width of each column.\n",
    "            Default: 25\n",
    "\n",
    "    depth (int):\n",
    "            Number of nested layers to traverse (e.g. Sequentials).\n",
    "            Default: 3\n",
    "\n",
    "    device (torch.Device):\n",
    "            Uses this torch device for model and input_data.\n",
    "            If not specified, uses result of torch.cuda.is_available().\n",
    "            Default: None\n",
    "\n",
    "    dtypes (List[torch.dtype]):\n",
    "            For multiple inputs, specify the size of both inputs, and\n",
    "            also specify the types of each parameter here.\n",
    "            Default: None\n",
    "\n",
    "    verbose (int):\n",
    "            0 (quiet): No output\n",
    "            1 (default): Print model summary\n",
    "            2 (verbose): Show weight and bias layers in full detail\n",
    "            Default: 1\n",
    "\n",
    "    *args, **kwargs:\n",
    "            Other arguments used in `model.forward` function.\n",
    "\n",
    "    Return:\n",
    "        ModelStatistics object\n",
    "                See torchsummary/model_statistics.py for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed2615f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Display Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7301c71e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:42.527807Z",
     "start_time": "2021-12-12T17:54:42.006192Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# summary(model, input_size=(batch_size, 1, 28, 28))\n",
    "\n",
    "summary(net, input_size=(200, 85277), \n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"],\n",
    "        verbose=2,\n",
    "        depth = 6,\n",
    "        col_width=16,\n",
    "        device='cuda:0',\n",
    "        row_settings=[\"depth\",\"var_names\"],);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8adb5b0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Loss functions , Weights, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca06d4b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:42.795010Z",
     "start_time": "2021-12-12T17:54:42.774270Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_class = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "loss_regr  = sc.censored_mse_loss\n",
    "\n",
    "if not args.censored_loss:\n",
    "    loss_regr = functools.partial(loss_regr, censored_enabled=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43017f55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:43.217715Z",
     "start_time": "2021-12-12T17:54:43.191775Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(repr(loss_regr))\n",
    "print(repr(loss_class))\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a39af9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:44.336524Z",
     "start_time": "2021-12-12T17:54:44.308070Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tasks_class.training_weight = tasks_class.training_weight.to(dev)\n",
    "tasks_regr.training_weight  = tasks_regr.training_weight.to(dev)\n",
    "tasks_regr.censored_weight  = tasks_regr.censored_weight.to(dev)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "scheduler = MultiStepLR(optimizer, milestones=args.lr_steps, gamma=args.lr_alpha)\n",
    "\n",
    "num_prints = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce589a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:44.683116Z",
     "start_time": "2021-12-12T17:54:44.661470Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(optimizer)\n",
    "print(f\"LR steps: {args.lr_steps}   gamma: {args.lr_alpha}\")\n",
    "print(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af065594",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:48.826391Z",
     "start_time": "2021-12-12T17:54:48.806268Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sparsechem import Nothing\n",
    "# if args.save_board:\n",
    "#     tb_name = os.path.join(args.output_dir, \"boards\", name)\n",
    "#     vprint(f\"\\nargs.save_board is '{args.save_board}' - will be written to {tb_name}.\")\n",
    "#     writer  = SummaryWriter(tb_name)\n",
    "# else:\n",
    "writer = Nothing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f0c6aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:49:52.106147Z",
     "start_time": "2021-12-12T17:49:52.087491Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#     print(\"Initial GPU Usage\")    \n",
    "#     gpu_usage()         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597eea10",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e5f0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:51.431117Z",
     "start_time": "2021-12-12T17:54:51.410781Z"
    }
   },
   "outputs": [],
   "source": [
    "args.epochs = 40\n",
    "print(args.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9ed01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:54:53.229049Z",
     "start_time": "2021-12-12T17:54:52.825894Z"
    }
   },
   "outputs": [],
   "source": [
    "print(tasks_class.training_weight)\n",
    "print(num_int_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15c9df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T18:22:41.789073Z",
     "start_time": "2021-12-12T18:22:41.766141Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
    "torch.set_printoptions( linewidth=132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d4b4a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T18:25:48.616576Z",
     "start_time": "2021-12-12T18:25:47.697794Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Training loop\n",
    "##\n",
    "for epoch in range(args.epochs):\n",
    "    t0 = time.time()\n",
    "    sc.train_class_regr(\n",
    "        net, optimizer,\n",
    "        loader          = loader_tr,\n",
    "        loss_class      = loss_class,\n",
    "        loss_regr       = loss_regr,\n",
    "        dev             = dev,\n",
    "        weights_class   = tasks_class.training_weight,\n",
    "        weights_regr    = tasks_regr.training_weight,\n",
    "        censored_weight = tasks_regr.censored_weight,\n",
    "        normalize_loss  = args.normalize_loss,\n",
    "        num_int_batches = num_int_batches,\n",
    "        progress        = args.verbose >= 2)\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    eval_round = (args.eval_frequency > 0) and ((epoch + 1) % args.eval_frequency == 0)\n",
    "    last_round = epoch == args.epochs - 1\n",
    "    break\n",
    "    \n",
    "    if eval_round or last_round:\n",
    "        results_va = sc.evaluate_class_regr(net, loader_va, \n",
    "                                            loss_class, \n",
    "                                            loss_regr, \n",
    "                                            tasks_class=tasks_class, \n",
    "                                            tasks_regr=tasks_regr, \n",
    "                                            dev=dev, \n",
    "                                            progress = args.verbose >= 2)\n",
    "        for key, val in results_va[\"classification_agg\"].items():\n",
    "            writer.add_scalar(key+\"/va\", val, epoch)\n",
    "        for key, val in results_va[\"regression_agg\"].items():\n",
    "            writer.add_scalar(key+\"/va\", val, epoch)\n",
    "\n",
    "        if args.eval_train:\n",
    "            results_tr = sc.evaluate_class_regr(net, loader_tr, \n",
    "                                                loss_class, loss_regr, \n",
    "                                                tasks_class=tasks_class, tasks_regr=tasks_regr, \n",
    "                                                dev=dev, progress = args.verbose >= 2)\n",
    "            for key, val in results_tr[\"classification_agg\"].items():\n",
    "                writer.add_scalar(key+\"/tr\", val, epoch)\n",
    "            for key, val in results_tr[\"regression_agg\"].items():\n",
    "                writer.add_scalar(key+\"/tr\", val, epoch)\n",
    "        else:\n",
    "            results_tr = None\n",
    "\n",
    "        if args.verbose:\n",
    "            ## printing a new header every 20 lines\n",
    "            header = num_prints % 20 == 0\n",
    "            num_prints += 1\n",
    "            sc.print_metrics_cr(epoch, t1 - t0, results_tr, results_va, header)\n",
    "\n",
    "    scheduler.step()\n",
    "    print('-'*100)\n",
    "    print('-'*100)\n",
    "    print('-'*100)    \n",
    "    break\n",
    "# writer.close()\n",
    "# vprint()\n",
    "# vprint(\"Saving performance metrics (AUCs) and model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373ffdf0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### `train_class_regr()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160acf41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:52:21.613021Z",
     "start_time": "2021-12-10T20:52:21.591462Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def train_class_regr(net, optimizer, loader, loss_class, loss_regr, dev,\n",
    "#                      weights_class, weights_regr, censored_weight,\n",
    "#                      normalize_loss=None, num_int_batches=1, progress=True):\n",
    "#     sc.train_class_regr(\n",
    "#         net, \n",
    "#         optimizer,\n",
    "loader          = loader_tr\n",
    "#         loss_class      = loss_class,\n",
    "#         loss_regr       = loss_regr,\n",
    "#         dev             = dev,\n",
    "weights_class   = tasks_class.training_weight\n",
    "weights_regr    = tasks_regr.training_weight\n",
    "censored_weight = tasks_regr.censored_weight\n",
    "normalize_loss  = args.normalize_loss\n",
    "num_int_batches = 1\n",
    "progress        = args.verbose >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f81c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:52:24.487175Z",
     "start_time": "2021-12-10T20:52:24.465915Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net.train()\n",
    "int_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc080e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:52:25.674142Z",
     "start_time": "2021-12-10T20:52:25.641450Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from tqdm  import tqdm\n",
    "print(type(loader))\n",
    "print(normalize_loss)\n",
    "print(num_int_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb231718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T20:52:28.187735Z",
     "start_time": "2021-12-10T20:52:28.103898Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "b = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c60d3ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T21:15:51.389313Z",
     "start_time": "2021-12-10T21:15:51.345451Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print( b.keys())\n",
    "for key in b.keys():\n",
    "    if isinstance(b[key], torch.Tensor):\n",
    "        print(f\" {key:10s}:   {b[key].shape}\")\n",
    "    elif isinstance(b[key], int):\n",
    "        print(f\" {key:10s}:   {b[key]}\")\n",
    "    else:\n",
    "        print(f\" {key:10s}:   {b[key]}\")\n",
    "\n",
    "print(type(y_class))        \n",
    "print(f\"yc_ind: \\n {b['yc_ind'][0]} \\n\\n {b['yc_ind'][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ec9d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T10:41:35.839373Z",
     "start_time": "2021-11-10T10:41:35.808250Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 0 ;\n",
    "# for b in tqdm(loader, leave=False, disable=(progress == False)):\n",
    "# b = next(iter(loader))\n",
    "print(i, b.keys())\n",
    "i+=1\n",
    "for key in b.keys():\n",
    "\n",
    "    if b[key] is None:\n",
    "        continue\n",
    "    if isinstance(b[key], torch.Tensor):\n",
    "        print(f\" {key:10s}:   {b[key].shape}\")\n",
    "    elif isinstance(b[key], int):\n",
    "        print(f\" {key}:   {b[key]}\")\n",
    "\n",
    "if int_count == 0:\n",
    "    print(\"optimizer.zero_grad()\")\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde13f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T05:02:06.223150Z",
     "start_time": "2021-09-14T05:02:06.198121Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985e05c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T10:41:40.916357Z",
     "start_time": "2021-11-10T10:41:40.888634Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "norm = normalize_loss\n",
    "print(f\"Normalize loss : {norm}\")\n",
    "if norm is None:\n",
    "    norm = b[\"batch_size\"] * num_int_batches\n",
    "print(f\"Normalize loss : {norm}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f66ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T10:41:42.693075Z",
     "start_time": "2021-11-10T10:41:42.662502Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fwd = batch_forward(net, b=b, \n",
    "                    input_size=loader.dataset.input_size, \n",
    "                    loss_class=loss_class, loss_regr=loss_regr, \n",
    "                    weights_class=weights_class, weights_regr=weights_regr, censored_weight=censored_weight, \n",
    "                    dev=dev)\n",
    "# fwd = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c506d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T10:41:44.419456Z",
     "start_time": "2021-11-10T10:41:44.390813Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss = fwd[\"yc_loss\"] + fwd[\"yr_loss\"]\n",
    "loss_norm = loss / norm\n",
    "print(f\" loss: {loss}      loss_norm: {loss_norm}    {type(loss_norm)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b405d5f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T10:41:49.026735Z",
     "start_time": "2021-11-10T10:41:48.977796Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_norm.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa516f0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T10:41:51.567858Z",
     "start_time": "2021-11-10T10:41:51.527403Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "int_count += 1\n",
    "print(int_count, num_int_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194862f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T10:41:55.585650Z",
     "start_time": "2021-11-10T10:41:55.538730Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if int_count == num_int_batches:\n",
    "    print(\" optimizer.step()\")\n",
    "    optimizer.step()\n",
    "    int_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068da2da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T10:41:58.774117Z",
     "start_time": "2021-11-10T10:41:58.728779Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if int_count > 0:\n",
    "    ## process tail batch (should not happen)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9146c5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  `batch_forward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9049b5f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:37:35.206388Z",
     "start_time": "2021-09-14T04:37:35.189198Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def batch_forward(net, b, input_size, loss_class, loss_regr, weights_class, weights_regr, censored_weight=[], dev=\"cpu\"):\n",
    "\n",
    "\n",
    "# fwd = batch_forward(net, b=b, \n",
    "#                     input_size=loader.dataset.input_size, \n",
    "#                     loss_class=loss_class, \n",
    "#                     loss_regr=loss_regr, \n",
    "#                     weights_class=weights_class, \n",
    "#                     weights_regr=weights_regr, \n",
    "#                     censored_weight=censored_weight, \n",
    "#                     dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623cec91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:39:16.132993Z",
     "start_time": "2021-09-14T04:39:16.116388Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_size = loader.dataset.input_size\n",
    "#                     loss_class = loss_class\n",
    "#                     loss_regr  = loss_regr\n",
    "#                     weights_class=weights_class, \n",
    "#                     weights_regr=weights_regr, \n",
    "#                     censored_weight=censored_weight, \n",
    "#                     dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba6da2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:41:39.009362Z",
     "start_time": "2021-09-14T04:41:38.987669Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\" input size : {input_size}\")\n",
    "print(b[\"x_ind\"][:,:4])\n",
    "print(b[\"x_ind\"][:,-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e8371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:41:55.843811Z",
     "start_time": "2021-09-14T04:41:55.823900Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = torch.sparse_coo_tensor(\n",
    "    b[\"x_ind\"],\n",
    "    b[\"x_data\"],\n",
    "    size = [b[\"batch_size\"], input_size]).to(dev, non_blocking=True)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94ac430",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:42:09.714465Z",
     "start_time": "2021-09-14T04:42:09.693651Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "yc_hat_all, yr_hat_all = net(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295dfe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:44:49.661051Z",
     "start_time": "2021-09-14T04:44:49.644279Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions( linewidth=120)\n",
    "torch.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eace388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:44:50.221911Z",
     "start_time": "2021-09-14T04:44:50.201244Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(yc_hat_all.shape)\n",
    "print(yc_hat_all[:5,:10])\n",
    "print(yr_hat_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202bd317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:45:16.833611Z",
     "start_time": "2021-09-14T04:45:16.815755Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out = {}\n",
    "out[\"yc_hat_all\"] = yc_hat_all\n",
    "out[\"yr_hat_all\"] = yr_hat_all\n",
    "out[\"yc_loss\"]    = 0\n",
    "out[\"yr_loss\"]    = 0\n",
    "out[\"yc_weights\"] = 0\n",
    "out[\"yr_weights\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf58dad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:50:54.288584Z",
     "start_time": "2021-09-14T04:50:54.265133Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(b[\"yc_ind\"].shape, '\\n', b[\"yc_ind\"][:,:20])\n",
    "print(b[\"yc_data\"].shape, '\\n', b[\"yc_data\"][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409640b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:55:16.884612Z",
     "start_time": "2021-09-14T04:55:16.864091Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if net.class_output_size > 0:\n",
    "    print(net.class_output_size)\n",
    "    yc_ind  = b[\"yc_ind\"].to(dev, non_blocking=True)\n",
    "    yc_w    = weights_class[yc_ind[1]]\n",
    "    yc_data = b[\"yc_data\"].to(dev, non_blocking=True)\n",
    "    yc_hat  = yc_hat_all[yc_ind[0], yc_ind[1]]\n",
    "    out[\"yc_ind\"]  = yc_ind\n",
    "    out[\"yc_data\"] = yc_data\n",
    "    out[\"yc_hat\"]  = yc_hat\n",
    "    out[\"yc_loss\"] = (loss_class(yc_hat, yc_data) * yc_w).sum()\n",
    "    out[\"yc_weights\"] = yc_w.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67475c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:56:01.037600Z",
     "start_time": "2021-09-14T04:56:01.008366Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(b[\"yc_data\"].shape, '\\n', b[\"yc_data\"][:20])\n",
    "print(yc_hat.shape, '\\n', yc_hat[:20])\n",
    "print(yc_w.shape, '\\n' , yc_w[:20] )\n",
    "print(loss_class(yc_hat, yc_data).shape, '\\n', loss_class(yc_hat, yc_data)[:20])\n",
    "print(out[\"yc_loss\"].shape, '\\n', out[\"yc_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a919850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:57:05.393723Z",
     "start_time": "2021-09-14T04:57:05.373948Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net.regr_output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93210949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T04:57:27.497538Z",
     "start_time": "2021-09-14T04:57:27.475777Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if net.regr_output_size > 0:\n",
    "    yr_ind  = b[\"yr_ind\"].to(dev, non_blocking=True)\n",
    "    yr_w    = weights_regr[yr_ind[1]]\n",
    "    yr_data = b[\"yr_data\"].to(dev, non_blocking=True)\n",
    "    yr_hat  = yr_hat_all[yr_ind[0], yr_ind[1]]\n",
    "\n",
    "    out[\"ycen_data\"] = b[\"ycen_data\"]\n",
    "    if out[\"ycen_data\"] is not None:\n",
    "        out[\"ycen_data\"] = out[\"ycen_data\"].to(dev, non_blocking=True)\n",
    "\n",
    "        if len(censored_weight) > 0:\n",
    "            ## updating weights of censored data\n",
    "            yrcen_w = yr_w * censored_weight[yr_ind[1]]\n",
    "            yr_w    = torch.where(out[\"ycen_data\"] == 0, yr_w, yrcen_w)\n",
    "\n",
    "    out[\"yr_ind\"]  = yr_ind\n",
    "    out[\"yr_data\"] = yr_data\n",
    "    out[\"yr_hat\"]  = yr_hat\n",
    "    out[\"yr_loss\"] = (loss_regr(input=yr_hat, target=yr_data, censor=out[\"ycen_data\"]) * yr_w).sum()\n",
    "    out[\"yr_weights\"] = yr_w.sum()\n",
    "else:\n",
    "    print(\"net.regr_output_size is 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebafd6ff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba23e64",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e1edb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5d0955",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb86c62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T22:47:10.639523Z",
     "start_time": "2021-07-21T22:47:10.617490Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# i = torch.LongTensor((np.arange(10),np.arange(10)))\n",
    "# v = torch.FloatTensor(np.random.normal(size=10))\n",
    "# G = torch.sparse.FloatTensor(i,v,torch.Size((100,100)))\n",
    "# x = torch.Tensor(np.random.normal(size=100))\n",
    "# device = torch.device('cpu')\n",
    "# x = x.to(device)\n",
    "# torch.mm(G, x.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dc8e1d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### training functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b2357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T10:41:27.492990Z",
     "start_time": "2021-11-10T10:41:27.462676Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_class_regr(net, optimizer, loader, loss_class, loss_regr, dev,\n",
    "                     weights_class, weights_regr, censored_weight,\n",
    "                     normalize_loss=None, num_int_batches=1, progress=True):\n",
    "    \n",
    "    ## Set the model in training mode.\n",
    "    net.train()\n",
    "\n",
    "    int_count = 0\n",
    "    for b in tqdm(loader, leave=False, disable=(progress == False)):\n",
    "        if int_count == 0:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        norm = normalize_loss\n",
    "        if norm is None:\n",
    "            norm = b[\"batch_size\"] * num_int_batches\n",
    "\n",
    "        fwd = batch_forward(net, b=b, \n",
    "                            input_size=loader.dataset.input_size, \n",
    "                            loss_class=loss_class, loss_regr=loss_regr, \n",
    "                            weights_class=weights_class, weights_regr=weights_regr, censored_weight=censored_weight, \n",
    "                            dev=dev)\n",
    "        loss = fwd[\"yc_loss\"] + fwd[\"yr_loss\"]\n",
    "        loss_norm = loss / norm\n",
    "    \n",
    "        loss_norm.backward()\n",
    "\n",
    "        int_count += 1\n",
    "        if int_count == num_int_batches:\n",
    "            optimizer.step()\n",
    "            int_count = 0\n",
    "\n",
    "    if int_count > 0:\n",
    "        ## process tail batch (should not happen)\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03bf6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T10:41:24.402677Z",
     "start_time": "2021-11-10T10:41:24.367444Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def batch_forward(net, b, input_size, loss_class, loss_regr, weights_class, weights_regr, censored_weight=[], dev=\"cpu\"):\n",
    "    \"\"\"returns full outputs from the network for the batch b\"\"\"\n",
    "    ## Convert CSR tensor to COO tensor.\n",
    "    X = torch.sparse_coo_tensor(\n",
    "        b[\"x_ind\"],\n",
    "        b[\"x_data\"],\n",
    "        size = [b[\"batch_size\"], input_size]).to(dev, non_blocking=True)\n",
    "\n",
    "    yc_hat_all, yr_hat_all = net(X)\n",
    "\n",
    "    out = {}\n",
    "    out[\"yc_hat_all\"] = yc_hat_all\n",
    "    out[\"yr_hat_all\"] = yr_hat_all\n",
    "    out[\"yc_loss\"]    = 0\n",
    "    out[\"yr_loss\"]    = 0\n",
    "    out[\"yc_weights\"] = 0\n",
    "    out[\"yr_weights\"] = 0\n",
    "\n",
    "    if net.class_output_size > 0:\n",
    "        yc_ind  = b[\"yc_ind\"].to(dev, non_blocking=True)\n",
    "        yc_w    = weights_class[yc_ind[1]]\n",
    "        yc_data = b[\"yc_data\"].to(dev, non_blocking=True)\n",
    "        yc_hat  = yc_hat_all[yc_ind[0], yc_ind[1]]\n",
    "        out[\"yc_ind\"]  = yc_ind\n",
    "        out[\"yc_data\"] = yc_data\n",
    "        out[\"yc_hat\"]  = yc_hat\n",
    "        out[\"yc_loss\"] = (loss_class(yc_hat, yc_data) * yc_w).sum()\n",
    "        out[\"yc_weights\"] = yc_w.sum()\n",
    "\n",
    "    if net.regr_output_size > 0:\n",
    "        yr_ind  = b[\"yr_ind\"].to(dev, non_blocking=True)\n",
    "        yr_w    = weights_regr[yr_ind[1]]\n",
    "        yr_data = b[\"yr_data\"].to(dev, non_blocking=True)\n",
    "        yr_hat  = yr_hat_all[yr_ind[0], yr_ind[1]]\n",
    "\n",
    "        out[\"ycen_data\"] = b[\"ycen_data\"]\n",
    "        if out[\"ycen_data\"] is not None:\n",
    "            out[\"ycen_data\"] = out[\"ycen_data\"].to(dev, non_blocking=True)\n",
    "            \n",
    "            if len(censored_weight) > 0:\n",
    "                ## updating weights of censored data\n",
    "                yrcen_w = yr_w * censored_weight[yr_ind[1]]\n",
    "                yr_w    = torch.where(out[\"ycen_data\"] == 0, yr_w, yrcen_w)\n",
    "\n",
    "        out[\"yr_ind\"]  = yr_ind\n",
    "        out[\"yr_data\"] = yr_data\n",
    "        out[\"yr_hat\"]  = yr_hat\n",
    "        out[\"yr_loss\"] = (loss_regr(input=yr_hat, target=yr_data, censor=out[\"ycen_data\"]) * yr_w).sum()\n",
    "        out[\"yr_weights\"] = yr_w.sum()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a6813d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fa94ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T05:17:59.461616Z",
     "start_time": "2021-09-14T05:17:59.431853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#####   model saving   #####\n",
    "if not os.path.exists(args.output_dir):\n",
    "   os.makedirs(args.output_dir)\n",
    "\n",
    "model_file = f\"{args.output_dir}/{name}.pt\"\n",
    "out_file   = f\"{args.output_dir}/{name}.json\"\n",
    "\n",
    "if args.save_model:\n",
    "   torch.save(net.state_dict(), model_file)\n",
    "   vprint(f\"Saved model weights into '{model_file}'.\")\n",
    "\n",
    "results_va[\"classification\"][\"num_pos\"] = num_pos_va\n",
    "results_va[\"classification\"][\"num_neg\"] = num_neg_va\n",
    "results_va[\"regression\"][\"num_samples\"] = num_regr_va\n",
    "\n",
    "if results_tr is not None:\n",
    "    results_tr[\"classification\"][\"num_pos\"] = num_pos - num_pos_va\n",
    "    results_tr[\"classification\"][\"num_neg\"] = num_neg - num_neg_va\n",
    "    results_tr[\"regression\"][\"num_samples\"] = num_regr - num_regr_va\n",
    "\n",
    "sc.save_results(out_file, args, validation=results_va, training=results_tr)\n",
    "\n",
    "vprint(f\"Saved config and results into '{out_file}'.\\nYou can load the results by:\\n  import sparsechem as sc\\n  res = sc.load_results('{out_file}')\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc71f21",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93c2c7f5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exploring Variables and Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29206913",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Panda Create Weights Dataframe\n",
    "\n",
    "Create a dataframe of 100 rows consisting of random training weights and task types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0bf8ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:09:13.551116Z",
     "start_time": "2021-09-14T03:09:13.543584Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    df = pd.DataFrame({\n",
    "        \"task_id\":         np.arange(100),\n",
    "        \"training_weight\": np.clip(np.random.randn(100), 0, 1),\n",
    "        \"task_type\":       np.random.choice([\"adme\", \"panel\", \"other\"], size=100),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a24eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:09:15.043037Z",
     "start_time": "2021-09-14T03:09:15.020351Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a42d57d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:09:31.170015Z",
     "start_time": "2021-09-14T03:09:31.165246Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conf_file  = glob.glob(f\"{output_dir}/*.json\")\n",
    "model_file = glob.glob(f\"{output_dir}/*.pt\")\n",
    "\n",
    "print(f\"Conf file : {conf_file}\")\n",
    "# results = sc.load_results(conf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba56bad",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Compressed Sparse Row Formatted Matrix Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646b837a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:09:34.915511Z",
     "start_time": "2021-09-14T03:09:34.901574Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ecfp = np.load(f\"./{data_dir}/chembl_23mini_x.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da993f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:09:36.120746Z",
     "start_time": "2021-09-14T03:09:36.107321Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('ecfp     : ' ,type(ecfp))\n",
    "print('ecfp_item:  ', type(ecfp_item := ecfp.item()),\n",
    "      '\\necfp_tocsr: ', type(ecfp_tocsr := ecfp.item().tocsr()))\n",
    "if (ecfp_item - ecfp_tocsr).nnz == 0:\n",
    "    print(' Matricies are equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c75490",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:09:44.404266Z",
     "start_time": "2021-09-14T03:09:44.397856Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(repr(ecfp_item))\n",
    "print(repr(ecfp_tocsr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d2674a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `y_class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac114d8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:09:47.339923Z",
     "start_time": "2021-09-14T03:09:47.334279Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_class = np.load(f\"./{data_dir}/chembl_23mini_y.npy\", allow_pickle=True)\n",
    "\n",
    "print('y_class      : ', type(y_class), y_class.shape)\n",
    "print('y_class_item : ', type(y_class_item := y_class.item()) , y_class_item.shape,\n",
    "    '\\ny_class_tocsr: ', type(y_class_tocsr := y_class.item().tocsr()), y_class_tocsr.shape)\n",
    "if (y_class_item - y_class_tocsr).nnz == 0:\n",
    "    print(' Matricies are equal')\n",
    "print('Y_class: ', repr(y_class))\n",
    "print('Y_class_item: ', repr(y_class_item))\n",
    "print('Y_class_to_csr: ', repr(y_class_tocsr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6635b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:11:43.101298Z",
     "start_time": "2021-09-14T03:11:43.092604Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print((y_class_tocsr == +1).shape)\n",
    "print((y_class_tocsr > 0.0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d7ea6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:11:50.595237Z",
     "start_time": "2021-09-14T03:11:50.584129Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_pos    = np.array((y_class_tocsr == +1).sum(0)).flatten()\n",
    "num_neg    = np.array((y_class_tocsr == -1).sum(0)).flatten()\n",
    "num_class  = np.array((y_class_tocsr != 0).sum(0)).flatten()\n",
    "print(f' num pos  : {num_pos[:100]}')\n",
    "print(f' num neg  : {num_neg[:100]}')\n",
    "print(f' num class: {num_class[:100]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d77635",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:11:53.942554Z",
     "start_time": "2021-09-14T03:11:53.938805Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if (num_class != num_pos + num_neg).any():\n",
    "    print(\"For classification all y values (--y_class/--y) must be 1 or -1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d5a602",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b490cc5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `y_censor`\n",
    "\n",
    "`y_censor` is a sparse matrix : row_count x class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d22f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:12:06.533508Z",
     "start_time": "2021-09-14T03:12:06.527736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_censor = np.load(f\"./{data_dir}/chembl_23mini_y_censored.npy\", allow_pickle=True)\n",
    "\n",
    "print('y_censor      : ', type(y_censor), y_censor.shape)\n",
    "print('y_censor_item : ', type(y_censor_item := y_censor.item()) , y_censor_item.shape,\n",
    "    '\\ny_censor_tocsr: ', type(y_censor_tocsr := y_censor.item().tocsr()), y_censor_tocsr.shape)\n",
    "if (y_censor_item - y_censor_tocsr).nnz == 0:\n",
    "    print(' Matricies are equal')\n",
    " \n",
    "print('Y_censor: ', repr(y_censor))\n",
    "print('Y_censor_item: ', repr(y_censor_item))\n",
    "print('Y_censor_to_csr: ', repr(y_censor_tocsr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd877fdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:28:36.480919Z",
     "start_time": "2021-09-14T03:28:36.477663Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(y_censor_tocsr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10318c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  `y_regr`\n",
    "\n",
    "`y_regr` is a sparse matrix : row_count x class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3233590c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:28:39.256666Z",
     "start_time": "2021-09-14T03:28:39.249774Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_regr = np.load(f\"./{data_dir}/chembl_23mini_y.npy\", allow_pickle=True)\n",
    "\n",
    "print('y_regr      : ', type(y_regr), y_regr.shape)\n",
    "print('y_regr_item : ', type(y_regr_item := y_regr.item()) , y_regr_item.shape,\n",
    "    '\\ny_regr_tocsr: ', type(y_regr_tocsr := y_regr.item().tocsr()), y_regr_tocsr.shape)\n",
    "if (y_regr_item - y_regr_tocsr).nnz == 0:\n",
    "    print(' Matricies y_regr_item and y_regr_tocsr are equal')\n",
    " \n",
    "\n",
    "print('Y_regr: ', repr(y_regr))\n",
    "print('Y_regr_item: ', repr(y_regr_item))\n",
    "print('Y_regr_to_csr: ', repr(y_regr_tocsr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349dd8b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T23:11:58.287148Z",
     "start_time": "2021-07-21T23:11:58.284277Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(y_regr_tocsr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa16e30",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292becc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:29:39.093797Z",
     "start_time": "2021-09-14T03:29:39.084214Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folding = np.load(f\"./{data_dir}/chembl_23mini_folds.npy\")\n",
    "print(repr(folding), folding.shape)\n",
    "print(np.unique(folding))\n",
    "print(np.bincount(folding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e2bf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:29:54.320107Z",
     "start_time": "2021-09-14T03:29:54.311827Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y1= y_class_tocsr[folding == 4]\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467d266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:29:58.781372Z",
     "start_time": "2021-09-14T03:29:58.777764Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(y_class_tocsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e731cbb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:29:59.155901Z",
     "start_time": "2021-09-14T03:29:59.151901Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d89bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:29:59.476517Z",
     "start_time": "2021-09-14T03:29:59.467321Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# del n_pos, n_neg\n",
    "n_pos =   np.array((y1 == +1).sum(0))\n",
    "n_pos.shape\n",
    "n_pos.flatten()\n",
    "# n_neg =   np.array((y1 == -1).sum(0)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf070f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T03:30:02.741039Z",
     "start_time": "2021-09-14T03:30:02.710445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folds = np.unique(folding)\n",
    "num_pos = []\n",
    "num_neg = []\n",
    "for fold in folds:\n",
    "    yf = y_class_tocsr[folding == fold]\n",
    "    num_pos.append( np.array((yf == +1).sum(0)).flatten() )\n",
    "    num_neg.append( np.array((yf == -1).sum(0)).flatten() )\n",
    "    print(f' Fold: {fold}')\n",
    "    print(f' ------------')\n",
    "    print('num_pos: ' , num_pos)\n",
    "    print('num_neg: ', num_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c7e23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T23:12:03.045854Z",
     "start_time": "2021-07-21T23:12:03.038527Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_pos_stack = np.row_stack(num_pos)\n",
    "\n",
    "num_pos_stack.shape\n",
    "num_pos_stack[:,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc315e20",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Input File Folding and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6dac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T23:12:04.578615Z",
     "start_time": "2021-07-21T23:12:04.464343Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folding_size = 2\n",
    "ecfp_folded = sc.fold_transform_inputs(ecfp_tocsr, folding_size=folding_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcdc530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T23:12:05.369591Z",
     "start_time": "2021-07-21T23:12:05.364438Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(repr(ecfp_tocsr))\n",
    "print(repr(ecfp_folded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb2048e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T23:12:06.377812Z",
     "start_time": "2021-07-21T23:12:06.263614Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folding_size = 73\n",
    "idx = ecfp_tocsr.nonzero()\n",
    "print('\\n', idx[0], idx[0].shape,'\\n', idx[1], idx[1].shape)\n",
    "\n",
    "folded = idx[1] % folding_size\n",
    "print(folded, len(folded))\n",
    "x = scipy.sparse.csr_matrix((ecfp_tocsr.data, (idx[0], folded)), shape=(ecfp_tocsr.shape[0], folding_size))\n",
    "print(repr(x))\n",
    "\n",
    "## Eliminate dups by adding them together.\n",
    "x.sum_duplicates()\n",
    "print(repr(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e64a038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T23:12:06.955537Z",
     "start_time": "2021-07-21T23:12:06.951594Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyt-gpu]",
   "language": "python",
   "name": "conda-env-pyt-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
